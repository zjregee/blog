[{"content":" # 一、整体架构 Docker 是开源的容器化平台，通过将应用程序及其依赖项打包成一个轻量级、可移植的容器，然后在任何支持 Docker 的环境中运行这些容器，实现更简单、更高效的部署和管理。下图是 Docker 官方文档给出的 Docker 整体架构图。\nDocker 的整体架构是一个 C/S 架构，Docker 客户端与 Docker 守护进程通信，由后者负责构建、运行和分发容器的繁重工作。Docker 守护进程提供 REST API 支持，使用 UNIX 套接字或网络接口来提供服务。Docker Registry 提供了 Docker 镜像使用、存储和注册的支持，其中 Docker Hub 是 Docker 官方提供的公共 Registry，Docker 默认在 Docker Hub 上查找镜像。\n在这里对 Docker 进行管理的核心概念容器与镜像进行简单的介绍。一个镜像是一个只读的模板，包含创建一个 Docker 容器的说明。通常，一个镜像基于另一个镜像，并进行一些额外的自定义。容器是镜像的可运行实例，可以使用 Docker API 或 CLI 创建、启动、停止或删除容器。可以将容器连接到一个或多个网络，为其附加存储，甚至根据当前状态创建一个新的镜像。容器是具有附加隔离和资源管理功能的进程，可以在有限制的条件下访问主机系统资源。\n此外，从上面的描述中不难发现，Docker 不仅仅指的是一个命令行程序或某些服务进程，他还包含了众多 Docker 公司为容器和镜像搭建的生态环境以及对容器构建、运行、测试、验证和分享的整体解决方案。事实上，Docker 的容器运行时在 2017 年因为种种原因开源（即在下一小节中会进一步介绍的 containerd），并在之后通过 CNCF 基金会进行管理。Docker 公司也将工作中心放在了构建全面工具链、提供整体服务和生态维护上。\n# 1.1 containerd 容器运行时 containerd 是一个为运行容器构建的符合 OCI 开放标准的运行时。containerd 构建在操作系统内和功能之上，并通过抽象层改进了容器管理，从而为开发人员隐藏容器底层机制的复杂性。通过使用 RUNC 等较低级别的容器运行时，确保容器化环境中的标准和互操作性，并有效地处理容器生命周期中的核心操作，包括创建、启动和停止容器。\n在目前的架构中，containerd 通过直接与操作系统交互来促进容器上的操作，而 Docker 引擎位于 containerd 之上，旨在提供额外的功能和增强的开发人员体验。\n具体来说，当运行 docker run 命令会进行以下流程：\nDocker CLI 通过 REST API 调用将运行命令和命令参数发送至 Docker 守护进程； Docker 守护进程解析并验证请求，检查容器镜像等内容是否在本地可用，以及是否需要从 Docker Registry 中拉取镜像； 一旦镜像准备好，Docker 守护进程就将控制权转移给 containerd，并由 containerd 从镜像创建容器； containerd 设置容器环境，包括设置容器文件系统、网络接口和其他隔离功能等任务； containerd 使用 shim 进程将容器的运行委托给 RUNC，这将创建并启动容器； 最后，一旦容器开始运行，containerd 将监控容器状态并相应地管理其生命周期。 # 1.2 OCI 与 CRI 标准 OCI 是一个开放的行业标准，旨在定义容器格式和运行时规范，以确保容器在不同的平台上可移植、可互操作性。通过推动容器技术的标准化，从而提高容器生态环境的可持续性。\n除此之外，Kubernetes 作为一个开源且成熟的容器编排平台，基于容器技术的基础之上，提供了一个强大的工作集来解决容器化应用程序的部署、管理和扩展问题，定义了 CRI 标准，用于与容器运行时通信，以管理容器的生命周期。CRI 标准的核心目标是将 Kubernetes 的容器管理功能与容器运行时解耦，使得 Kubernetes 能够以统一的方式与不同的容器运行时进行交互。\n然而，由于Docker 本身不直接支持 CRI 标准，为了能够在 Kubernetes 中使用 Docker，Kubernetes 在发展阶段通过一些适配器的工作来兼容 Docker。目前 Kubernetes 已经移除了对 Docker 的支持，并直接使用 containerd 来操作容器。作为 CNCF 的子项目，containerd 很好地提供了 CRI 标准的支持。\n# 二、命名空间隔离与系统资源限制 namespace 和 cgroups 是 Linux 操作系统中用于资源隔离和管理的两个关键技术。\nnamespace 允许在同一台物理机上创建隔离的环境，每个环境都有自己的视图，就好像它们在独立的系统上运行一样。这种隔离使得多个进程可以在同一台主机上运行，彼此间互不干扰。常见的 namespace 包括：PID namespace，允许在系统中创建进程隔离，每个 PID namespace 中的进程只能看到相同 namespace 中的其他进程；Mount namespace，为不同进程提供独立的文件系统视图，使得在不同的 Mount namespace 中可以挂载不同的文件系统；Network namespace，允许不同的进程拥有独立的网络栈；User namespace，为进程提供独立的用户和组标识符空间，允许在不同的 namespace 中有相同的用户和组的名称，但实际上对应不同的用户和组。\ncgroups 允许系统管理员限制和控制一组进程的资源使用，包括 CPU、内存、磁盘 I/O 等。通过将进程防止在 cgroups 中，管理员可以为这些进程分配资源配额，确保它们不会消耗系统的全部资源。cgroups 是多个资源控制器的集合，包括 cpu、memory、blkio、net_cls 和 devices 等。\nchroot 是一个 Linux 命令，用于改变当前进程及其子进程的根目录。这个命令不如 namespace 和 cgroups 强大，但可以创造一种类似于容器的环境，在执行 chroot 后，进程将无法访问新根目录之外的文件系统内容。\n# 三、Docker 中的数据管理 # 3.1 联合文件系统 Docker 通过联合文件系统技术来实现容器的轻量化和高效的文件系统管理。联合文件系统的基本原理是通过将多个文件系统挂载在同一个目录下，使它们看起来像是一个单一的文件系统，但实际上数据存储在各自的文件系统中。\nDocker 镜像是由多个层组成的，每个层都是文件系统的一个快照，包含了构建镜像时所添加或修改的文件。每个层都只包含自身的变化，因此可以高效地共享和重用已有的层。这使得 Docker 镜像可以非常轻量，因为它们通常只存储应用程序的变化部分，而不是整个文件系统。当一个容器启动时，Docker 会创建一个读写层，用于容器运行时的文件写入操作。这个读写层是基于镜像的只读层构建的，但是采用写时复制机制，从而确保了原始镜像的不变性。\n联合文件系统将 Docker 容器中的多个层联合挂载在一起，形成一个单一的文件系统试图。当容器的应用程序访问文件时，联合文件系统根据文件路径逐层向下查找，同时只在最上层的读写层中覆盖、重写或添加文件。由于镜像只有只读层组成，因此确保了应用程序环境的一致性和可重复性。\n通过联合文件系统机制，Docker 实现高效的文件系统管理和轻量级的容器化。联合文件系统使得 Docker 容器可以快速启动，占用少量的存储空间，并且可以方便地与其他容器共享文件系统中的内容，提供了容器的性能和可移植性。\nDocker 提供了多种联合文件系统的支持，在早期版本的 Docker 中，AUFS 是 Docker 中默认使用的联合文件系统，但后来由于一些兼容性和稳定性的问题，Docker 目前默认使用 OverlayFS 实现容器的轻量化和高效的文件系统管理。\n# 3.2 卷与文件系统挂载 默认情况下，容器中写入的文件系统更新都存储在上一小节中提到的可写层中，这意味着：当容器不再存在时，数据不会持久存在，并且另一个进程很难从容器中获取数据；容器的可写层与运行容器的主机紧密耦合，很难将数据移动到其他地方；这种联合文件系统额外的抽象相较于直接写入主机文件系统相比，显然会降低性能，即使联合文件系统通常在操作系统内核中实现。\nDocker 提供了 bind mount 和 volume 两个方式可以让容器在主机上存储文件，以便即使在容器停止后文件依然存在。此外，Docker 还提供了 tmpfs 用于将文件存储在内存中。\n一个简单且直观的差异在于数据存储位置：volume 存储在由 Docker 管理的主机文件系统的一部分中，非 Docker 进程不应该修改文件系统的这一部分，这也是 Docker 推崇的保存数据的最佳方式；挂载的目录可以主机系统中的任何位置，非 Docker 进程可能会随时修改它。tmpfs 中的数据仅存储在主机系统的内存中，并且不会写入主机系统的文件系统中，容器可以在容器的生命周期内使用它来存储非持久状态或敏感信息。\n# 四、Docker 使用实践 # 4.1 开发环境统一神器 Dev Container Dev Container 是 vscode 提供的一个插件，与 vscode 集成良好。Dev Container 提供了一种开发配置工具，支持在容器中构建、开发、运行和调试应用程序，而无需在本地安装和配置所有必需的软件和依赖项。\nDev Container 通过项目目录下的 .devcontainer 文件夹来定义这些环境。在实践中，可以使用 Dockerfile 定义开发容器的基础镜像和构建步骤，并通过一个名为 devcontainer.json 的文件，配置容器的其他属性，例如挂载目录、端口映射和环境变量等。\n通过使用 Dev Container，不仅可以在各种主机上快速启动一致的开发环境，并且可以为每个项目的配置环境进行隔离，避免所有的系统配置都直接安装在主机上。此外，编写 Dev Container 配置文件的过程也是记录开发环境配置的过程，具有复用性。\n# 4.2 单节点多容器部署 Docker Compose Docker Compose 是 Docker 官方提供的一个工具，用于定义和运行多个 Docker 容器的应用程序。它通过一个简单的 YAML 文件来配置应用程序的服务、网络和卷等，并可以一键运行相关容器和运行环境。在项目开发过程中，可以通过 Docker Compose 来定义服务的运行流程，便于使用和部署，以及梳理各容器在整体服务中扮演的角色。\n# 4.3 与 Github Actions 的 CI 集成 Github Actions 是 Github 提供的自动化集成测试和部署流程工具，通过在项目目录下编写相关工作流配置文件，可以定义各种灵活的 CI/CD 流程，并在每次提交代码时自动执行。在工作流中，可以通过 Docker 来定义工作流的测试环境，Docker 可以轻松地将测试运行在各种具体环境中。\n# 4.4 一些好用的 Docker 服务列表 Github 上有众多基于 Docker 一键部署的服务，但说实话，很多对我来说都没什么实际的使用价值，这部分记录了一些日常会使用且非常喜欢的 Docker 服务，持续 update ~\nmemos: 本地部署的日记、周报和随想记录网站 # 相关参考 https://docs.docker.com/manuals/ https://docs.docker.com/get-started/overview/ https://www.docker.com/blog/containerd-vs-docker/ ","date":"2024-01-12T00:00:00Z","permalink":"https://zjregee.github.io/blog/p/docker/","title":"Docker 基本原理及相关概念"},{"content":"groupcache 是 Golang 官方库给出的一个分布式缓存实现示例，旨在提供一个简单、有效的分布式缓存解决方案，用于替代许多场景下同样用于分布式内存缓存的 memcached 集群。\n# 一、分布式缓存架构 groupcache 集群包括多个对等的分布式节点，并通过 HTTP 请求的方式实现连接。每个节点对外提供的 HTTP 服务不仅用于处理客户端的缓存查询请求，同时也用于处理对等节点之间的缓存查询请求。值得一提的是，对于外部的客户端缓存查询请求，groupcache 节点通过 URL 路径解析的方式处理请求交互，并通过 Protobuf 的编解码方式进行节点间信息的处理。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 type httpGetter struct { baseURL string transport func(context.Context) http.RoundTripper } func (h *httpGetter) Get(ctx context.Context, in *pb.GetRequest, out *pb.GetResponse) error { ... } type HTTPPool struct { Context func(*http.Request) context.Context Transport func(context.Context) http.RoundTripper self string opts HTTPPoolOptions mu sync.Mutex peers *consistenthash.Map httpGetters map[string]*httpGetter } func (p *HTTPPool) ServeHTTP(w http.ResponseWriter, r *http.Request) { ... } HTTPPool 是每个节点中的内存数据结构，存储着整个集群的拓扑信息。对等的分布式节点之间通过一致性哈希算法来确定每个节点所管理的键值范围。一致性哈希算法的使用不仅可以使得集群中的节点快速定位到键值所属的对应节点，通过一致性哈希算法中副本数的设置也可以尽可能保障键值的均匀分配。此外，HTTPPool 通过 ServerHTTP 方法实现 http.Handler 接口实现对外提供的 HTTP 服务，httpGetter 提供了对其他节点进行访问的 Get 方法封装。\n1 2 3 4 5 6 7 8 9 type ProtoGetter interface { Get(ctx context.Context, in *pb.GetRequest, out *pb.GetResponse) error } type PeerPicker interface { PickPeer(key string) (ProtoGetter, bool) } var portPicker func(groupName string) PeerPicker groupcache 会将 HTTPPool 注册至 portPicker，从而实现缓存命名空间，不同命名空间的缓存服务使用不同的 HTTPPool。\n# 二、缓存填充设计 HTTPPool 构建起了整个 groupcache 的网络拓扑结构并提供了 HTTP 请求流动的支持。在 groupcache 中，除了 HTTPPool，每个分布式节点还会维护自己的内存缓存。\n# 2.1 ByteView 与 Sink 1 2 3 4 5 6 7 8 9 10 11 type ByteView struct { b []byte s string } type Sink interface { SetString(s string) error SetBytes(v []byte) error SetProto(m proto.Message) error view() (ByteView, error) } 在缓存设计中，groupcache 提供了 ByteView 和 Sink 封装。ByteView 是缓存中的值类型，通过 ByteView 来避免缓存中的值发生变化。同时，这也意味着 groupcache 的设计初衷在于提供不可变的缓存查询支持，不支持数据的增删改。这在官方的文档中被称为对版本化值的不支持，没有缓存过期时间，没有显式的缓存驱逐（只会在缓存区满时对缓存进行淘汰），无需 CAS 操作（因为没有修改过程中的潜在冲突）。\n支持增删改的分布式缓存系统需要保持强一致性，而并非所有场景都需要支持对缓存的增删改。大部分的缓存场景只需支持对高频访问数据的维护，即使存在需要改动的情况也可以将不会发生改变的东西剥离引入缓存。因此 groupcache 的设计理念在现实场景中仍然有一定的参考和使用价值，但并非适用于所有场景。Sink 是对缓存查询行为的封装，缓存查询过程中会将对应 ByteView 的值更新在实现 Sink 接口的对象中。\n# 2.2 内存缓存架构与查询流程 1 2 3 4 5 6 7 8 9 type Getter interface { Get(ctx context.Context, key string, dest Sink) error } type GetterFunc func(ctx context.Context, key string, dest Sink) error func (f GetterFunc) Get(ctx context.Context, key string, dest Sink) error { return f(ctx, key, dest) } groupcache 以 lib 库的形式提供给用户，在部署时与用户进程进行集成，用户需要为 groupcache 提供实现 Getter 接口的缓存获取方法。在之前已经提到，groupcache 中的每个节点通过一致性哈希算法确定自己负责的键值范围，这可以理解为这部分键值属于节点的本职工作。那么节点如何获取这部分键值呢，答案就是用户提供的 Getter 接口实现。实现 Getter 接口的方法可以从 redis 或其他数据库中获取实际数据，甚至是另外一个 groupcache 集群。groupcache 整体的接口设计以 lib 库的模式进行，而不直接负责运行分布式缓存服务，提供了使用上的灵活性。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 type flightGroup interface { Do(key string, fn func() (interface{}, error)) (interface{}, error) } type Group struct { name string getattr Gettter peers PeerPicker cacheBytes int64 mainCache cache hotCache cache loadGroup flightGroup } func (g *Group) Get(ctx context.Context, key string, dest Sink) error { ... } func (g *Group) getLocally(ctx context.Context, key string, dest Sink) (ByteView, error) { ... } func (g *Group) getFromPeer(ctx context.Context, key string, dest Sink) (ByteView, error) { ... } func (g *Group) lookupCache(key string) (ByteView, bool) { ... } func (g *Group) populateCache(key string, value ByteView, cache *cache) { ... } Group 是内存缓存的主要数据结构，其中包括了 mainCache 和 hotCache 两种缓存，两者都是基于 LRU 算法实现的内存缓存。cacheBytes 用于限制缓存的大小，两种缓存加起来的内存使用量不大于 cacheBytes，否则就会通过 populateCache 方法驱逐部分缓存。mainCache 和 hotCache 中缓存的键值不仅仅来源于 Getter 方法，也包括接收到不属于节点管理范围的键值查询请求时，通过 getFromPeer 方法从其他对等节点获取的键值数据。\nGroup 接收到键值查询请求后，完整的处理流程包括：查询 mainCache 和 hotCache 中是否包含键值数据，存在缓存数据时直接返回相关数据；当缓存数据不存在时，判断键值数据是否有该节点直接负责，若由该节点直接负责该数据，则通过 getLocally 方法调用 Getter 方法获取数据，并添加至 mainCache；若由其他节点负责该数据，则通过 getFromPeer 方法从其他节点获取数据，并通过随机概率将该数据添加至 hotCache（通过引入随机性，使得 hotCache 中缓存的是其他节点中的热点数据，即当需要经常从其他节点查询某数据时，则有较大概率将数据加入 hotCache）。\n# 2.3 缓存未命中下的限流 至此，groupcache 的整体架构以及实现分布式缓存的原理已经基本清晰。groupcache 通过两种方式确保了缓存未命中下的限流：\n所有对等节点均匀划分了键值范围，当缓存未命中时，只会有一个节点从后端的数据库中查询键值数据，其他节点只需从该节点同步数据，避免大量的重复查询流量直接引入后端的数据库中，这被成为缓存填充的协调以及键值加载后的多路复用。 通过 flightGroup 方法避免了缓存未命中并有大量查询请求在查询同一个未命中的键值时生成众多相同的缓存更新操作。这里有两层意思，缓存未命中时，节点只会向其他负责该数据的节点发送一个查询请求，负责该数据的节点只会向后端的数据库发送一个查询请求。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 type call struct { wg sync.WaitGroup val interface{} err error } type Group struct { mu sync.Mutex m map[string]*call } func (g *Group) Do(key string, fn func() (interface{}, error)) (interface{}, error) { g.mu.Lock() if g.m == nil { g.m = make(map[string]*call) } if c, ok := g.m[key]; ok { g.mu.Unlock() c.wg.Wait() return c.val, c.err } c := new(call) c.wg.Add(1) g.m[key] = c g.mu.Unlock() c.val, c.err = fn() c.wg.Done() g.mu.Lock() delete(g.m, key) g.mu.Unlock() return c.val, c.err } 上面的代码是 groupcache 中对 flightGroup 的实现。\n写在最后。\ngroupcache 整体代码在不包括测试的情况下一千多行，麻雀虽小，五脏俱全，其中包含的细节和工程实现还是比较完整的，对缓存穿透和热点节点问题给出了一定的解决思路。据官网所描述，groupcache 也曾在 Google 中用于生产环境，其设计思想并没有很复杂，但仍然具有一定参考价值。此外，由于灵活的运用了接口和 lib 库设计模式使得代码并没有非常直观，没有一个端到端的运行链，很多时候逻辑是循环嵌套的。\n项目地址：https://github.com/golang/groupcache.\n","date":"2023-12-11T00:00:00Z","permalink":"https://zjregee.github.io/blog/p/groupcache/","title":"groupcache 支持热点填充的分布式内存缓存设计"},{"content":" 该笔记基于 Golang 1.21.6。\n源码地址：https://github.com/golang/go\n# 一、context context 包提供了在 Goroutines 之间传递取消信号、超时和截止时间的一种方式，以及存储和检索请求处理相关数据的机制，是 Golang 中用于处理请求范围内数据和控制请求生命周期的重要工具。Context 接口定义了基本的上下文操作：Deadline 方法返回一个上下文被取消的时间，即完成工作的截止时间；Done 方法返回一个 Channel。这个 Channel 会在当前工作完成或上下文被取消后关闭，多次调用 Done 方法会返回同一个 Channel；Err 方法返回上下文结束的原因，它只会在 Done 方法对应的 Channel 关闭时返回非空值，如果上下文被取消返回 Canceled 错误，如果上下文超时返回 DeadlineExceeded 错误；Value 方法从上下文中获取键对应的值，对于同一个上下文来说，多次调用 Value 方法并传入相同的键会返回相同的结果，该方法可以用来传递特定的数据。\n1 2 3 4 5 6 7 8 package context type Context interface { Deadline() (deadline time.Time, ok bool) Done() \u0026lt;-chan struct{} Err() error Value(key any) any } context 包的最大用处在于在 Goroutines 构成的树形结构中同步信号以减少计算资源的浪费。上下文可以从最顶层的 Goroutines 逐层传递到最底层，以便在上层的 Goroutines 执行出现错误时将信号即时同步给下层。一个常见的使用场景是多个 Goroutines 同时订阅上下文 Done 方法 Channel 中的消息，一旦接受到取消信号就立刻停止当前正在执行的工作。\n# 1.1 默认上下文与私有结构体 context 包中有两个常用的 Background 和 TODO 函数，它们分别用于创建根上下文和未来可能会用到但目前还没有具体值的上下文。这两者返回的上下文均基于内部的私有结构体 emptyCtx，它通过空方法实现了 Context 接口的所有方法，没有任何实际功能。具体来说，backgroundCtx 是上下文的默认值，其他所有上下文都应该从它衍生出来，todoCtx 应该在不确定使用哪种上下文时使用，或仅作为一种占位符存在。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 package context type emptyCtx struct{} func (emptyCtx) Deadline() (deadline time.Time, ok bool) { return } func (emptyCtx) Done() \u0026lt;-chan struct{} { return nil } func (emptyCtx) Err() error { return nil } func (emptyCtx) Value(key any) any { return nil } type backgroundCtx struct{ emptyCtx } func (backgroundCtx) String() string { return \u0026#34;context.Background\u0026#34; } type todoCtx struct{ emptyCtx } func (todoCtx) String() string { return \u0026#34;context.TODO\u0026#34; } func Background() Context { return backgroundCtx{} } func TODO() Context { return todoCtx{} } 除了这两个简单的默认上下文，context 包还提供了诸多派生上下文，派生上下文用于在已有的上下文中创建一个新的上下文，新上下文继承了原始上下文的一些信息，同时可以添加或修改一些新的属性。派生上下文通常通过 WithXXX 函数实现，例如 WithCancel、WithTimeout、WithDeadline 等，每种派生上下文的使用场景和实现原理会在后面的内容中展开。\n# 1.2 派生上下文之传值 1 2 3 4 5 6 7 8 9 10 11 12 package context func WithValue(parent Context, key, val any) Context { ... } type valueCtx struct { Context key, val any } func (c *valueCtx) Value(key any) any { ... } func value(c Context, key any) any { ... } WithValue 函数接受一个父上下文，以及一个 KV 对，返回一个新的上下文。这个新的上下文包含了父上下文的所有信息，并在其中添加了 KV 对数据。valueCtx 的实现原理较为简单，在父上下文的基础上额外增加了 key、val 字段用于保存 KV 对数据。此处值得一提的是 value 函数，value 函数会通过循环从该上下文从上搜索直至到上下文树顶部，在过程中不断根据上下文的类型进行匹配，处理不同类型的上下文。当前上下文是 valueCtx 时，如果键匹配则返回对应的值，否则继续往上层上下文查找；当前上下文是 cancelCtx 时，如果键是 \u0026amp;cancelCtxKey，则返回当前上下文，否则继续往上层上下文查找；当前上下文是 withoutCancelCtx 时，如果键是 \u0026amp;cancelCtxKey，则返回当前上下文，否则继续往上层上下文查找；当前上下文是 timerCtx 时，如果键是 \u0026amp;cancelCtxKey，则返回该上下文关联的 cancelCtx，否则继续往上层上下文查找；当前上下文是 backgroundCtx 或 todoCtx 时，直接返回 nil；对于其他上下文，直接调用上下文的 Value 方法。这里只陈述搜索逻辑，因为尚未提到其他上下文，不具体解释其中的一些行为。\n# 1.3 派生上下文之取消 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 package context var cancelCtxKey int type CancelFunc func() type CancelCauseFunc func(cause error) func WithCancel(parent Context) (ctx Context, cancel CancelFunc) { ... } func WithCancelCause(parent Context) (ctx Context, cancel CancelCauseFunc) {...} func Cause(c Context) error { ... } type canceler interface { cancel(removeFromParent bool, err, cause error) Done() \u0026lt;-chan struct{} } type cancelCtx struct { Context mu sync.Mutex done atomic.Value children map[canceler]struct{} err error cause error } WithCancel 函数返回一个父上下文的拷贝上下文，新上下文使用新的 Done channel，新的 Done channel 当 WithCancel 函数返回的 cancel 函数被调用或者父上下文的 Done channel 被关闭时关闭。WithCancelCause 函数类似，但会额外设置取消原因，这个取消原因可以在被取消的上下文和其派生上下文中通过 Cause 函数来获取，WithCancelCause 函数返回的 cancel 函数只有在上下文还没有取消时可以取消以及设置取消原因。\nWithCancel 和 WithCancelCause 函数返回的上下文均基于内部的私有结构体 cancelCtx，cancelCtx 各字段的作用包括：Context 用于记录父上下文；mu 字段用于保护其他字段的并发访问；done 字段是一个支持原子操作的值容器，用于记录 cancelCtx 的 Done Channel；children 字段是一个存储实现 canceler 接口的子上下文的集合，用于在取消该上下文时，取消其他子上下文，一个实现了 canceler 接口的上下文支持通过 cancel 方法立刻取消该上下文，cancelCtx 和在之后会涉及到的 timerCtx 均实现了该接口；err 字段用于记录该上下文的取消原因或错误状态；cause 字段用于记录该上下文取消的根本原因，即该原因可能是上层上下文传递下来的或是一些底层的错误信息，Cause 函数的实现原理即通过该上下文的 Value 函数循环向上层上下文寻找 cancelCtx，并返回该 cancelCtx 的 cause 字段信息。此外，cancelCtx 的诸多字段会通过惰性创建，在使用的时候进行初始化。\nWithCancel 和 WithCancelCause 函数的实现类似，通过创建一个 cancelCtx，并调用 cancelCtx 的 propagateCancel 方法设置该上下文的父上下文，以便在父上下文被取消时取消该上下文，并返回封装了 cancelCtx 的 cancel 方法的 cancel 函数。propagateCancel 和 cancel 方法是 cancelCtx 的核心方法，在展开 propagateCancel 方法的完整实现逻辑之前，需要首先介绍 context 包中另外两个私有结构体 afterFuncCtx 和 stopCtx 以及工具函数 parentCancelCtx 和 removeChild。\n1 2 3 4 5 6 7 8 9 10 11 12 package context type afterFuncCtx struct { cancelCtx once sync.Once f func() } type stopCtx struct { Context stop func() bool } afterFuncCtx 的目的是实现一个带有延迟执行函数的上下文，它包含了一个函数 f，该函数会在该上下文取消时执行，且通过 once 字段确保只执行一次，事实上这个 once 字段还可以保证最多执行一次。stopCtx 被用于当一个带有延迟执行函数的上下文需要注册 cancelCtx 子上下文时，作为该 cancelCtx 上下文的父上下文。stopCtx 相当于一个中间上下文，原本没有 stopCtx 的情况下，在一个带有延迟执行函数的上下文中注册 cancelCtx 子上下文时，cancelCtx 的父上下文则为这个带有延迟执行函数的上下文。stopCtx 提供了取消上下文并注销注册的能力，通过 stop 字段记录的函数可以使得当这个带有延迟执行函数的上下文被取消需要执行延迟执行函数的时候不再执行该 cancelCtx 的 cancel 方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 package context func parentCancelCtx(parent Context) (*cancelCtx, bool) { done := parent.Done() if done == closedchan || done == nil { return nil, false } p, ok := parent.Value(\u0026amp;cancelCtxKey).(*cancelCtx) if !ok { return nil, false } pdone, _ := p.done.Load().(chan struct{}) if pdone != done { return nil, false } return p, true } func removeChild(parent Context, child canceler) { if s, ok := parent.(stopCtx); ok { s.stop() return } p, ok := parentCancelCtx(parent) if !ok { return } p.mu.Lock() if p.children != nil { delete(p.children, child) } p.mu.Unlock() } parentCancelCtx 函数用于返回父上下文内置的 cancelCtx，removeChild 函数用于从父上下文中移除某个实现 canceler 接口的子上下文，当父上下文是 stopCtx 时，调用 stopCtx 记录的 stop 函数注销子上下文在父上下延迟执行函数中的注册，如果父上下文内置的是 cancelCtx，则将子上下文从父上下文中的 children 字段中删除。值得一提的是，当父上下文是 stopCtx 时，不需要将子上下文从实际父上下文的 children 字段删除，因为子上下文的 cancel 方法通过延迟函数的函数调用行为注册，而没有通过 children 字段注册。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 package context func AfterFunc(ctx Context, f func()) (stop func() bool) { a := \u0026amp;afterFuncCtx{ f: f, } a.cancelCtx.propagateCancel(ctx, a) return func() bool { stopped := false a.once.Do(func() { stopped = true }) if stopped { a.cancel(true, Canceled, nil) } return stopped } } type afterFuncer interface { AfterFunc(func()) func() bool } func (a *afterFuncCtx) cancel(removeFromParent bool, err, cause error) { a.cancelCtx.cancel(false, err, cause) if removeFromParent { removeChild(a.Context, a) } a.once.Do(func() { go a.f() }) } 这里需要进一步解释带有延迟执行函数的上下文实现原理。AfterFunc 函数用于在上下文中注册一个函数，这个函数会在该上下文被取消时执行这个函数，同时会返回一个 stop 函数，该函数可以在上下文被取消之前放弃在上下文被取消时执行这个函数。AfterFunc 函数的实现依赖于已经提到的 afterFuncCtx，它创建一个中间 cancelCtx，并通过中间 cancelCtx 的 propagateCancel 方法该上下文中注册 afterFuncCtx 子上下文，当该上下文被取消时，会调用 afterFuncCtx 子上下文的 cancel 方法，从而实现在原上下文中增加一个延迟执行函数。当在原上下文返回之前调用 AfterFunc 函数返回的 stop 函数时，会提前取消 afterFuncCtx 上下文，并将其从原上下文中注销注册。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 package context var closedchan = make(chan struct{}) func init() { close(closedchan) } func (c *cancelCtx) cancel(removeFromParent bool, err, cause error) { if err == nil { panic(\u0026#34;context: internal error: missing cancel error\u0026#34;) } if cause == nil { cause = err } c.mu.Lock() if c.err != nil { c.mu.Unlock() return } c.err = err c.cause = cause d, _ := c.done.Load().(chan struct{}) if d == nil { c.done.Store(closedchan) } else { close(d) } for child := range c.children { child.cancel(false, err, cause) } c.children = nil c.mu.Unlock() if removeFromParent { removeChild(c.Context, c) } } cancelCtx 的 cancel 方法用于关闭 Done Channel 取消该上下文，并且会通过 child 字段调用每个子上下文的 cancel 方法取消子上下文，并通过 removeChild 函数将自己从父上下文中删去，过程中会通过 closedchan 实现复用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 package context var goroutines atomic.Int32 func (c *cancelCtx) propagateCancel(parent Context, child canceler) { c.Context = parent done := parent.Done() if done == nil { return } select { case \u0026lt;-done: child.cancel(false, parent.Err(), Cause(parent)) return default: } if p, ok := parentCancelCtx(parent); ok { p.mu.Lock() if p.err != nil { child.cancel(false, p.err, p.cause) } else { if p.children == nil { p.children = make(map[canceler]struct{}) } p.children[child] = struct{}{} } p.mu.Unlock() return } if a, ok := parent.(afterFuncer); ok { c.mu.Lock() stop := a.AfterFunc(func() { child.cancel(false, parent.Err(), Cause(parent)) }) c.Context = stopCtx{ Context: parent, stop: stop, } c.mu.Unlock() return } goroutines.Add(1) go func() { select { case \u0026lt;-parent.Done(): child.cancel(false, parent.Err(), Cause(parent)) case \u0026lt;-child.Done(): } }() } 在梳理了上述内容之后，最核心的 propagteCancel 方法的实现变得十分清晰。在注册子上下文至父上下文时，如果父上下文内置了 cancelCtx，则直接将自己的 cancel 方法通过父上下文的 children 字段注册，如果父上下文实现了 afterFuncer 接口，则通过父上下文的 AfterFunc 方法以父上下文延迟执行函数的形式注册，并通过中间上下文 stopCtx，保存注销注册的函数，如果父上下文不属于这两类，则创建一个 Goroutine 通过 select 来监听父上下文和子上下文的取消情况。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 package context func WithoutCancel(parent Context) Context { ... } type withoutCancelCtx struct { c Context } func (withoutCancelCtx) Deadline() (deadline time.Time, ok bool) { return } func (withoutCancelCtx) Done() \u0026lt;-chan struct{} { return nil } func (withoutCancelCtx) Err() error { return nil } func (c withoutCancelCtx) Value(key any) any { return value(c, key) } func (c withoutCancelCtx) String() string { return contextName(c.c) + \u0026#34;.WithoutCancel\u0026#34; } WithoutCancel 函数提供了一个父上下文的拷贝，并没有继续维持上下文中之间的取消能力，当父上下文取消时，子上下文不会取消。\n# 1.4 派生上下文之超时 1 2 3 4 5 6 package context func WithDeadline(parent Context, d time.Time) (Context, CancelFunc) { ... } func WithDeadlineCause(parent Context, d time.Time, cause error) (Context, CancelFunc) { ... } func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) { ... } func WithTimeoutCause(parent Context, timeout time.Duration, cause error) (Context, CancelFunc) { ... } WithDeadline、WithDeadlineCause、WithTimeout 和 WithTimeoutCause 函数提供了一个带有截止时间的上下文，该上下文会集成父上下文的特性，并在截止时间到达时，取消该上下文。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 package context func WithDeadlineCause(parent Context, d time.Time, cause error) (Context, CancelFunc) { if parent == nil { panic(\u0026#34;cannot create context from nil parent\u0026#34;) } if cur, ok := parent.Deadline(); ok \u0026amp;\u0026amp; cur.Before(d) { return WithCancel(parent) } c := \u0026amp;timerCtx{ deadline: d, } c.cancelCtx.propagateCancel(parent, c) dur := time.Until(d) if dur \u0026lt;= 0 { c.cancel(true, DeadlineExceeded, cause) return c, func() { c.cancel(false, Canceled, nil) } } c.mu.Lock() defer c.mu.Unlock() if c.err == nil { c.timer = time.AfterFunc(dur, func() { c.cancel(true, DeadlineExceeded, cause) }) } return c, func() { c.cancel(true, Canceled, nil) } } type timerCtx struct { cancelCtx timer *time.Timer deadline time.Time } func (c *timerCtx) Deadline() (deadline time.Time, ok bool) { return c.deadline, true } func (c *timerCtx) cancel(removeFromParent bool, err, cause error) { c.cancelCtx.cancel(false, err, cause) if removeFromParent { removeChild(c.cancelCtx.Context, c) } c.mu.Lock() if c.timer != nil { c.timer.Stop() c.timer = nil } c.mu.Unlock() } WithDeadlineCause 函数通过内部的私有结构体 timerCtx 实现，timerCtx 依赖 cancelCtx 实现大部分功能，实现逻辑较为简单。当创建一个 timerCtx 时，根据截至时间和 time.AfterFunc 函数创建一个延迟执行函数，当时间截止后，调用 timerCtx 的 cancel 方法，此外，也可以通过 WIthDeadlineCause 函数返回的 cancel 函数提前调用 timerCtx 的 cancel 方法。\n# 二、errors # 2.1 基本定义 error 是 builtin 包内置的一个接口，定义了表示错误的基本类型，error 接口只有一个方法，nil 表示没有错误。\n1 2 3 4 5 package builtin type error interface { Error() string } New 方法返回一个包含 string 的 error 实现 errorString。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package errors func New(text string) error { return \u0026amp;errorString{text} } type errorString struct { s string } func (e *errorString) Error() string { return e.s } var ErrUnsupported = New(\u0026#34;unsupported operation\u0026#34;) # 2.2 错误链 为了提供关于错误的额外上下文，在错误处理过程中实现更复杂的操作，通过 errors 包提供的相关函数以及 fmt 包提供的 %w 标志，可以简单的将错误包裹在另一个错误中，形成清晰的错误处理链条。\nUnwrap 函数用于获取错误链中的下一个错误，可以通过循环来迭代整个错误链。Is 函数用于比较错误链中的错误，判断某个特定类型的错误是否存在于错误莲中，这种方式比直接使用 == 更加令灵活，因为它不仅会检查最外层的错误。As 函数用于将错误断言为某个接口类型，并将该类型的值存储在目标变量中，这对于处理实现了特定接口的错误很有用。Is 和 As 函数都都可以以整个错误链为对象进行递归操作，提供对错误链的原生支持。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 package errors func Unwrap(err error) error { u, ok := err.(interface { Unwrap() error }) if !ok { return nil } return u.Unwrap() } func Is(err, target error) bool { if target == nil { return err == target } isComparable := reflectlite.TypeOf(target).Comparable() return is(err, target, isComparable) } func is(err, target error, targetComparable bool) bool { for { if targetComparable \u0026amp;\u0026amp; err == target { return true } if x, ok := err.(interface{ Is(error) bool }); ok \u0026amp;\u0026amp; x.Is(target) { return true } switch x := err.(type) { case interface{ Unwrap() error }: err = x.Unwrap() if err == nil { return false } case interface{ Unwrap() []error }: for _, err := range x.Unwrap() { if is(err, target, targetComparable) { return true } } return false default: return false } } } func As(err error, target any) bool { if err == nil { return false } if target == nil { panic(\u0026#34;errors: target cannot be nil\u0026#34;) } val := reflectlite.ValueOf(target) typ := val.Type() if typ.Kind() != reflectlite.Ptr || val.IsNil() { panic(\u0026#34;errors: target must be a non-nil pointer\u0026#34;) } targetType := typ.Elem() if targetType.Kind() != reflectlite.Interface \u0026amp;\u0026amp; !targetType.Implements(errorType) { panic(\u0026#34;errors: *target must be interface or implement error\u0026#34;) } return as(err, target, val, targetType) } func as(err error, target any, targetVal reflectlite.Value, targetType reflectlite.Type) bool { for { if reflectlite.TypeOf(err).AssignableTo(targetType) { targetVal.Elem().Set(reflectlite.ValueOf(err)) return true } if x, ok := err.(interface{ As(any) bool }); ok \u0026amp;\u0026amp; x.As(target) { return true } switch x := err.(type) { case interface{ Unwrap() error }: err = x.Unwrap() if err == nil { return false } case interface{ Unwrap() []error }: for _, err := range x.Unwrap() { if err == nil { continue } if as(err, target, targetVal, targetType) { return true } } return false default: return false } } } var errorType = reflectlite.TypeOf((*error)(nil)).Elem() # 2.3 错误合并 Join 方法用于将数个 error 合并成一个 error，其具体实现通过返回一个包含 error 数组的 error 实现 joinError。joinError 实现的 Error 方法会将内部 error 数组的多个 error 所提供的错误信息通过换行符连接，Unwrap 方法用于将 joinError 方便地纳入错误链之中，在上一小节中错误链提供的方法会原生支持 joinError。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 package errors func Join(errs ...error) error { n := 0 for _, err := range errs { if err != nil { n++ } } if n == 0 { return nil } e := \u0026amp;joinError{ errs: make([]error, 0, n), } for _, err := range errs { if err != nil { e.errs = append(e.errs, err) } } return e } type joinError struct { errs []error } func (e *joinError) Error() string { if len(e.errs) == 1 { return e.errs[0].Error() } b := []byte(e.errs[0].Error()) for _, err := range e.errs[1:] { b = append(b, \u0026#39;\\n\u0026#39;) b = append(b, err.Error()...) } return unsafe.String(\u0026amp;b[0], len(b)) } func (e *joinError) Unwrap() []error { return e.errs } # 三、bufio bufio 包包装了 io.Reader 和 io.Writer 对象，并提供了带缓冲的 IO 操作，用以提高 IO 操作的性能。该包包含了一些用于读写数据的缓冲区，以减少系统调用的次数，从而提高效率。\n# 3.1 Reader 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 package bufio type Reader struct { buf []byte rd io.Reader r, w int err error lastByte int lastRuneSize int } func NewReaderSize(rd io.Reader, size int) *Reader { ... } func NewReader(rd io.Reader) *Reader { ... } func (b *Reader) Size() int { ... } func (b *Reader) Reset(r io.Reader) { ... } func (b *Reader) Peek(n int) ([]byte, error) { ... } func (b *Reader) Discard(n int) (int, error) { ... } func (b *Reader) Read(p []byte) (int, error) { ... } func (b *Reader) ReadByte() (byte, error) { ... } func (b *Reader) UnreadByte() error { ... } func (b *Reader) ReadRune() (rune, int, error) { ... } func (b *Reader) UnreadRune() { ... } func (b *Reader) Buffered() int { .. } func (b *Reader) ReadSlice(delim byte) ([]byte, error) { ... } func (b *Reader) ReadLine() ([]byte, bool, error) { ... } func (b *Reader) ReadBytes(delim byte) ([]byte, error) { ... } func (b *Reader) ReadString(delim byte) (string, error) { ... } func (b *Reader) WriteTo(w io.Writer) (int64, error) { ... } 在 Reader 结构体中，buf 用于存储数据的字节切片，在读取时将数据存储在这个缓冲区中，以减少对底层 io.Reader 的实际读取次数，rd 用于存储 Reader 使用的底层数据源，它是一个实现了 io.Reader 接口的对象，r、w 用于跟踪缓冲区的读写状态，lastByte 用于存储最后一个读取的字节，lastRuneSize 用于记录最后读取的一个 Unicode 字符的大小。通过 lastByte 和 lastRuneSize 可以将最后一个字节或 Unicode 字符放回缓冲区，以便后续的读取操作能够重新读取该字节。\nPeek 方法在不消费数据的情况下返回接下来 n 个字节的数据，当 n 大于缓存 Reader 缓存区大小时，则最多返回缓存区大小的数据。Discard 方法跳过接下来 n 个字节的数据，不同于 Peek 方法，在不发生错误的前提下，Discard 方法一定会跳过 n 个字节的数据。Read 方法读取 n 个字节至指定数组中，在 Reader 中存在缓存数据时，会直接将缓存的数据拷贝至指定数组，且不额外读取新的数据，当 Reader 中不存在缓存数据时，当指定数组的字节大小大于 Reader 的缓冲区大小时，直接调用内部 io.Reader 提供的方法读取一次数据至指定数组，避免内存拷贝开销，当指定数组的字节大小小于 Reader 的缓冲区大小时，调用内部 io.Reader 提供的方法读取一次数据至缓冲区，并将缓冲区的数据再次拷贝至指定数组。值得一提的是，Read 方法最多只会调用内部 io.Reader 的接口读取一次，不保障一定能读出数据，而之前提到的 Peek 方法和 Discard 方法由于内部使用了循环，至少保障能读出一次数据（若循环次数大于内部设定的值，则也无法读出数据）。\nReadByte 和 ReadRune 方法类似，在不发生错误的前提下，循环填充缓冲区，以至能够缓冲区中的数据能够拷贝返回一个字节的数据或是 Unicode 字符。UnreadByte 和 UnReadRune 方法用于将消费的最后一个字节数据或 Unicode 字符放回缓冲区，以便后续的读取操作能够重新读取该字节数据或 Unicode 字符。\nReadSlice 方法用以从输入流中读取以指定字节为分割符的一行数据，循环调用内部 io.Reader 提供的方法填充缓冲区，直至出现指定字符、填满缓冲区或出现错误时返回数据，扫描指定字符时会在每次循环更新扫描开始位置，确保不重复扫描同一个数据区域。ReadLine 方法用于从输入流中处理以换行符 \u0026lsquo;\\r\u0026rsquo; 和 \u0026lsquo;\\n\u0026rsquo; 结尾的一行数据，并自动去除换行符，当缓冲区满时，如果数据以 \u0026lsquo;\\r\u0026rsquo; 结尾，则可能存在 \u0026lsquo;\\r\u0026rsquo; 和 \u0026lsquo;\\n\u0026rsquo; 跨越缓冲区的情况，会将 \u0026lsquo;\\r\u0026rsquo; 放回缓冲区。ReadSlice 方法当缓冲区填满时即时没有出现指定字符也会返回，ReadBytes 方法循环调用 ReadSlice 直至出现指定字符，并将多次读取的数据拼接成一个完成的数据返回。ReadString 方法类似，但返回的不是字节数组而是字符串类型。\n上述提到的所有方法有些是返回缓冲区的引用，有些需要将缓冲区的数据进行拷贝。具体来说，Peek、ReadSlice、ReadLine 实现了零拷贝，Read、ReadByte、ReadRune、ReadBytes、ReadString 需要额外一次内存拷贝。\nWriteTo 方法用于将 Reader 的所有数据写入实现 io.Writer 接口的对象中，该方法首先将缓存中的数据写入，如果 Reader 内部的 io.Reader 实现了 WriterTo 方法，则直接调用内部 io.Reader 的 WriterTo 方法完成后续流程，如果传入的实现了 io.Writer 接口的对象 实现了 ReaderFrom 方法，则直接通过该 ReadFrom 方法完成后续流程，否则循环填充缓存，并将缓存中的数据写入，直至遇到 io.EOF 错误写入所有数据。\n# 3.2 Writer 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 package bufio type Writer struct { err error buf []byte n int wr io.Writer } func NewWriterSize(w io.Writer, size int) *Writer { ... } func NewWriter(w io.Writer) *Writer { ... } func (b *Writer) Size() int { ... } func (b *Writer) Reset(w io.Writer) { ... } func (b *Writer) Flush() error { ... } func (b *Writer) Available() int { ... } func (b *Writer) AvailableBuffer() []byte { ... } func (b *Writer) Buffered() int { ... } func (b *Writer) Write(p []byte) (int, error) { ... } func (b *Writer) WriteByte(c byte) error { ... } func (b *Writer) WriteRune(r rune) (int, error) { ... } func (b *Writer) WriteString(s string) (int, error) { ... } func (b *Writer) ReadFrom(r io.Reader) (int64, error) { ... } Writer 的实现相对简单，err 记录读写过程中的错误，buf 用于写入缓存，n 用于记录缓存的字节数，wr 记录封装的 io.Writer。Writer 缓存的默认大小为 4096 Bytes，且在创建完成后大小不会发生变化。Flush 函数用于将 Writer 缓存的数据写入内部的 io.Writer。Write、WriteByte、WriteRune、WriteString 函数用于写入指定的数据，在写入过程中，会首先尝试填充缓存，并当缓存满的时候调用 Flush 并循环直至需要写入的所有数据均以写入缓存或写入内部的 io.Writer，并且在过程中发现需要写入的数据过大时会将数据直接写入内部的 io.Writer，避免拷贝带来的过大开销。ReadFrom 函数用于从一个数据源读取数据，并将获取的数据写入，在读取过程中会首先将读取的数据写入缓存，并当缓存的数据全部写入后，通过内部的 io.Writer 实现的 ReadFrom 函数继续剩余的过程。\n1 2 3 func (b *Writer) AvailableBuffer() []byte { return b.buf[b.n:][:0] } AvailableBuffer 方法提供了一种零拷贝的写入方法，这个函数的目的是返回一个空的缓冲区，其容量等于 Writer 缓存未被填满的空间。通过这个方法，调用者可以在 Writer 缓存中直接追加数据，从而避免其他写入方法带来的额外一次内存拷贝。需要注意的是，函数返回的缓冲区仅在下一次写入操作之前有效，否则会引入数据错乱。\n# 3.3 ReadWriter 1 2 3 4 5 6 7 8 package bufio type ReadWriter struct { *Reader *Writer } func NewReadWriter(r *Reader, w *Writer) *ReadWriter { ... } bufio 包还提供了一个 ReadWriter 结构体，允许将 Reader 和 Writer 作为一个整体来处理读取和写入。\n# 3.4 Scanner bufio 中的 Scanner 类型是一个用于读取文本数据的方便的工具，Scanner 提供了逐行或逐个指定分割符读取文本的能力，并可以通过自定义的 SplitFunc 函数来处理不同的分割符。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 package bufio type Scanner struct { r io.Reader split SplitFunc maxTokenSize int token []byte buf []byte start int end int err error empties int scanCalled bool done bool } type SplitFunc func(data []byte, atEOF bool) (int, []byte, error) func ScanBytes(data []byte, atEOF bool) (int, []byte, error) { ... } func ScanRunes(data []byte, atEOF bool) (int, []byte, error) { ... } func ScanLines(data []byte, atEOF bool) (int, []byte, error) { ... } func ScanWords(data []byte, atEOF bool) (int, []byte, error) { ... } func NewScanner(r io.Reader) *Scanner { ... } func (s *Scanner) Err() error { ... } func (s *Scanner) Buffer(buf []byte, max int) { ... } func (s *Scanner) Split(split SplitFunc) { ... } func (s *Scanner) Bytes() []byte { ... } func (s *Scanner) Text() string { ... } func (s *Scanner) Scan() bool { ... } Scanner 结构体中 r 记录 io.Reader 输入流，通过这个输入流读取数据进行扫描，split 记录定义如何分割输入文本数据的函数，maxTokenSize 记录 token 的最大大小，token 记录最后一个被 split 函数返回的 token，buf 一个用作参数传递给 split 函数的缓冲区，buf 保存了从输入流中读取的数据，start 表示 buf 中第一个未处理字节的位置，end 表示 buf 中数据的结束位置，err 记录潜在的错误，empties 记录连续空 token 的次数，scanCalled 标记是否调用过 Scan 方法，done 表示是否扫描结束。\n在 bufio 包中提供了四种 SplitFunc 实现，分别是 ScanBytes、ScanRunes、ScanLines 和 ScanWords，默认情况下通过 NewScanner 创建的 Scanner 会使用 ScanLines。通过 Buffer 和 Split 方法可以修改 Scanner 所使用的缓冲区、token 的最大大小以及所使用的 SplitFunc。Bytes 和 Text 方法返回最后一个记录的 token。\nScan 方法是 Scanner 结构体的核心方法，它通过循环直到生成一个 token 或者扫描结束。在循环过程中，它首先尝试通过缓存中的已有数据生成 token，如果缓冲区数据遇到错误无法生成 token则返回错误，如果需要更多数据，首先判断当前缓冲区的使用情况，如果当前缓冲区前半部分有很多空闲空间或缓冲区已满则将数据移动到缓冲区的开始位置，如果缓冲区仍然填满，则成倍扩大缓冲区的大小，然后通过循环内部 io.Reader 的接口获取一次数据，如果连续取到空数据的次数超过阈值，则返回错误。Scan 方法的主要逻辑是不断从输入流中读取数据，并使用 split 函数生成 token，直到遇到 io.EOF 错误或其他错误为止，在这个过程中，会通过成倍扩大缓冲区大小不断调整缓冲区大小以适应输入数据。\nScanner 结构体提供的 Scan 方法与 Reader 结构体提供的 ReadBytes 方法类似，均可以实现相似的功能，Scan 方法提供了更高度定制的分割行为以及对错误的处理，在某些简单的读取场景，使用 ReadBytes 方法可能更为方便。\n","date":"2023-11-26T00:00:00Z","permalink":"https://zjregee.github.io/blog/p/go/","title":"Golang 源码阅读笔记"},{"content":" 本文是 mini 系列的第六篇文章，mini 系列是一些知名框架或技术的最小化实现，本系列文章仅作为学习积累的目的，代码或架构在很大程度上参考了现有的一些源码或博客。Monoio 是字节跳动开源的不同于 Tokio 设计的 Rust 异步运行时实现，本文根据其官方教程介绍基于 thread-per-core 模型的异步运行时示例。\nMonoio 项目地址：https://github.com/bytedance/monoio\nmini-monoio 代码实现地址：https://github.com/zjregee/mini/mini-monoio\n# 一、Rust 异步机制 Rust 中的异步机制通过 Async + Await 语法糖，在 HIR 阶段被展开为 Generator 语法，然后 Generator 又会在 MIR 阶段展开成状态机，生成结构最终实现 Future trait，从而可供异步运行时调度。Rust 通过 Future trait 描述状态机对外暴露的接口，异步任务的本质就是实现 Future trait 的状态机，程序可以利用 poll 方法推动状态机执行，poll 方法会告诉程序现在遇到阻塞，或是任务执行完毕返回结果。\n程序由计算逻辑和 IO 组成，异步运行时的本质在于如何高效地和操作系统交互，协调表达计算逻辑和 IO 之间的关系。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 async fn do_http() -\u0026gt; i32 { 1 } fn do_http() -\u0026gt; DOHTTPFuture { DoHTTPFuture } struct DoHTTPFuture; impl Future for DoHTTPFuture { type Output = i32; fn poll(self: Pin\u0026lt;\u0026amp;mut Self\u0026gt;, _cx: \u0026amp;mut Context\u0026lt;\u0026#39;_\u0026gt;) -\u0026gt; Poll\u0026lt;Self::Output\u0026gt; { Poll::Ready(1) } } 上面的代码示例是一种等价的写法，我们可以手动实现一些实现 Future trait 的值，异步函数也会由编译器自动生成返回一个实现 Future trait 的匿名结构。上面的例子较为简单，一旦涉及到 await，本质上异步任务就变成了一个状态机，每次 await 代表一次状态转换。在 await 调用时，线程不会在此等待，而是保存当前的状态以供下次恢复并执行其他任务。\n# 1.1 异步 IO 支撑 为了实现异步运行时所期望的异步并发能力，即在等待 IO 完成的过程中能够处理其他任务，我们需要操作系统内核提供相应的能力。提供异步 IO 能力的常见方法包括两种：epoll 和 io_uring。epoll 是 Linux 中优秀的 IO 事件通知机制，可以同时监听多个 fd 的状态，实现非阻塞的 IO 操作。io_uring 是更为先进的异步 syscall 机制，其主要特点包括：零拷贝，减少数据在用户空间和内核空间之间的复制次数，提高性能；高性能事件通知，相比 epoll 提供了更高效的事件通知机制及多种事件类型支持；批处理操作，io_uring 支持批处理操作，允许应用程序将多个 IO 操作一次性提交给内核，从而减少系统调用的开销。\n异步 IO 对于异步运行时的性能是非常重要的，在 Tokio 官网中也提到过在读取大量文件这一看起来适合异步运行时这一场景，由于操作系统通常不提供异步文件 API，Tokio 相比于普通线程池没有任何优势。此外，值得一体的是 epoll 并不能真正的提供异步 IO 能力。\n# 1.2 Reactor 模式 vs Proactor 模式 在基于系统提供的异步 IO 能力之上，Reactor 模式和 Proactor 模式是两种常用的用于处理并发 IO 操作的设计模式，它们分别采用了不同的方式来处理事件和异步操作。Reactor 模式基于事件驱动，由一个中心化的事件分发器负责监听并分发事件。在 Reactor 模式中，事件分发器通常是同步的，在一个主循环中等待事件的发生，然后分发事件给相应的处理器。处理器负责处理 IO 事件，包括接受连接、读取数据、写入数据等，每个事件类型都有对应的处理器。Proactor 模式也是事件驱动的，但它采用异步的方式。在 Proactor 模式中，发起 IO 操作后，系统会异步地通知操作完成。Proactor 模式中有一个中心化的 IO 完成处理器负责等待异步 IO 操作完成的通知，并在操作完成后调用相应的回调函数。两者的根本区别在于 Reactor 模式强调同步事件分发，处理器直接负责底层 IO。Proactor 模式强调异步 IO 操作，IO 完成处理器负责等待通知并调用回调函数，处理器无需直接关注底层 IO。\n# 1.3 异步运行时组件梳理 异步运行时大体上可以分为两个组件，Executor 模块和 Reactor 模块。Executor 模块包含执行器和任务队列，它的工作就是不断的推动任务运行，当所有的任务执行完毕必须等待时，把执行权交给 Reactor 模块。Reactor 模块负责与操作系统交互，管理注册的 IO，并等待 IO 就绪，还需要把 IO 所关联的任务唤醒重新加入 Executor 模块的任务队列中。由于 IO 要通过异步运行时管理，因此，在异步编程中不能直接使用 Rust 标准中的 IO 函数，而是需要通过使用异步运行时提供的 IO 函数来实现异步 IO。异步运行时提供的 IO 函数不仅会将 IO 通过 Reactor 模块注册，还会通过异步任务上下文所携带的 waker 来唤醒任务将异步任务重新执行。\n# 二、Monoio 设计要点 Monoio 是字节跳动根据自身业务需求实现并开源的 Rust 异步运行时，旨在兼顾平台兼容性的情况下，实现高效的 thread-per-core Rust 异步运行时。本章内容结合 Monoio 提供的官方博客以及文档介绍 Monoio 的设计要点。\n# 2.1 基于 GAT 的生命周期租借 不同于常见的基于 epoll 异步 IO 的 Rust 异步运行时，Monoio 基于 io_uring 实现 Rust 异步运行时。epoll 和 io_uring 的一个主要区别在于 epoll 是一种基于就绪状态的通知，而 io_uring 是一种基于完成的通知。基于就绪状态的通知模式，任务会通过 epoll 等待并感知 IO 就绪，并在就绪时再执行 syscall。使用 io_uring 可以减少 syscall 的使用，从而减少上下文切换次数。除此之外，io_uring 允许用户和内核共享两个无锁队列，其中一个无锁队列实现用户态程序写，内核态消费，另一个无锁队列实现内核态写，用户态消费，从而实现零拷贝减少内核中数据拷贝。\n这两种模式的差异会很大程度上影响异步运行的设计和 IO 接口。在第一种模式下，等待时不需要持有 buffer，只有执行 syscall 的时候才需要 buffer，所以这种模式下可以允许用户在真正执行 syscall 的时候传入 \u0026amp;mut Buffer；而在第二种模式下，在将 IO 请求提交给内核后，内核可以在任何时候访问 buffer，必须确保该 IO 请求返回前 buffer 的有效性，这种情况下无法通过 Rust 编译器实现生命周期检查。为了解决这个问题，异步运行时需要捕获 buffer 的所有权，从而保证 buffer 的有效性。Monoio 通过 GAT 实现生命周期租借来保证 buffer 的有效性。\nGAT 是 Rust 编程语言中一个新特性，它允许在 trait 中定义关联类型时使用泛型参数。在引入 GAT 之前，trait 中的关联类型不能直接依赖于 trait 的泛型参数，这导致了一些限制，GAT 可以帮助编写更通用、灵活和类型安全的代码。\n# 2.2 thread-per-core 模型 基于任务窃取策略的异步运行时可以较为充分地利用 CPU，应对通用场景可以做到较好的性能。同时跨线程任务调度会带来额外开销，且对 Task 本身有 Send 和 Sync 约束，导致无法很好地使用 thread local storage。实际应用中很多场景并不需要跨线程调度，如 nginx 负载均衡代理可以通过 thread-per-core 模型实现，这样不仅可以减少跨线程通信的开销，提高性能，也可以尽可能地利用 thread local 来做极低成本的任务间通信。基于 thread-per-core 模型的运行时特点包括：所有任务在固定线程运行，没有任务窃取；任务队列为 thread local 数据结构操作无锁无竞争；对于特定场景，如网关代理，更容易充分利用硬件性能，做到比较好的水平扩展性。\n# 2.3 跨线程能力支持 thread-per-core 模型不代表没有跨线程能力，用户依然可以使用跨线程共享的数据结构，并且 Monoio 提供了跨线程等待的能力。跨线程等待的本质是在别的线程唤醒本线程的任务，Monoio 在 waker 中标记任务的所有权，如果当前线程并不是任务所属线程，那么 Monoio 通过无锁队列将任务发送到其所属线程上并唤醒。除了提供跨线程等待能力外，Monoio 也提供了 spawn_blocking 能力，供用户执行较重的计算逻辑，以免影响到同线程的其他任务。\n# 2.4 异步运行时兼容 通过二次封装增加内存拷贝开销来兼容其他异步运行时，从而兼容其他运行异步运行时的生态。\n# 三、mini-monoio 实现 # 3.1 Reactor 模块 mini-monoio 通过 polling crate 完成 epoll 操作实现 Reactor 模式。Reactor 数据结构和核心方法如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 pub struct Reactor { poller: Poller, waker_mapping: rustc_hash::FxHashMap\u0026lt;u64, Waker\u0026gt;, buffer: Vec\u0026lt;Event\u0026gt;, } impl Reactor { pub fn add(\u0026amp;mut self, fd: RawFd) { ... } pub fn modify_readable(\u0026amp;mut self, fd: RawFd, cx: \u0026amp;mut Context) { ... } pub fn modify_writable(\u0026amp;mut self, fd: RawFd, cx: \u0026amp;mut Context) { ... } pub fn delete(\u0026amp;mut self, fd: RawFd) { ... } pub fn wait(\u0026amp;mut self) { ... } } Reactor 数据结构使用 HashMap 管理事件对应的 waker，Poller 是对 epoll 操作的封装，buffer 用于存储已经完成待处理的事件。在 mini-monoio 的实现中，由于只关心读和写，并且 TCP 连接是全双工的，同一个 fd 上的读写无关，可以对应不同的 waker，将对 fd 的读事件表示为 fd * 2，对 fd 的写事件表示为 fd * 2 + 1。\n这里可以通过 slab 减少内存频繁分配和释放带来的开销，slab 是一个用于分配和管理连续内存块的分配器，用于管理大小相等的内存块，这些内存块通常用于存储相同类型的数据结构。\nadd、modify_readable、modify_writeable、delete 用于设置所感兴趣的事件与 waker 之间的对应关系。当没有任务需要执行需要等待 IO 的情况下，wait 函数用于收割通过 Poller 管理并已经完成的事件，并通过事件对应的 waker 唤醒相应任务重新执行。\n# 3.2 Executor 模块 任务定义\n异步任务对应一个 Future，因为不知道 Future 的具体类型，所以这里通过 LocalBoxFuture 存储。\n1 2 3 pub struct Task { future: RefCell\u0026lt;LocalBoxFuture\u0026lt;\u0026#39;static, ()\u0026gt;\u0026gt;, } 工作队列定义\n通过 VecDeque 实现工作队列，因为 mini-monoio 所采用的 per-thread-core 模型，所以这里只需要通过 Rc 管理任务，而不需要考虑跨线程。\n1 2 3 pub struct TaskQueue { queue: RefCell\u0026lt;VecDeque\u0026lt;Rc\u0026lt;Task\u0026gt;\u0026gt;\u0026gt;, } waker 定义\nwaker 需要实现函数的动态分发，并手动维护任务的引用计数，在此略过，具体细节可参考本文参考资料。\n1 2 3 4 5 6 7 8 9 impl Task { fn wake_(self: Rc\u0026lt;Self\u0026gt;) { Self::wake_by_ref_(\u0026amp;self) } fn wake_by_ref_(self: \u0026amp;Rc\u0026lt;Self\u0026gt;) { EX.with(|ex| ex.local_queue.push(self.clone())); } } 在实现 waker 的动态分发的基础上，任务需要实现相应的 wake 函数，以供需要重新调度任务时将任务推送入工作队列中。\nExecutor 实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 scoped_tls::scoped_thread_local!(pub(crate) static EX: Executor); pub struct Executor { local_queue: TaskQueue, pub(crate) reactor: Rc\u0026lt;RefCell\u0026lt;Reactor\u0026gt;\u0026gt;, _marker: PhantomData\u0026lt;Rc\u0026lt;()\u0026gt;\u0026gt;, } impl Executor { pub fn spawn(fut: impl Future\u0026lt;Output = ()\u0026gt; + \u0026#39;static) { ... } pub fn block_on\u0026lt;F, T, O\u0026gt;(\u0026amp;self, f: F) -\u0026gt; O where F: Fn() -\u0026gt; T, T: Future\u0026lt;Output = O\u0026gt; + \u0026#39;static, { let _waker = waker_fn::waker_fn(|| {}); let cx = \u0026amp;mut Context::from_waker(\u0026amp;_waker); EX.set(self, || { let fut = f(); pin_utils::pin_mut!(fut); loop { if let std::task::Poll::Ready(t) = fut.as_mut().poll(cx) { break t; } while let Some(t) = self.local_queue.pop() { let future = t.future.borrow_mut(); let w = waker(t.clone()); let mut context = Context::from_waker(\u0026amp;w); let _ = Pin::new(future).as_mut().poll(\u0026amp;mut context); } if let std::task::Poll::Ready(t) = fut.as_mut().poll(cx) { break t; } self.reactor.borrow_mut().wait(); } }) } } 由于每个工作线程都会有各自的 Executor 数据结构，所以这里通过 scoped_tls crate 实现 local thread storage。Executor 数据结构包括一个任务队列，对应的 reactor 数据结构。PhantomData 用于确保 Executor 不能实现 Send 和 Sync， 从而存在跨线程传输或访问的风险。\nExecutor 数据结构的核心接口包括 spawn 和 block_on 函数。spawn 函数将传入的异步任务 Future 包装后推送入工作队列。block_on 函数是异步运行时的主循环入口，它首先创建一个虚拟的 waker 对象用来创建异步运行时的执行上下文，这个虚拟的 waker 对象本身不做任何事情，然后在当前线程循环执行工作队列中的任务以及等待 IO，当传入的异步任务完成后退出。这里利用 pin_utils crate 宏创建 Pin 指针，确保异步任务不会在运行中移动。\n# 3.3 IO 组件实现 这里实现了一个适配 mini-monoio 的 TcpStream IO 组件，通过为其适配 tokio::io::AsyncRead 和 tokio::io::AsyncWrite trait，并将相应的异步 IO 任务挂载至 mini-monoio 的 Reactor 模块，从而支持由 mini-monoio 推动整个异步流程的进行。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 pub struct TcpStream { stream: StdTcpStream, } impl From\u0026lt;StdTcpStream\u0026gt; for TcpStream { fn from(stream: StdTcpStream) -\u0026gt; Self { let reactor = get_reactor(); reactor.borrow_mut().add(stream.as_raw_fd()); Self { stream } } } impl Drop for TcpStream { fn drop(\u0026amp;mut self) { let reactor = get_reactor(); reactor.borrow_mut().delete(self.stream.as_raw_fd()); } } impl tokio::io::AsyncRead for TcpStream { fn poll_read( mut self: std::pin::Pin\u0026lt;\u0026amp;mut Self\u0026gt;, cx: \u0026amp;mut std::task::Context\u0026lt;\u0026#39;_\u0026gt;, buf: \u0026amp;mut tokio::io::ReadBuf\u0026lt;\u0026#39;_\u0026gt;, ) -\u0026gt; Poll\u0026lt;io::Result\u0026lt;()\u0026gt;\u0026gt; { ... } } impl tokio::io::AsyncWrite for TcpStream { fn poll_write( mut self: std::pin::Pin\u0026lt;\u0026amp;mut Self\u0026gt;, cx: \u0026amp;mut std::task::Context\u0026lt;\u0026#39;_\u0026gt;, buf: \u0026amp;[u8], ) -\u0026gt; Poll\u0026lt;Result\u0026lt;usize, io::Error\u0026gt;\u0026gt; { ... } fn poll_flush( self: std::pin::Pin\u0026lt;\u0026amp;mut Self\u0026gt;, cx: \u0026amp;mut std::task::Context\u0026lt;\u0026#39;_\u0026gt;, ) -\u0026gt; Poll\u0026lt;Result\u0026lt;(), io::Error\u0026gt;\u0026gt; { ... } fn poll_shutdown( self: std::pin::Pin\u0026lt;\u0026amp;mut Self\u0026gt;, cx: \u0026amp;mut std::task::Context\u0026lt;\u0026#39;_\u0026gt;, ) -\u0026gt; Poll\u0026lt;Result\u0026lt;(), io::Error\u0026gt;\u0026gt; { ... } } # 参考资料 https://www.cloudwego.io/zh/blog/2023/04/17/%E5%AD%97%E8%8A%82%E5%BC%80%E6%BA%90-monoio-%E5%9F%BA%E4%BA%8E-io-uring-%E7%9A%84%E9%AB%98%E6%80%A7%E8%83%BD-rust-runtime/ https://www.ihcblog.com/rust-runtime-design-1/ https://rustmagazine.github.io/rust_magazine_2021/chapter_12/monoio.html ","date":"2023-11-14T00:00:00Z","permalink":"https://zjregee.github.io/blog/p/mini-monoio/","title":"基于 thread-per-core 模型的 Rust 异步运行时 mini-monoio 实现示例"},{"content":" # 一、异步编程抽象 异步编程是一种编程模型，用于处理非阻塞的、并发的操作，旨在提高程序性能和资源利用率。在传统的同步编程中，每个操作都会等待上一个操作完成后再执行，而在异步编程中，程序可以继续执行其他操作，而不必等待当前操作完成，这使得程序可以在处理 I/O 操作和网络请求等耗时操作时更加高效。\n异步编程是一个相对于同步编程的概念，与多线程编程存在一定的关联与区别。这一点，会在后续对 Rust 异步运行时的实现探秘中有更加深刻的理解。简单且不完全的来说，异步编程可以是单线程，也可以是多线程。多线程编程模型聚焦于线程同步、共享资源访问等问题。两者有相似的概念和实现，也有各自不同的聚焦问题，不同的解决方案。虽然不是等同的概念，但可以结合使用以发挥各自的优势。\n在不同的编程语言中，异步编程的实现方式各有不同。常见的异步编程抽象包括 Callbacks、Promises/Futures、Async/Await 等。\n# 1.1 Callbacks 基于 Callbacks 的异步编程是一种处理异步操作的编程范式，它通过在异步任务完成时调用预定义的回调函数来处理结果。这种模式通常用于事件驱动的环境，例如用户界面开发等。在基于 Callbacks 的异步编程中，启动异步操作的同时会在异步操作中注册一个用于处理操作完成后结果的回调函数。启动异步操作的线程不等待异步任务完成，而继续执行其他操作。当异步任务完成时，系统调用事先注册的回调函数，并将结果传递给该函数。这种异步编程模式存在的主要问题在于实际开发中很容易因为各种需求而实现多层复杂嵌套的回调，这种被称为回调地狱的代码通常难以维护，可读性差。下面是一个在 C++ 中实现基于 Callbacks 的异步编程的示例。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #include \u0026lt;thread\u0026gt; #include \u0026lt;functional\u0026gt; void async_task(const std::function\u0026lt;void(int, const std::string\u0026amp;)\u0026gt;\u0026amp; callback) { std::this_thread::sleep_for(std::chrono::seconds(2)); int error_code = 0; std::string result = \u0026#34;\u0026#34;; callback(error, result); } void handle_data(int err_code, const std::string\u0026amp; result) { ... } int main() { std::thread(async_task, handle_data).detach(); ... return 0; } # 1.2 Futures/Promises Futures/Promises 是异步编程中的一个经典解决方案，在诸多编程语言和框架中得到了广泛的应用。\nFuture 是一种表示异步操作结果的对象，通常表示一个尚未完成的操作，它代表了一个可能在将来完成的值。Future 提供了一种非阻塞的方式，允许程序继续执行其他任务而不用等待完成。Future 可以有三种状态：未完成、已完成成功、已完成失败。每一个异步操作返回一个 Future 对象，可以在需要的时候获取结果。Future 是只读的，可以注册回调函数，以便在 Future 完成时执行特定的操作。\nPromise 是一种表示异步操作的进行中状态的对象，用于控制 Future 的状态。Promise 对象可以用来设置 Future 的结果，一旦 Promise 设置了结果，与之相关的 Future 就会被通知，并触发相应的回调函数。Future 是可写的，可以通过接口改变状态。\nFuture 和 Promise 的设计理念整体上非常相似，在不同编程语言和框架中所实现的异步编程中的概念处理上存在一定区别。一般来说，Future 可以视为异步任务的返回值，表示一个未来值的占位符，Promise 表示异步任务的执行过程，表示一个值的生产过程。将异步操作分成 Future 和 Promise 两个部分的主要原因是为了实现读写分离，对外部调用者只读，对内部实现可写。下面是在 C++ 中基于 Futures/Promises 实现异步编程的一个示例。在这个示例中，promise 用于设置异步操作的结果，future 用于获取异步操作的结果，异步线程通过 std::thread 启动，主线程通过 future.get() 等待异步操作完成，并获取结果。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 #include \u0026lt;thread\u0026gt; #include \u0026lt;future\u0026gt; int aync_task() { std::this_thread::sleep_for(std::chrono::seconds(2)); return 42; } int main() { std::promise\u0026lt;int\u0026gt; promise; std::future\u0026lt;int\u0026gt; future = promise.get_future(); std::thread async_thread([\u0026amp;promise]() { int result = async_task(); promise.set_value(result); } catch (...) { promise.set_exception(std::current_exception()); }) int result = future.get(); async_thread.join(); return 0; } # 1.3 Async/Await Async/Await 是一种现代编程语言中常见的异步编程模式，在许多编程语言中，也已经成为处理异步操作的主流方式。Async/Await 的设计出发点旨在简化异步编程，提供一种更直观、易读的方式来处理异步操作。Async/Await 可以让异步代码看起来更像同步代码，使得开发者能够使用类似于同步编程的方式编写异步代码，代码流程更加线性，使得理解代码的执行顺序变得更加容易，减少了异步操作带来的复杂性和混乱。\n在基于 Async/Await 的异步编程中，编程语言通常会定义 async 和 await 关键字。async 关键字用于标识一个异步函数，异步函数返回一个 Future，代表一个尚未完成的异步计算。await 关键字用于等待一个 Future 完成，并在其结果可用时继续执行。异步函数可以包含 await 关键字，await 关键字会挂起当前的异步函数，允许其他任务在等待时执行。await 关键字只能在异步函数中使用，因为它会挂起当前的异步函数，而在同步函数中无法实现这种挂起和恢复的机制。下面是在 Python 中基于 Async/Await 实现异步编程的一个示例。\n1 2 3 4 5 6 7 8 9 import asyncio async def async_operation(): await asyncio.sleep(2) async def main(): await async_operation() asyncio.run(main()) # 二、Rust 中的异步运行时 Rust 中的异步编程模型基于 Async/Await 异步编程抽象，且拥有相比于其他主流语言不同的异步运行时实现。在 JavaScript 中，JavaScript 是一种事件驱动、单线程的语言，JavaScript 基于 Async/Await 的异步编程模型通过事件循环实现非阻塞的异步执行。在 Python 中，基于 Async/Await 的异步编程模型通过有栈协程实现，Python 的 asyncio 模块提供了异步运行时，支持异步任务的调度和执行。\nRust 中的 Async/Await 编程模型通过无栈协程实现，并通过第三方异步运行时库来支持，而不是内置于语言本身。在编译时，Rust 会将异步函数自动转换为状态机，状态机的每个状态代表函数的执行状态，await 关键字对应状态机中的一个状态转换。这个过程是在编译时完成的，因此在运行时不会引入额外的性能开销。状态机需要在第三方异步运行时库中得到调度，由异步运行时来推进异步函数的各个部分。相比于其他主流语言，Rust 中的异步运行时通过无锁设计、无栈协程、轻量级运行时和零成本抽象等往往可以得到更好的性能优势。这种设计不仅提高了异步执行的效率，还为开发者提供了更灵活的异步编程选项，以适应不同的应用场景和性能要求。\n有栈协程 vs 无栈协程\n相较于由操作系统内核管理且上下文切换开销大的线程，协程是由程序本身进行调度的轻量级执行单元，协程的切换更加轻量，不涉及操作系统的内核调度。有栈协程和无栈协程是两种协程实现的不同方式，有栈协程由类似于线程栈独立的执行栈，无栈协程不使用独立的执行栈，使用上更轻量。\nRust 开源社区提供了多种成熟的异步运行时实现，其中最流行的框架包括 Tokio、async-std 和 smol。Tokio 是 Rust 中最受欢迎的异步运行时，Tokio 提供了一个强大的异步生态系统，涵盖了网络编程、文件系统操作、定时器、以及其他与异步 I/O 相关的功能，并且得益于 Tokio 所提供的丰富的组件和强大的灵活性，可以使得 Tokio 适用于各种不同类型的异步编程场景。async-std 设计时注重简洁与标准库的一致性，使得开发者可以轻松地将现有代码转换为异步代码。smol 是一个轻量级的异步运行时，他的设计目标是简化异步编程并减少依赖关系，相较于 Tokio 和 async-std，smol 的功能可能更加简化，这也使得它成为一种更加轻便、适用于特定场景的异步运行时选择。\n# 三、走进 Tokio 上一节中已经提到 Tokio 是 Rust 中最常用的异步运行时，它提供了编写网络应用程序所需的构建块，同时提供了针对各种系统的灵活性。从高层次上，Tokio 主要组成部分包括用于执行异步代码的多线程运行时、标准库的异步版本和一个庞大的相关库生态系统。当使用异步方式编写应用程序时，通过减少同时执行许多操作的成本，可以更好的扩展应用程序。然而，异步 Rust 代码不能自己运行，所以必须选择一个运行时来执行它。此外，在编写异步代码时，不能直接使用 Rust 标准库提供的普通阻塞 API，而必须使用由 Tokio 提供的异步版本。Tokio 提供了运行时的多种变体,从多线程、窃取工作的运行时到轻量级的单线程运行时。每个运行时都允许用户根据自己的需要进行调整。并且 Tokio 的诸多功能，例如 TCP、UDP、Unix 套接字、计时器、同步使用程序等，可以根据应用程序所需要的特性选择，从而优化编译时间或最终程序占用的空间。\n尽管 Tokio 对于需要同时做很多事情的项目很有用，但也有如下的诸多情况不适合使用 Tokio：\n通过在多个线程上并行运行，加速 CPU 密集型计算。Tokio 是为 IO 绑定应用程序设计的，其中每个单独的任务花费大部分时间等待 IO。如果应用程序所做的唯一事情是并行运行计算，那么可以使用 Rayon。 读取大量文件。虽然看起来 Tokio 对于只需要读取大量文件的项目很有用，但是与普通线程池相比，Tokio 在这种情况下没有提供任何优势，这是因为操作系统通常不提供异步文件 API。 发送单个 web 请求。如果需要使用一个异步 Rust 库，比如 reqwest，但是不需要一次做很多事情，使用这个库的阻塞版本会让项目更简单。Tokio 仍然可以工作，但是相比阻塞 API 没有真正的优势。 # 3.1 Hello Tokio 1 2 3 4 5 6 7 8 9 10 use mini_redis::{client, Result}; #[tokio::main] async fn main() -\u0026gt; Result\u0026lt;()\u0026gt; { let mut client = client::connect(\u0026#34;127.0.0.1:6379\u0026#34;).await?; client.set(\u0026#34;hello\u0026#34;, \u0026#34;world\u0026#34;.into()).await?; let result = client.get(\u0026#34;hello\u0026#34;).await?; println!(\u0026#34;got value from the server; result={:?}\u0026#34;, result); Ok(()) } 使用异步编程，不能立即完成的操作被挂起到后台。线程没有被阻塞，并且可以继续运行其他事情。一旦操作完成，任务将被解除挂起，并从它停止的地方继续处理。如上的示例只有一个任务，因此在挂起期间什么也不会发生，但是异步程序通常有许多这样的任务。\n在 async 函数中对 .await 的任何调用都会将控制返回给线程。当操作在后台进行时，线程可以做其他工作。Rust 的异步操作是惰性的，这导致了与其他语言不同的运行时语义。异步函数像其他 Rust 函数一样被调用。然而，调用这些函数并不会导致函数体的执行。相反，调用 async 函数返回一个表示操作的值。这在概念上类似于零参数闭包。要实际运行该操作，应对返回值使用 .await 操作符。async 函数的返回值是实现 Future trait 的匿名类型。\n1 2 3 4 5 6 7 8 9 10 11 #[tokio::main] async fn main() { println!(\u0026#34;hello\u0026#34;); } fn main() { let mut rt = tokio::runtime::Runtime::new().unwrap(); rt.block_on(async { println!(\u0026#34;hello\u0026#34;); }) } 用于启动应用程序的主函数不同于大多数 Rust 代码中常见的函数，它是一个 async 函数，并且带有 #[tokio::main] 标注。当我们想要进入异步上下文时，使用 async fn。然而，异步函数必须由运行时执行。运行时包含异步任务调度器，提供事件 I/O，计时器等。运行时不会自动启动，所以 main 函数需要启动它。#[tokio::main] 函数是一个宏，它将 async fn main() 转换为初始化运行时实例并执行 async main 函数的同步 fn main()。\n# 3.2 Spawning 并发性和并行性不是一回事。如果在两个任务之间交替进行，那么只是在同时处理两个任务，但不是并行的。使用 Tokio 的优点之一是异步代码允许并发地处理许多任务，而不必使用普通线程并行地处理它们。事实上，Tokio 可以在一个线程上并发地运行多个任务。\n一个 Tokio 任务是一个异步的绿色线程，它们是通过传递一个异步块给 tokio::spawn 来创建的。spawn 函数返回一个 JoinHandle，调用者可以使用它与生成的任务交互。异步块可以有一个返回值，调用者可以使用 JoinHandle 上的 .await 获取返回值。等待 JoinHandle 返回一个结果。当任务在执行过程中遇到错误时，JoinHandle 将返回 Err。当任务出现 panic，或者运行时强制取消任务时，就会发生这种情况。\n绿色线程是一种用户空间线程，由应用程序或运行时系统而不是操作系统内核来管理，相较于传统的操作系统线程更加轻量。绿色线程通过用户空间的协作式调度实现，而非操作系统的线程调度器进行抢占式调度。在协作式调度中，一个绿色线程主动让出执行权给其他线程，而不是强制性地倍系统调度切换。相较于协程，绿色线程是一种更宽泛的概念，而协程通常是一种具体实现，调度方式可以是协作式的，也可以是抢占式的，可以是绿色线程的一种形式。\n任务是调度程序管理的执行单元。生成任务将其提交给 Tokio 调度器，然后确保任务在有工作要做时执行。生成的任务可以在与其生成的线程相同的线程上执行，也可以在不同的运行时线程上执行。任务可以在生成之后在线程之间移动。Tokio 的任务很清凉，在底层，它们只需要单一的分配和 64 字节的内存，应用程序可以自由地生成数千甚至数百万个任务。\n# 3.2.1 \u0026lsquo;static bound 当在 Tokio 运行时上生成任务时，其类型的生成器必须是静态的。这意味着生成的任务必须不包含对任务外部拥有的数据的任何引用。下面的代码存在编译错误，这是因为默认情况下变量不会移动到异步块中，v 数组仍然属于 main 函数。通过使用 task::spawn(async move {}) 可以指示编译器将 v 数组移动到生成的任务中。任务拥有它的所有数据，使它成为 \u0026lsquo;static。如果必须同时从多个任务访问单个数据块，可以使用例如 Arc 之类的同步原语。\n1 2 3 4 5 6 7 8 9 use tokio::task; #[tokio::main] async fn main() { let v = vec![1, 2, 3]; task::spawn(async { println!(\u0026#34;Here\u0026#39;s a vec: {:?}\u0026#34;, v); }); } 一个常见的误解是 \u0026lsquo;static 意味着永远存在，但事实上，一个标记为 \u0026lsquo;static 的值仅仅意味着不存在内存泄漏，意味着永远保持这个值是正确的。这一点很重要，因为编译器无法推断新生成的任务存在了多长时间。通过 \u0026lsquo;static，开发者提供了这项任务能够永远运行下去的保障（当然实际上不会永远运行下去，提供这个保障意味着在开发者看来一直持有这个值是合理的），这样 Tokio 就可以让这项任务能运行多久就运行多久。这部分可以参考 https://github.com/pretzelhammer/rust-blog/blob/master/posts/common-rust-lifetime-misconceptions.md#2-if-t-static-then-t-must-be-valid-for-the-entire-program。\n# 3.2.2 Send bound 由 tokio::spawn 生成的任务必须实现 Send。这允许 Tokio 运行时在任务在 .await 处挂起时在线程之间移动任务。当所有 .await 调用处保存的数据是 Send 的，那么任务就是 Send 的。当任务调用 .await 时，任务将执行权返回给调度程序，下次执行该任务时，任务将从上次返回的点恢复。为了实现这个功能。任务需要保存 .await 处使用的所有状态。如果这些状态是 Send 的，那么任务本身就可以跨线程移动，相反，如果这些状态不是 Send 的，任务就无法满足 Send。\n例如如下代码是正确的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 use tokio::task::yield_now; use std::rc::Rc; #[tokio::main] async fn main() { tokio::spawn(async { { let rc = Rc::new(\u0026#34;hello\u0026#34;); println!(\u0026#34;{}\u0026#34;, rc); } yield_now().await; }); } 而如下代码是错误的：\n1 2 3 4 5 6 7 8 9 10 11 use tokio::task::yield_now; use std::rc::Rc; #[tokio::main] async fn main() { tokio::spawn(async { let rc = Rc::new(\u0026#34;hello\u0026#34;); yield_now().await; println!(\u0026#34;{}\u0026#34;, rc); }); } # 3.3 Shared State 在 Tokio 中有几种不同的方式来共享状态：用互斥锁来保护共享状态；使用一个任务用于管理状态，通过消息传递对其进行保护。通常第一种方法用于简单数据，第二种方法用于需要异步工作的情况（例如 I/O 原语）。在本小节中，示例代码的共享状态是一个 HashMap，操作都不是异步的，可以使用互斥锁。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 use tokio::net::TcpListener; use std::collections::HashMap; use std::sync::{Arc, Mutex}; #[tokio::main] async fn main() { let listener = TcpListener::bind(\u0026#34;127.0.0.1:6379\u0026#34;).await.unwrap(); println!(\u0026#34;Listening\u0026#34;); let db = Arc::new(Mutex::new(HashMap::new())); loop { let (socket, _) = listener.accept().await.unwrap(); let db = db.clone(); println!(\u0026#34;Accepted\u0026#34;); tokio::spawn(async move { process(socket, db).await; }); } } 需要注意的是，上述的代码使用 std::sync::Mutex 而不是 tokio::sync::Mutex 来保护 HashMap。一个常见的错误是在异步代码中无条件地使用 tokio::sync::Mutex，这是一个通过 .await 调用锁定的异步互斥锁。同步互斥锁在等待获取锁时会阻塞当前线程，反过来，这将阻止其他任务的处理，在这种情况下使用异步互斥锁并没有任何帮助，因为异步互斥锁内部同样使用的是同步互斥锁。根据经验，在异步代码中使用同步互斥锁是可行的，只要争用保持在较低的水平，且锁不会在调用 .await 时仍然持有。\n# 3.3.1 tasks，threads and contention 当争用最少时，使用阻塞互斥锁来保护短临界区是一种可接受的策略。当锁被争夺时，执行任务的线程必须阻塞并等待互斥锁。这不仅会阻塞当前任务，还会阻塞当前线程上调度的所有其他任务。默认情况下，Tokio 运行时使用多线程调度器。任务安排在运行时管理的任意数量的线程上。如果计划执行大量任务，并且它们都需要访问互斥锁，那么就会出现争用。如果使用 current_thread 运行时风格的 Tokio 运行时，那么互斥锁将永远不会被争夺。\ncurrent_thread 运行时风格的 Tokio 运行时是轻量级的单线程运行时。当只生成少量任务并打开少量套接字时，这是一个不错的选择。例如，在异步客户端库之上提供同步 API 桥接时，它可以很好地工作。\n如果同步互斥锁的争抢成为一个问题，最好的解决办法很少是切换至 Tokio 互斥锁，通常需要考虑这些优化：切换到专用任务来管理状态和使用消息传递；对互斥对象分片；重构代码以避免互斥。\n# 3.3.2 holding a MutexGuard across an .await 1 2 3 4 5 6 7 use std::sync::{Mutex, MutexGuard}; async fn increment_and_do_stuff(mutex: \u0026amp;Mutex\u0026lt;i32\u0026gt;) { let mut lock: MutexGuard\u0026lt;i32\u0026gt; = mutex.lock().unwrap(); *lock += 1; do_something_async().await; } 上述代码存在错误，因为 std::sync::MutexGuard 类型不是 Send。为了避免这个错误，需要让互斥锁的析构函数在调用 .await 之前运行。修改后的下面的代码是正确的：\n1 2 3 4 5 6 7 async fn increment_and_do_stuff(mutex: \u0026amp;Mutex\u0026lt;i32\u0026gt;) { { let mut lock: MutexGuard\u0026lt;i32\u0026gt; = mutex.lock().unwrap(); *lock += 1; } do_something_async().await; } 下面的代码同样存在错误：\n1 2 3 4 5 6 7 use std::sync::{Mutex, MutexGuard}; async fn increment_and_do_stuff(mutex: \u0026amp;Mutex\u0026lt;i32\u0026gt;) { let mut lock: MutexGuard\u0026lt;i32\u0026gt; = mutex.lock().unwrap(); *lock += 1; drop(lock); do_something_async().await; } 这是因为编译器当前仅根据作用域信息计算 future 是否为 Send。这一点有望在未来进行更新，以支持显式地删除它，但现在必须显式地使用作用域。\n除此之外，事实上问题的另一个根本原因不在于互斥锁有没有实现 Send，不应该试图通过使用某种方式 tokio::spawn 没有实现 Send 的任务。因为如果 Tokio 如果在任务持有锁的情况下挂其任务，其他试图争抢锁的任务可能被安排在同一个线程上执行，这将导致死锁，等待互斥锁的任务将阻止持有互斥锁的任务释放互斥锁。\n重构代码，不要在调用 .await 时持有锁\n之前已经提供了这样的一个代码示例在调用 .await 之前释放锁，还可以通过一些更健壮的方式来实现这一点。例如在如下的代码中，将互斥锁封装在一个结构体中，并且只将互斥锁在该结构体的非异步方法中上锁。这样的设计模式可以保证不会出现 Send 问题，因为互斥锁不会出现在异步函数中的任何地方。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 use std::sync::Mutex; struct CanIncrement { mutex: Mutex\u0026lt;i32\u0026gt;, } impl CanIncrement { fn increment(\u0026amp;self) { let mut lock = self.mutex.lock().unwrap(); *lock += 1; } } async fn increment_and_do_stuff(can_incr: \u0026amp;CanIncrement) { can_incr.increment(); do_something_async().await; } 使用一个任务来管理状态，并使用消息传递对其进行操作\n这种方法通常在共享资源是 I/O 资源时使用。\n使用 Tokio 的异步锁\n异步互斥锁的主要特点是它可以在 .await 中被持有而不会出现任何问题。也就是说，异步互斥锁的开销要比普通互斥锁高，通常最好使用另外两种方法中的一种。\n1 2 3 4 5 6 7 use tokio::sync::Mutex; async fn increment_and_do_stuff(mutex: \u0026amp;Mutex\u0026lt;i32\u0026gt;) { let mut lock = mutex.lock().await; *lock += 1; do_something_async().await; } # 3.4 Channels 1 2 3 4 5 6 7 8 9 10 11 12 13 14 use mini_redis::client; #[tokio::main] async fn main() { let mut client = client::connect(\u0026#34;127.0.0.1:6379\u0026#34;).await.unwrap(); let t1 = tokio::spawn(async { let res = client.get(\u0026#34;foo\u0026#34;).await; }); let t2 = tokio::spawn(async { client.set(\u0026#34;foo\u0026#34;, \u0026#34;bar\u0026#34;.into()).await; }); t1.await.unwrap(); t2.await.unwrap(); } 上面的代码无法编译成功，因为两个任务都需要以某种方式访问 client，由于 client 没有实现 Copy，如果没有一些代码来促进这种共享，它将无法编译。虽然可以为每个任务打开一个连接，但这显然也不是一个理想的方法。在这种情况下也不能使用 std::sync::Mutex，因为需要在持有锁的情况下调用 .await。这里可以使用 Tokio 提供的异步锁，但这只允许一个正在运行的请求。对于诸如 redis 此类实现流水线客户端的场景来收，异步互斥会导致连接利用率不足。\n上述的问题可以通过消息传递解决。使用此策略，管理 client 的任务能够获得独占访问权限，以便调用 get 和 set。此外，channel 还可以用作缓冲区，操作可以在 client 任务繁忙时发送给 client 任务。一旦 client 任务可以处理新请求，它就会从 channel 中提取下一个请求。这可以产生更好的吞吐量，并扩展到支持连接池。\n# 3.4.1 Tokio‘s channel primitives Tokio 提供了许多种 channel，每种 channel 都有不同的用途：mpsc，多生产者，单消费者 channel，可以发送多个值；oneshot，单生产者，单消费者 channel，可以发送单个值；broadcast，多生产者，多消费者 channel，可以发送多个值，每个接收者都能看到每个值；watch，单生产者，多消费者 channel，可以发送多个值，但不保留历史记录，接收方只能看到最近的值。\n如果需要一个多生产者多消费者 channel，其中每条消息只有一个消费者看到，可以使用 async-channel 这个 crate。还有一些 channel 可以在异步 Rust 代码之外使用，比如 std::sync::mpsc 和 crossbeam::channel。这些 channel 通过阻塞线程来等待消息，这在异步代码中是不允许的。\n当每个 Sender 都超出范围或被丢弃，就不可能再向 channel 中发送更多消息。此时，Receiver 上的 recv 调用将返回 None，这意味着所有发送方都已离开并且 channel 已经关闭。oneshot 调用发送不需要 .await。这是因为 oneshot channel 上发送会立即失败或成功，而不需要任何形式的等待。\n# 3.4.2 一次错误理解 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 use bytes::Bytes; use mini_redis::client; use tokio::sync::{mpsc, oneshot}; #[derive(Debug)] enum Command { Get { key: String, resp: Responder\u0026lt;Option\u0026lt;Bytes\u0026gt;\u0026gt;, }, Set { key: String, val: Bytes, resp: Responder\u0026lt;()\u0026gt;, }, } type Responder\u0026lt;T\u0026gt; = oneshot::Sender\u0026lt;mini_redis::Result\u0026lt;T\u0026gt;\u0026gt;; #[tokio::main] async fn main() { let (tx, mut rx) = mpsc::channel(32); let tx2 = tx.clone(); let manager = tokio::spawn(async move { let mut client = client::connect(\u0026#34;127.0.0.1:6379\u0026#34;).await.unwrap(); while let Some(cmd) = rx.recv().await { match cmd { Command::Get { key, resp } =\u0026gt; { let res = client.get(\u0026amp;key).await; let _ = resp.send(res); } Command::Set { key, val, resp } =\u0026gt; { let res = client.set(\u0026amp;key, val).await; // Ignore errors let _ = resp.send(res); } } } }); let t1 = tokio::spawn(async move { let (resp_tx, resp_rx) = oneshot::channel(); let cmd = Command::Get { key: \u0026#34;foo\u0026#34;.to_string(), resp: resp_tx, }; if tx.send(cmd).await.is_err() { eprintln!(\u0026#34;connection task shutdown\u0026#34;); return; } let res = resp_rx.await; println!(\u0026#34;GOT (Get) = {:?}\u0026#34;, res); }); let t2 = tokio::spawn(async move { let (resp_tx, resp_rx) = oneshot::channel(); let cmd = Command::Set { key: \u0026#34;foo\u0026#34;.to_string(), val: \u0026#34;bar\u0026#34;.into(), resp: resp_tx, }; if tx2.send(cmd).await.is_err() { eprintln!(\u0026#34;connection task shutdown\u0026#34;); return; } let res = resp_rx.await; println!(\u0026#34;GOT (Set) = {:?}\u0026#34;, res); }); t1.await.unwrap(); t2.await.unwrap(); manager.await.unwrap(); } 在第一次阅读上面的代码时，我产生了误解，我认为对 t1 调用 .await，由于只能等待 t1 返回，才能运行接下来的代码，但是 t1 又在等待接受消息，所以这个地方会产生死锁。但其实不是这样，tokio::spawn 中的异步代码块不是在对 tokio::spawn 返回的 JoinHandle 调用 .await 时才开始运行的，异步任务已经提交到异步运行时开始运行了，调用 .await 是在等待执行结果。在这里混淆了对 async fn 调用 .await 的惰性执行与异步阻塞。\n# 3.4.2 backpressure and bounded channels 无论何时引入并发性或队列，都必须确保队列是有界的，并且系统能够优雅地处理负载。无界队列最终将填满所有可用内存，并导致系统以不可预测的方式失败。Tokio 注意避免隐形排队，其中很大一部分原因在于异步操作是惰性的。考虑如下的代码：\n1 2 3 loop { async_op(); } 如果异步操作急切地运行，循环将重复地将一个新的 async_op 排在队列中运行，而不确保之前的操作已经完成。这导致隐性无界排队。基于回调的系统和基于渴望 future 的系统特别容易受到这种影响。然而，对于 Tokio 和异步 Rust 代码，上面的代码片段根本不会导致 async_op 运行。这是因为 .await 没有被调用。如果将代码片段更新为使用 .await，则循环在重新开始之前等待操作完成。\n1 2 3 loop { async_op().await; } 必须明确引入并发和队列，可以实现这一点的方法包括 tokio::spawn、select!、join! 和 mpsc::channel 等。这样做时，需要确保并发的总量是有限的。例如，在编写 TCP accept 循环时，确保打开的套接字总数是有限的。当使用 mpsc::channel 时，选择一个可管理的容量。注意并选择好的边界是编写可靠的 Tokio 应用程序的重要部分。\n# 3.5 I/O Tokio 中的 I/O 操作方式与 std 中的基本相同，但是是异步的，有一个用于读取的 trait AsyncRead 和一个用于写入的 trait AsyncWrite。特定类型需要适当地实现这些特征（TcpStream、File 和 Stdout）。AsyncRead 和 AsyncWrite 也已经由许多数据结构实现。\n# 3.5.1 AsyncRead and AsyncWrite 这两个 trait 提供了异步读写字节流的功能，这些 trait 上的方法不会被直接调用，就像不会从 Future trait 中手动调用 poll 方法一样。相反，可以通过 AsyncReadExt 和 AsyncWriteExt 提供的实用程序方法来使用它们。\nasync fn read()\n1 2 3 4 5 6 7 8 9 10 11 use tokio::fs::File; use tokio::io::{self, AsyncReadExt}; #[tokio::main] async fn main() -\u0026gt; io::Result\u0026lt;()\u0026gt; { let mut f = File::open(\u0026#34;foo.txt\u0026#34;).await?; let mut buffer = [0; 10]; let n = f.read(\u0026amp;mut buffer[..]).await?; println!(\u0026#34;The bytes: {:?}\u0026#34;, \u0026amp;buffer[..n]); Ok(()) } AsyncReadExt::read 提供了一个将数据读入缓冲区的异步方法，返回所读的字节数。当 read() 返回 Ok(0) 时，这表示流已经关闭。任何 read() 的进一步调用都将立即以 Ok(0) 完成。对于 TcpStream 实例，这表示套接字的读部分已经关闭。\nasync fn read_to_end()\nAsyncReadExt::read_to_end 从流中读取所有字节，直到 EOF。\nasync fn write()\nAsyncWriteExt::write 将缓冲区写入，返回写入的字节数。\nasync fn write_all()\nAsyncWriteExt::write_all 将整个缓冲区写入。\n# 3.5.2 helper functions 1 2 3 4 5 6 7 8 9 10 use tokio::fs::File; use tokio::io; #[tokio::main] async fn main() -\u0026gt; io::Result\u0026lt;()\u0026gt; { let mut reader: \u0026amp;[u8] = b\u0026#34;hello\u0026#34;; let mut file = File::create(\u0026#34;foo.txt\u0026#34;).await?; io::copy(\u0026amp;mut reader, \u0026amp;mut file).await?; Ok(()) } 此外，就像 std 一样，tokio::io 模块包含许多有用的实用函数以及用于处理标准输入、标准输出和标准错误的 API。例如，tokio::io::copy 异步地将 reader 的全部内容复制到 writer 中。值得注意的是，这里利用了字节数组也实现了 AsyncRead 的事实。\n# 3.5.3 echo server example 在这里将使用两种略微不同的方式实现 echo 服务器。\nusing io::copy()\n1 2 3 4 5 6 7 8 9 10 11 12 13 use tokio::io; use tokio::net::TcpListener; #[tokio::main] async fn main() -\u0026gt; io::Result\u0026lt;()\u0026gt; { let listener = TcpListener::bind(\u0026#34;127.0.0.1:6142\u0026#34;).await?; loop { let (mut socket, _) = listener.accept().await?; tokio::spawn(async move { // copy data here }); } } 在这里只有一个 TcpStream，这个值同时实现了 AsyncRead 和 AsyncWrite。因为 io::copy 对 read 和 write 都要求 \u0026amp;mut，所以套接字不能同时用于两个参数。下面的代码是无法通过编译的：\n1 io::copy(\u0026amp;mut socket, \u0026amp;mut socket).await; splitting a reader + writer\n为了解决这个问题，必须将套接字拆分成一个读句柄和一个写句柄。拆分 reader/writer 的最佳方法取决于特定的类型。任何 reader + write 类型都可以用 io::split 实用程序进行分割。这两个句柄可以独立使用，包括用于单独的任务。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 use tokio::io::{self, AsyncReadExt, AsyncWriteExt}; use tokio::net::TcpStream; #[tokio::main] async fn main() -\u0026gt; io::Result\u0026lt;()\u0026gt; { let socket = TcpStream::connect(\u0026#34;127.0.0.1:6142\u0026#34;).await?; let (mut rd, mut wr) = io::split(socket); tokio::spawn(async move { wr.write_all(b\u0026#34;hello\\r\\n\u0026#34;).await?; wr.write_all(b\u0026#34;world\\r\\n\u0026#34;).await?; Ok::\u0026lt;_, io::Error\u0026gt;(()) }); let mut buf = vec![0; 128]; loop { let n = rd.read(\u0026amp;mut buf).await?; if n == 0 { break; } println!(\u0026#34;GOT {:?}\u0026#34;, \u0026amp;buf[..n]); } Ok(()) } 因为 io::split 支持任何实现 AsyncRead + AsyncWrite 并返回独立句柄的值，所以内部使用 Arc 和 Mutex。这个开销可以通过 TcpStream 来避免。TcpStream 提供了两个专门的拆分函数。TcpStream::split 接受对流的引用，并返回读句柄和写句柄。因为使用了引用，所以两个句柄必须保持在调用 split() 的同一个任务上。这种专门的分割是零成本的，不需要 Arc 或 Mutex。TcpStream 还提供了 into_split，它支持可以跨任务移动的句柄，只需要一个 Arc。\n1 2 3 4 5 6 tokio::spawn(async move { let (mut rd, mut wr) = socket.split(); if io::copy(\u0026amp;mut rd, \u0026amp;mut wr).await.is_err() { eprintln!(\u0026#34;failed to copy\u0026#34;); } }); 因为 io::copy() 是在拥有 TcpStream 的同一个任务上调用的，所以在这里可以使用 TcpStream::split。\nmanual copying\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 use tokio::io::{self, AsyncReadExt, AsyncWriteExt}; use tokio::net::TcpListener; #[tokio::main] async fn main() -\u0026gt; io::Result\u0026lt;()\u0026gt; { let listener = TcpListener::bind(\u0026#34;127.0.0.1:6142\u0026#34;).await?; loop { let (mut socket, _) = listener.accept().await?; tokio::spawn(async move { let mut buf = vec![0; 1024]; loop { match socket.read(\u0026amp;mut buf).await { Ok(0) =\u0026gt; return, Ok(n) =\u0026gt; { if socket.write_all(\u0026amp;buf[..n]).await.is_err() { return; } } Err(_) =\u0026gt; { return; } } } }); } } 由于使用了 AsyncRead 和 AsyncWrite 实用程序，所以必须将拓展 trait 纳入范围。\nallocating a buffer\n避免使用 stack 上分配的缓冲区，.await 调用期间存在的所有任务数据都必须由任务存储。在这个例子中，buf 在 .await 调用中使用。所有任务数据都存储在单个分配中，可以将其视为一个枚举，其中每个变量都是需要为特定的 .await 调用存储的数据。每个接受的套接字生成的任务的内部结构可能如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 struct Task { task: enum { AwaitingRead { socket: TcpStream, buf: [BufferType], }, AwaitingWriteAll { socket: TcpStream, buf: [BufferType], } } } 这会让任务结构变得非常庞大，并且由于缓冲区大小通常是 page 大小，这将使得任务的大小略大于 page 大小，变得非常尴尬。编译器相比基本的枚举类型进一步优化了异步块的布局。实际上，变量不会像基本的枚举类型那样在不同的种类之间移动，但是任务大小仍然至少与最大的变量一样大。基于此，通常更有效的做法是为缓冲区分配专门的内存，而不是使用通用的分配方式。\n# 3.6 Bridging with Sync Code 在之前的使用 Tokio 的诸多示例中，通过 #[tokio::main] 标注了 main 函数，使得整个代码异步。在某些情况下，可能需要运行一小部分同步代码，这部分可以参考 spawn_blocking。在其他情况下，可能更容易将应用程序结构分为大部分同步，使用较小的或逻辑上不同的异步部分。例如，GUI 应用程序可能希望在主线程上运行 GUI 代码，并在旁边的另一个线程上运行 Tokio 运行时。这一小节介绍如何将 async/await 隔离到项目的一小部分。\n# 3.6.1 what #[tokio::main] expands to 1 2 3 4 5 6 7 8 9 10 11 12 13 14 #[tokio::main] async fn main() { println!(\u0026#34;Hello world\u0026#34;); } fn main() { tokio::runtime::Builder::new_multi_thread() .enable_all() .build() .unwrap() .block_on(async { println!(\u0026#34;Hello world\u0026#34;); }) } #[tokio::main] 宏是一个宏，它将 main 函数替换为一个非异步 main 函数，该函数启动一个运行时，然后调用代码。从宏观上看，要在我们的项目中使用 async/await，可以做类似的事情，利用 block_on 方法在适当的地方进入异步上下文。\n# 3.6.2 a synchronous interface to mini-redis 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 use tokio::net::ToSocketAddrs; use tokio::runtime::Runtime; pub use crate::clients::client::Message; pub struct BlockingClient { inner: crate::clients::Client, rt: Runtime, } impl BlockingClient { pub fn connect\u0026lt;T: ToSocketAddrs\u0026gt;(addr: T) -\u0026gt; crate::Result\u0026lt;BlockingClient\u0026gt; { let rt = tokio::runtime::Builder::new_current_thread() .enable_all() .build()?; let inner = rt.block_on(crate::clients::Client::connect(addr))?; Ok(BlockingClient { inner, rt }) } } 上面的代码通过存储一个 Runtime 对象并使用它的 block_on 方法构建一个 mini-redis 的同步接口。在这里使用了 current_thread 运行时，这是因为 Tokio 默认的 multi_thread 运行时会产生一堆后台线程，所以它可以有效地同时运行许多事情。对于上面的示例，一次只做一件事，因此运行多个线程不会获得任何好处。这使得 current_thread 运行时非常适合，它不产生任何线程。enable_all 调用在 Tokio 运行时启用 IO 和定时器驱动程序。如果未启用它们，则运行时无法执行 IO 或计时器。因为 current_thread 运行时不产生任何线程，所以它只在调用 block_on 时操作。一旦 block_on 返回，该运行时上的所有生成任务将冻结，直到再次调用 block_on。如果生成的任务在不调用 block_on 时必须继续运行，则使用 multi_thread。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 use bytes::Bytes; use std::time::Duration; impl BlockingClient { pub fn get(\u0026amp;mut self, key: \u0026amp;str) -\u0026gt; crate::Result\u0026lt;Option\u0026lt;Bytes\u0026gt;\u0026gt; { self.rt.block_on(self.inner.get(key)) } pub fn set(\u0026amp;mut self, key: \u0026amp;str, value: Bytes) -\u0026gt; crate::Result\u0026lt;()\u0026gt; { self.rt.block_on(self.inner.set(key, value)) } pub fn set_expires( \u0026amp;mut self, key: \u0026amp;str, value: Bytes, expiration: Duration, ) -\u0026gt; crate::Result\u0026lt;()\u0026gt; { self.rt.block_on(self.inner.set_expires(key, value, expiration)) } pub fn publish(\u0026amp;mut self, channel: \u0026amp;str, message: Bytes) -\u0026gt; crate::Result\u0026lt;u64\u0026gt; { self.rt.block_on(self.inner.publish(channel, message)) } } # 3.6.3 other approaches spawning things on a runtime\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 use tokio::runtime::Builder; use tokio::time::{sleep, Duration}; fn main() { let runtime = Builder::new_multi_thread() .worker_threads(1) .enable_all() .build() .unwrap(); let mut handles = Vec::with_capacity(10); for i in 0..10 { handles.push(runtime.spawn(my_bg_task(i))); } std::thread::sleep(Duration::from_millis(750)); println!(\u0026#34;Finished time-consuming task.\u0026#34;); for handle in handles { runtime.block_on(handle).unwrap(); } } async fn my_bg_task(i: u64) { let millis = 1000 - 50 * i; println!(\u0026#34;Task {} sleeping for {} ms.\u0026#34;, i, millis); sleep(Duration::from_millis(millis)).await; println!(\u0026#34;Task {} stopping.\u0026#34;, i); } Runtime 对象有一个名为 spawn 的方法，当调用此方法，将创建一个在运行时上运行的新的后台任务。上面的例子在运行时生成 10 个后台任务，然后等待它们全部完成。这可能是在图形应用程序中实现后台网络请求的一种好方法，因为网络请求在 GUI 主线程上运行太费时了。可以在后台运行的 Tokio 运行时中生成请求，并在请求完成时让任务将信息发送回 GUI 代码。如果想要一个进度条，甚至可以增量地发送信息。\n在这个例子中，将运行时配置为 multi_thread 运行时是非常重要的。如果更改为 current_thread 运行时，耗时的任务将在任何后台任务开始之前完成。这是因为在 current_thread 运行时上产生的后台任务只会在调用 block_on 时执行，否则运行时没有任何地方可以运行它们。\n这个示例通过调用 spawn 调用返回的 JoinHandle 上的 block_on 来等待生成的任务完成，还可以通过消息传递通道，例如 tokio::sync::mpsc，或通过修改受到例如互斥锁等保护的共享值。对于 GUI 中的进度条来说，这是一种很好的方法，因为 GUI 每帧读取共享值。spawn 方法也可以用于 Handle 类型，可以克隆 Handle 类型以获得运行时的许多句柄，并且每个 Handle 可用于在运行时上生成新任务。\nsending messages\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 use tokio::runtime::Builder; use tokio::sync::mpsc; pub struct Task { name: String, } async fn handle_task(task: Task) { println!(\u0026#34;Got task {}\u0026#34;, task.name); } #[derive(Clone)] pub struct TaskSpawner { spawn: mpsc::Sender\u0026lt;Task\u0026gt;, } impl TaskSpawner { pub fn new() -\u0026gt; TaskSpawner { let (send, mut recv) = mpsc::channel(16); let rt = Builder::new_current_thread() .enable_all() .build() .unwrap(); std::thread::spawn(move || { rt.block_on(async move { while let Some(task) = recv.recv().await { tokio::spawn(handle_task(task)); } }); }); TaskSpawner { spawn: send, } } pub fn spawn_task(\u0026amp;self, task: Task) { match self.spawn.blocking_send(task) { Ok(()) =\u0026gt; {}, Err(_) =\u0026gt; panic!(\u0026#34;The shared runtime has shut down.\u0026#34;), } } } 第三种方法是生成一个运行时，并使用消息传递与它通信。这比其他两种方法涉及更多的样板文件，但是是最灵活的方法。可以使用多种方法配置这个示例，例如使用信号量来限制活动任务的数量，或者使用相反方向的 channel 来发送响应。当使用这种方式生成一个运行时，这实际上是一种 atcor 模式的应用。\n本章节主要参考了 Tokio 的官方教程，原文还提到了 Select、Streams、Graceful Shutdown 等内容可供参考。\n# 参考资料 https://tokio.rs/tokio/tutorial ","date":"2023-11-10T00:00:00Z","image":"https://zjregee.github.io/blog/p/tokio/cover_hud65947a92fbac0d992d55c4c8e5c9fc4_307071_120x120_fill_q75_box_smart1.jpg","permalink":"https://zjregee.github.io/blog/p/tokio/","title":"Rust 异步运行时探秘"},{"content":" 本文是 mini 系列的第五篇文章，mini 系列是一些知名框架或技术的最小化实现，本系列文章仅作为学习积累的目的，代码或架构在很大程度上参考了现有的一些源码或博客。本文根据 Tokio 官方教程实现了一个 Rust 异步运行时示例以及一个实现 Future trait 可供运行时调度的值类型。\nTokio 项目地址：https://github.com/tokio-rs/tokio\nmini-tokio 代码实现地址：https://github.com/zjregee/mini/mini-tokio\n# 一、Futures 在 Rust 中直接调用异步函数返回的值是 future，即实现标准库所提供的 std::future::Future trait 的值，该 trait 定义如下：\n1 2 3 4 5 6 7 8 9 use std::pin::Pin; use std::task::{Context, Poll}; pub trait Future { type Output; fn poll(self: Pin\u0026lt;\u0026amp;mut Self\u0026gt;, cx: \u0026amp;mut Context) -\u0026gt; Poll\u0026lt;Self::Output\u0026gt;; } 关联类型 Output 是 future 完成后产生的类型，Pin 类型是 Rust 在异步函数中支持借用的方式。与其他语言的 future 实现方式不同，Rust 中的 future 并不表示在后台发生的计算，而是 future 本身就是计算。future 的所有者需要负责轮询 future 来推动计算，推进计算的过程是通过调用 Future::poll 来实现的。\n# 1.1 implementing future 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 use std::future::Future; use std::pin::Pin; use std::task::{Context, Poll}; use std::time::{Duration, Instant}; struct Delay { when: Instant, } impl Future for Delay { type Output = \u0026amp;\u0026#39;static str; fn poll(self: Pin\u0026lt;\u0026amp;mut Self\u0026gt;, cx: \u0026amp;mut Context\u0026lt;\u0026#39;_\u0026gt;) -\u0026gt; Poll\u0026lt;\u0026amp;\u0026#39;static str\u0026gt; { if Instant::now() \u0026gt;= self.when { println!(\u0026#34;Hello world\u0026#34;); Poll::Ready(\u0026#34;done\u0026#34;) } else { cx.waker().wake_by_ref(); Poll::Pending } } } #[tokio::main] async fn main() { let when = Instant::now() + Duration::from_millis(10); let future = Delay { when }; let out = future.await; assert_eq!(out, \u0026#34;done\u0026#34;); } # 1.2 async fn as a Future 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 use std::future::Future; use std::pin::Pin; use std::task::{Context, Poll}; use std::time::{Duration, Instant}; enum MainFuture { State0, State1(Delay), Terminated, } impl Future for MainFuture { type Output = (); fn poll(mut self: Pin\u0026lt;\u0026amp;mut Self\u0026gt;, cx: \u0026amp;mut Context\u0026lt;\u0026#39;_\u0026gt;) -\u0026gt; Poll\u0026lt;()\u0026gt; { use MainFuture::*; loop { match *self { State0 =\u0026gt; { let when = Instant::now() + Duration::from_millis(10); let future = Delay { when }; *self = State1(future); } State1(ref mut my_future) =\u0026gt; { match Pin::new(my_future).poll(cx) { Poll::Ready(out) =\u0026gt; { assert_eq!(out, \u0026#34;done\u0026#34;); *self = Terminated; return Poll::Ready(()); } Poll::Pending =\u0026gt; { return Poll::Pending; } } } Terminated =\u0026gt; { panic!(\u0026#34;future polled after completion\u0026#34;) } } } } } Rust 中的 futures 是状态机。在这里，MainFuture 被表示为 future 可能状态的枚举。future 从 State 0 状态开始，当调用 poll 时，future 试图尽可能地推进其内部状态。如果 future 可以被完成，则返回 Poll::Ready，其中包含异步计算的输出。如果 future 不能完成，通常是由于它正在等待的资源没有准备好，那么返回 Poll::Pending，接收到 Poll::Pending 向调用方表明 future 将在稍后的时间完成，调用方应该稍后再次调用 poll。futures 是由其他 futures 组成的，在外部的 futures 上调用 poll 会导致调用内部 futures 的poll 函数。\n# 二、Executors 异步函数返回 futures，futures 一定需要被调用 poll 来推进它们的状态。futures 是由 futures 来组成的。那么又是由谁来调用最外层 future 的 poll 呢？要运行异步函数，它们要么传递给 tokio::spawn，要么是带有 #[tokio::main] 注释的 main 函数。这导致将生成的外部 future 提交给 Tokio 执行器。执行器负责对外部的 future 调用 Future::poll，推动异步计算完成。\n# 2.1 mini-tokio 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 use std::collections::VecDeque; use std::future::Future; use std::pin::Pin; use std::task::{Context, Poll}; use std::time::{Duration, Instant}; use futures::task; fn main() { let mut mini_tokio = MiniTokio::new(); mini_tokio.spawn(async { let when = Instant::now() + Duration::from_millis(10); let future = Delay { when }; let out = future.await; assert_eq!(out, \u0026#34;done\u0026#34;); }); mini_tokio.run(); } struct MiniTokio { tasks: VecDeque\u0026lt;Task\u0026gt;, } type Task = Pin\u0026lt;Box\u0026lt;dyn Future\u0026lt;Output = ()\u0026gt; + Send\u0026gt;\u0026gt;; impl MiniTokio { fn new() -\u0026gt; MiniTokio { MiniTokio { tasks: VecDeque::new(), } } fn spawn\u0026lt;F\u0026gt;(\u0026amp;mut self, future: F) where F: Future\u0026lt;Output = ()\u0026gt; + Send + \u0026#39;static, { self.tasks.push_back(Box::pin(future)); } fn run(\u0026amp;mut self) { let waker = task::noop_waker(); let mut cx = Context::from_waker(\u0026amp;waker); while let Some(mut task) = self.tasks.pop_front() { if task.as_mut().poll(\u0026amp;mut cx).is_pending() { self.tasks.push_back(task); } } } } 这将导致运行异步块。这个执行器有个显著的缺陷，这个执行器不断地循环所有的 futures 并调用 poll。大多数时候，futures 不会准备好执行更多的工作，并且会再次返回 Poll::Pending。这个过程会消耗 CPU 周期，通常效率不高。理想情况下，我们希望 mini-tokio 仅在 futures 能够取得进展的时候调用 poll。当任务被阻塞的资源准备好执行所请求的操作时，就会发生这种情况。如果任务想要从 TCP 套接字读取数据，那么只希望在 TCP 套接字接收到数据时轮询任务。\n# 三、Wakers 通过 wakers，资源能够通知等待任务该资源已准备好继续某些操作。\n1 fn poll(self: Pin\u0026lt;\u0026amp;mut Self\u0026gt;, cx: \u0026amp;mut Context) -\u0026gt; Poll\u0026lt;Self::Output\u0026gt;; poll 的 Context 参数有一个 waker() 方法，此方法返回绑定到当前任务的 waker。waker 有一个 wake() 方法，调用此方法向执行器发出信号，表明应该安排执行关联的任务。资源在转换到就绪状态时调用 wake()，以通知执行器轮询任务将能够取得进展。\n# 3.1 updating delay 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 use std::future::Future; use std::pin::Pin; use std::task::{Context, Poll}; use std::time::{Duration, Instant}; use std::thread; struct Delay { when: Instant, } impl Future for Delay { type Output = \u0026amp;\u0026#39;static str; fn poll(self: Pin\u0026lt;\u0026amp;mut Self\u0026gt;, cx: \u0026amp;mut Context\u0026lt;\u0026#39;_\u0026gt;) -\u0026gt; Poll\u0026lt;\u0026amp;\u0026#39;static str\u0026gt; { if Instant::now() \u0026gt;= self.when { println!(\u0026#34;Hello world\u0026#34;); Poll::Ready(\u0026#34;done\u0026#34;) } else { let waker = cx.waker().clone(); let when = self.when; thread::spawn(move || { let now = Instant::now(); if now \u0026lt; when { thread::sleep(when - now); } waker.wake(); }); Poll::Pending } } } 当 future 返回 Poll::Pending 时，它必须确保在某个时刻向 waker 发出信号，忘记这样做会导致任务无限期搁置。当返回 Poll::Pending 后忘记唤醒任务是 bug 的常见来源。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 impl Future for Delay { type Output = \u0026amp;\u0026#39;static str; fn poll(self: Pin\u0026lt;\u0026amp;mut Self\u0026gt;, cx: \u0026amp;mut Context\u0026lt;\u0026#39;_\u0026gt;) -\u0026gt; Poll\u0026lt;\u0026amp;\u0026#39;static str\u0026gt; { if Instant::now() \u0026gt;= self.when { println!(\u0026#34;Hello world\u0026#34;); Poll::Ready(\u0026#34;done\u0026#34;) } else { cx.waker().wake_by_ref(); Poll::Pending } } } 在之前的 Delay 实现中，在返回 Poll::Pending 之前，我们调用了 cx.wake().wake_by_ref()。这是因为我们还没有实现计数器线程，所以我们内联地给 waker 发送信号，这样将导致 future 立即重新调度，再次执行，并且可能无法完成。这样的实现会导致一个忙循环，除了浪费一些 CPU 周期，也并没有什么问题。\n# 3.2 update mini-tokio 更新后的 mini-tokio 使用一个 channel 来存储被调度的任务。channel 允许任务排队并从任何线程执行。wakers 必须是 Send 和 Sync 的，所以在这里使用 crossbeam crate，因为标准库中的 channel 不是 Sync 的。可以发送到其他线程的类型是 Send，大多数类型都是 Send，但像 Rc 这样的类型不是。可以通过不可变引用并发访问的类型是 Sync。类型可以是 Send，但不是 Sync的。例如 Cell 它可以通过不可变引用进行修改，因此并发访问是不安全的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 use crossbeam::channel; use std::sync::{Arc, Mutex}; struct MiniTokio { scheduled: channel::Receiver\u0026lt;Arc\u0026lt;Task\u0026gt;\u0026gt;, sender: channel::Sender\u0026lt;Arc\u0026lt;Task\u0026gt;\u0026gt;, } struct Task { future: Mutex\u0026lt;Pin\u0026lt;Box\u0026lt;dyn Future\u0026lt;Output = ()\u0026gt; + Send\u0026gt;\u0026gt;\u0026gt;, executor: channel::Sender\u0026lt;Arc\u0026lt;Task\u0026gt;\u0026gt;, } impl Task { fn schedule(self: \u0026amp;Arc\u0026lt;Self\u0026gt;) { self.executor.send(self.clone()); } } wakers 是 Sync 的，并且可以被 clone。当 wake 被调用时，任务必须被调度执行。在这里通过 channel 实现这一点。当 wake() 在 waker 上被调用时，任务被推送到 channel 的发送端口。Task 结构将实现 wake 逻辑。现在需要将 schedule 函数与 std::task::Waker 挂钩。标准库提供了一个 low-level 的 API，通过手动构造的虚函数表可以实现这一点。这个实现方式为实现者提供了最大的灵活性，但需要大量 unsafe 的样板代码。在这里不直接使用 RawWakerVTable，而是使用 futures crate 提供的 ArcWake 实用程序。这个 crate 允许通过实现一个简单的 trait，将 Task 结构体公开为一个 waker。\n1 2 3 4 5 6 7 use futures::task::{self, ArcWake}; use std::sync::Arc; impl ArcWake for Task { fn wake_by_ref(arc_self: \u0026amp;Arc\u0026lt;Self\u0026gt;) { arc_self.schedule(); } } 当之前的计时器线程调用 waker.wake() 时，任务被推送到 channel 中。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 impl MiniTokio { fn run(\u0026amp;self) { while let Ok(task) = self.scheduled.recv() { task.poll(); } } fn new() -\u0026gt; MiniTokio { let (sender, scheduled) = channel::unbounded(); MiniTokio { scheduled, sender } } fn spawn\u0026lt;F\u0026gt;(\u0026amp;self, future: F) where F: Future\u0026lt;Output = ()\u0026gt; + Send + \u0026#39;static, { Task::spawn(future, \u0026amp;self.sender); } } impl Task { fn poll(self: Arc\u0026lt;Self\u0026gt;) { let waker = task::waker(self.clone()); let mut cx = Context::from_waker(\u0026amp;waker); let mut future = self.future.try_lock().unwrap(); let _ = future.as_mut().poll(\u0026amp;mut cx); } fn spawn\u0026lt;F\u0026gt;(future: F, sender: \u0026amp;channel::Sender\u0026lt;Arc\u0026lt;Task\u0026gt;\u0026gt;) where F: Future\u0026lt;Output = ()\u0026gt; + Send + \u0026#39;static, { let task = Arc::new(Task { future: Mutex::new(Box::pin(future)), executor: sender.clone(), }); let _ = sender.send(task); } } Task:poll() 函数使用 futures crate 中的 ArcWake 实用程序创建 waker，这个 waker 用于创建 task::Context，该 task::Context 被传递给 poll。\n# 四、总结 Rust 的 async/await 特性是由 traits 支持的，这允许第三方 crate 提供执行细节：异步 Rust 操作是惰性的，需要调用者去轮询它们；wakers 被传递给 futures，将 future 与调用它的任务联系起来；当资源尚未准备好完成操作时，将返回 Poll::Pending 并记录任务的 waker；当资源准备就绪时，通知任务的 waker；执行器接收通知并安排任务的执行；再次轮询任务，这一次资源准备就绪，任务取得进展。\n# 4.1 一些尚未解决的问题 Rust 的异步模型允许单个 future 在执行时跨任务迁移。考虑以下代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 use futures::future::poll_fn; use std::future::Future; use std::pin::Pin; #[tokio::main] async fn main() { let when = Instant::now() + Duration::from_millis(10); let mut delay = Some(Delay { when }); poll_fn(move |cx| { let mut delay = delay.take().unwrap(); let res = Pin::new(\u0026amp;mut delay).poll(cx); assert!(res.is_pending()); tokio::spawn(async move { delay.await; }); Poll::Ready(()) }).await; } poll_fn 函数使用闭包创建 Future 实例。在这个例子中，Delay::poll 被不同的 waker 实例调用了不止一次。当发生这种情况时，我们必须确保在传递给最近的 poll 调用的 waker 实例上调用 wake。在实现 future 时，重要的是要假设每个对 poll 的调用都可以提供一个不同的 waker 实例，poll 函数必须用新的 waker 替代之前记录的 waker。\n之前的 Delay 实现在每次轮询时都会生成一个新线程。如果轮询过于频繁（例如 select! 这个 future 和一些其他的 future，当其中一个发生事件时，都要进行轮询），效率会非常低。一种方法是记住是否已经生成了一个新线程，只有在还没有生成一个线程的情况下才生成一个新线程。但是，如果这样做，必须确保线程的 waker 在以后的轮询调用中更新，否则不会唤醒最近的 waker。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 use std::future::Future; use std::pin::Pin; use std::sync::{Arc, Mutex}; use std::task::{Context, Poll, Waker}; use std::thread; use std::time::{Duration, Instant}; struct Delay { when: Instant, waker: Option\u0026lt;Arc\u0026lt;Mutex\u0026lt;Waker\u0026gt;\u0026gt;\u0026gt;, } impl Future for Delay { type Output = (); fn poll(mut self: Pin\u0026lt;\u0026amp;mut Self\u0026gt;, cx: \u0026amp;mut Context\u0026lt;\u0026#39;_\u0026gt;) -\u0026gt; Poll\u0026lt;()\u0026gt; { if let Some(waker) = \u0026amp;self.waker { let mut waker = waker.lock().unwrap(); if !waker.will_wake(cx.waker()) { *waker = cx.waker().clone(); } } else { let when = self.when; let waker = Arc::new(Mutex::new(cx.waker().clone())); self.waker = Some(waker.clone()); thread::spawn(move || { let now = Instant::now(); if now \u0026lt; when { thread::sleep(when - now); } let waker = waker.lock().unwrap(); waker.wake_by_ref(); }); } if Instant::now() \u0026gt;= self.when { Poll::Ready(()) } else { Poll::Pending } } } 这里有点复杂，核心思想是每次调用 poll 时，future 检查提供的 waker 是否与先前记录的 waker 匹配。如果两个 waker 不匹配，需要更新记录的 waker。\n# 4.2 notify 实用工具 wakers 是异步 Rust 工作的基础，通常没有必要降低到这个层次编写代码。在 Delay 的例子中，通过使用 tokio::sync::Notify 实用程序完全使用 async/await 来实现它。这个实用程序提供了一个基本的任务通知机制，它处理 waker 的细节，包括确保记录的 waker 与当前任务匹配。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 use tokio::sync::Notify; use std::sync::Arc; use std::time::{Duration, Instant}; use std::thread; async fn delay(dur: Duration) { let when = Instant::now() + dur; let notify = Arc::new(Notify::new()); let notify_clone = notify.clone(); thread::spawn(move || { let now = Instant::now(); if now \u0026lt; when { thread::sleep(when - now); } notify_clone.notify_one(); }); notify.notified().await; } # 4.3 定义 trait 中的异步方法 在 Rust 中，异步方法通过 async 关键字来定义，然而，trait 不能直接定义异步方法。异步方法的处理需要在运行时处理 Future，这种处理依赖于特定的异步运行时环境，这导致了异步方法的实现涉及到更多的运行时支持，而 trait 的设计初衷在于提供一种在编译时进行静态分发的方法。\n为了在 trait 中支持异步方法，需要引入更复杂的机制，目前常见的使用方法是通过 async-trait crate 来实现定义 trait 中的异步方法。总的来说，Rust 的设计哲学是尽可能提供简单、静态的机制来支持各种编程范式，而异步编程则引入了一些动态的概念。这两者之间的差异导致了异步方法不直接支持 trait 的原因。\n值得一提的是，最新的 Rust 版本在近期已经提供了 async trait 的支持。\nhttps://blog.rust-lang.org/inside-rust/2023/05/03/stabilizing-async-fn-in-trait.html\n# 参考资料 https://tokio.rs/tokio/tutorial/async ","date":"2023-11-03T00:00:00Z","permalink":"https://zjregee.github.io/blog/p/mini-tokio/","title":"Rust 异步运行时实现示例"},{"content":" 本文是 mini 系列的第四篇文章，mini 系列是一些知名框架或技术的最小化实现，本系列文章仅作为学习积累的目的，代码或架构在很大程度上参考了现有的一些源码或博客。本文基于 bitcask 存储模型使用 Rust 语言实现了一个高性能的持久化 kv 数据库。\n代码实现地址：https://github.com/zjregee/mini/mini-bitcask\n# 一、bitcask 存储模型 bitcask 是一种键值存储引擎的存储模型，旨在提供高性能和简单的数据持久化。它主要用于构建分布式存储系统，通常用于支持键值对数据库。bitcask 的核心设计思想是将数据以追加日志的方式存储在磁盘上。这个追加日志是按照写入顺序不断增长的，新的写入会追加到文件的末尾。每个写入都会生成一个唯一的文件句柄，包含了对应数据的键、值、时间戳等信息。为了加速键的查找过程，bitcask 使用了内存中的哈希表或其他高效的数据结构来维护键和对应数据文件的索引。这使得在内存中进行键的查找非常高效。随着写入操作的进行，bitcask 的数据文件会不断增长。为了避免文件过大和提高性能，bitcask 会定期执行 merge 操作。merge 操作会将多个小的数据文件合并成一个更大的文件，并删除重复的键。这个操作确保在不断写入的同时，维护着较小的数据文件，提高读取性能。\n相比于基于 LSM-Tree 数据结构的键值存储引擎，bitcask 的设计相对简单，易于理解和实现，容易维护和部署。基于 LSM-Tree 数据结构的键值存储引擎的写入操作先写入内存结构，后台异步合并到磁盘，bitcask 使用追加日志的方式顺序写入，两者都具有较高的写入吞吐量。对于读取性能而言，基于 LSM-Tree 数据结构的键值存储引擎在读取数据时可能需要访问多个不同层次跨越内存和磁盘之间的结构，相比于 bitcask 的内存索引可能有更高的读取延迟。相比基于 LSM-Tree 数据结构的键值存储引擎，bitcask 通过定期合并操作来维护数据文件，这可能导致在执行合并时出现停顿，影响实时性。此外，基于 LSM-Tree 数据结构的键值存储引擎的有序的键值存储结构设计对于范围查询操作更为高效。总体来说，基于 LSM-Tree 数据结构的键值存储引擎适用于更多的应用场景，在分布式数据库和存储系统中有着广泛的应用。\n# 二、持久化索引原理与实现 # 2.1 目录模型 每一个 bitcask 实例对应一个目录，任何时刻只有一个操作进程可以打开这个目录提供存储服务。该目录中有一个处于 active 状态的文件用于写入数据，当该文件达到大小阈值后，关闭这个文件并创建一个新的处于 active 状态的文件。一旦一个文件被关闭，就被归档并不会再次打开写入数据。\n处于 active 状态的文件仅通过在文件末尾追加键值条目的方式写入。删除操作同样通过追加特定的键值条目数据实现，实际值只会在合并操作时删除。bitcask 在内存中维护一个索引，记录每个 key 对应的 value 所存储的文件以及在文件中的偏移地址。当处理读取操作时，通过内存索引只需要一次磁盘 IO 即可获取 key 对应的 value。\n为了减少磁盘的占用，删除一些已经被删除操作删除的值。bitcask 通过合并操作迭代目录中所有归档文件，并生成一组新的只包含每个 key 最新 value 的文件。在完成压缩操作后，还会在每个数据文件旁边创建一个元数据文件，元数据文件中包含相应数据文件中 key 对应 value 的位置和大小，以便加速数据库的构建过程。\n除此之外，bitcask 官方文档所提到的一些细节：\n1）bitcask 依赖操作系统的文件系统缓存来提高读取性能；\n2）bitcask 的最初目标不是成为最快的存储引擎，而是获得足够的速度以及代码、设计和文件格式的高质量和简单性。在初步测试中，bitcask 在许多场景下可以优于其他快速存储系统；\n3）bitcask 不执行任何数据压缩，因为这样做的成本和收益非常依赖应用程序；\n4）通过 10 倍 RAM 数据集的初步测试证明 bitcask 能够处理比 RAM 大得多的数据集而不会性能降级；\n5）由于 bitcask 中的数据文件和提交日志是相同的操作，在崩溃恢复中不需要 replay，可以实现快速恢复且不丢失数据；\n# 2.2 键值条目实现 键值条目是每次数据操作追加在文件末尾的数据条目，其内存数据结构如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 pub struct Entry { pub valid: bool, pub crc32: u32, pub key_size: u32, pub value_size: u32, pub state: u16, pub time_stamp: u64, pub key: Vec\u0026lt;u8\u0026gt;, pub value: Vec\u0026lt;u8\u0026gt;, } impl Entry { pub fn new(key: Vec\u0026lt;u8\u0026gt;, value: Vec\u0026lt;u8\u0026gt;, t: u16, mark: u16) -\u0026gt; Entry {...} pub fn new_with_expire(key: Vec\u0026lt;u8\u0026gt;, value: Vec\u0026lt;u8\u0026gt;, ddl: u64, t: u16, mark: u16) -\u0026gt; Entry {...} pub fn decode_header(buf: Vec\u0026lt;u8\u0026gt;) -\u0026gt; Option\u0026lt;Entry\u0026gt; {...} pub fn encode(\u0026amp;self) -\u0026gt; Option\u0026lt;Vec\u0026lt;u8\u0026gt;\u0026gt; {...} pub fn get_type(\u0026amp;self) -\u0026gt; u16 {...} pub fn get_mark(\u0026amp;self) -\u0026gt; u16 {...} pub fn size(\u0026amp;self) -\u0026gt; u32 {...} } 键值条目数据结构可以分为两部分，长度为 22 字节的 header 区域和 data 区域。header 区域记录了 4 字节的校验码、4 字节的 key 长度、4 字节的 value 长度、2 字节的状态码、8 字节的时间戳。data 区域记录了 key 和 value 的实际数据，具体大小视 key 和 value 的大小而定。2 字节的状态码分为两部分，其中的一个字节用于记录 type，另一个字节用于记录 mark，状态码可用于标识该键值条目的操作类型，例如对删除操作进行特别标注。\n键值条目数据结构的主要方法包括创建一个内存数据结构，反序列化 header 区域，序列化整个键值条目，获取状态码中的 type 和 mark，以及获取键值条目的大小。\n# 2.3 文件抽象实现 每个存储在 bitcask 所管理目录中的文件可以用以下内存数据结构表示：\n1 2 3 4 5 6 7 8 9 10 11 12 pub struct DBFile { pub id: u32, pub path: String, pub offset: u32, pub file: Option\u0026lt;File\u0026gt; } impl DBFile { pub fn new(path: String, file_id: u32) -\u0026gt; Option\u0026lt;DBFile\u0026gt; {...} pub fn read(\u0026amp;self, mut offset: u32) -\u0026gt; Option\u0026lt;entry::Entry\u0026gt; {...} pub fn write(\u0026amp;mut self, entry: entry::Entry) -\u0026gt; bool {...} } 文件数据结构记录了文件的 id 和路径，offset 记录了文件的大小，file 用于打开文件。文件数据结构的主要方法包括根据文件 id 和路径打开文件，并提供读取一个键值条目和写入一个键值条目的接口。读取键值条目的接口可用于迭代使用，直至顺序读取完文件中的所有键值条目。\n# 三、kv 数据库实现 建立在键值条目和文件的抽象之上，我们可以实现如下的 kv 数据库数据结构。其中 config 记录了 kv 数据库的配置信息，hash_index 是 kv 数据库的内存索引，expires 用来管理键值的过期情况，active_file 记录了当前处于 active 状态的文件，arch_files 记录了已被归档的文件集合。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 #[derive(Default)] pub struct Config { pub dir_path: String, pub max_file_size: u32, } #[derive(Default)] pub struct kv { pub config: config::Config, pub hash_index: hash::Hash, pub expires: HashMap\u0026lt;String, u64\u0026gt;, pub active_file: Option\u0026lt;db_file::DBFile\u0026gt;, pub arch_files: HashMap\u0026lt;u32, db_file::DBFile\u0026gt;, } impl kv { pub fn open(config: config::Config) -\u0026gt; Option\u0026lt;kv\u0026gt; {...} pub fn get(\u0026amp;mut self, key: String) -\u0026gt; Option\u0026lt;String\u0026gt; {...} pub fn set(\u0026amp;mut self, key: String, value: String) -\u0026gt; bool {..} pub fn set_with_expire(\u0026amp;mut self, key: String, value: String, ddl: u64) -\u0026gt; bool {...} pub fn delete(\u0026amp;mut self, key: String) -\u0026gt; bool {...} pub fn clear(\u0026amp;mut self) -\u0026gt; bool {...} pub fn close(\u0026amp;mut self) {...} fn build_index(\u0026amp;mut self) {...} fn build_entry(\u0026amp;mut self, entry: entry::Entry) {...} fn store_entry(\u0026amp;mut self, entry: entry::Entry) -\u0026gt; bool {...} fn check_expired(\u0026amp;self, key: \u0026amp;String) -\u0026gt; bool {...} } 数据库数据结构提供了诸多方法用于数据库构建和实现 kv 操作。open 函数用于打开指定配置下的数据库实例，get 函数用于查询 key，set 函数用于插入 key，set_with_expire 函数用于在插入 key 时设置 key 的过期时间，delete 函数用于删除 key，clear 函数用于清空数据库，close 函数用于关闭数据库，在关闭数据库时需要刷新文件系统缓存，避免数据未落盘造成数据丢失，build_index 函数用于构建数据库，build_entry 函数用于在构建数据库时通过键值条目更新内存索引，store_entry 函数用于在处于 ative 状态的文件中写入新的键值条目，check_expired 函数用于检查 key 是否过期。\n# 3.1 数据库构建实现 数据库的构建过程首先需要遍历数据目录的所有数据文件，并提取数据文件名中的文件 id 信息，根据提取出的文件 id 信息，即可筛选出归档文件集合和处于 active 状态的文件（因为追加日志不断增长，id 最大的文件即为处于 active 状态的文件，如果不存在该文件，则创建一个新的处于 ative 状态的文件）。然后再将数据目录中的数据文件按照 id 从小到大排列依次打开迭代数据文件中的键值条目，根据每个键值条目代表的操作类型更新内存索引。当迭代完所有的数据文件，即数据库构建完成，可对外提供 kv 服务。\n# 3.2 kv 操作实现 查询 key\n查询 key 的过程首先需要检查 key 是否过期，如果 key 没有过期，则直接从内存索引中获取查询结果，如果 key 已经过期，则在内存索引删除相应的 key 和 value 并更新过期记录情况。\n插入key\n插入 key 首先需要在内存索引中插入相应的 key 和 value，然后生成相应的持久化键值条目写入处于 active 状态的文件。\n插入 key 并设置过期时间\n插入 key 并设置过期时间与插入 key 类似，在内存索引中插入相应的 key 和 value，然后生成相应的持久化键值条目写入处于 active 状态的文件（这里的持久化键值条目与插入 key 不同，有不同的条目类型并会额外记录 key 的过期时间），并更新过期记录情况。\n其他操作\n删除操作与清空操作同样会生成一个持久化键值条目，通过条目类型标识操作类型。\n# 四、异步网络接口实现 至此已经实现了一个能够支持常规 kv 操作的数据库，本节通过 axum 和 tokio 框架为其实现一个异步的网络接口，可以通过 RESTful 接口访问 kv 服务。axum 是一个基于 Tokio 运行时用于构建异步、可扩展、高性能 Web 服务的 Rust 框架。下面是通过 axum 框架路由 HTTP 请求，启动网络服务并异步处理各个请求的部分代码示例，并行模式采用了 channel 进行通信的方式，维护一个数据库示例，并通过带缓冲区的 channel 获取待处理的请求。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 async fn kv_get ( Json(payload): Json\u0026lt;serde_json::Value\u0026gt;, Extension(state): Extension\u0026lt;mpsc::Sender\u0026lt;Message\u0026gt;\u0026gt;, ) -\u0026gt; Json\u0026lt;Value\u0026gt; {...} async fn kv_set ( Json(payload): Json\u0026lt;serde_json::Value\u0026gt;, Extension(state): Extension\u0026lt;mpsc::Sender\u0026lt;Message\u0026gt;\u0026gt;, ) -\u0026gt; Json\u0026lt;Value\u0026gt; {...} async fn kv_set_with_expire ( Json(payload): Json\u0026lt;serde_json::Value\u0026gt;, Extension(state): Extension\u0026lt;mpsc::Sender\u0026lt;Message\u0026gt;\u0026gt;, ) -\u0026gt; Json\u0026lt;Value\u0026gt; {...} async fn kv_delete ( Json(payload): Json\u0026lt;serde_json::Value\u0026gt;, Extension(state): Extension\u0026lt;mpsc::Sender\u0026lt;Message\u0026gt;\u0026gt;, ) -\u0026gt; Json\u0026lt;Value\u0026gt; {...} async fn kv_clear ( Extension(state): Extension\u0026lt;mpsc::Sender\u0026lt;Message\u0026gt;\u0026gt;, ) -\u0026gt; Json\u0026lt;Value\u0026gt; {...} async fn kv_close ( Extension(state): Extension\u0026lt;mpsc::Sender\u0026lt;Message\u0026gt;\u0026gt;, ) -\u0026gt; Json\u0026lt;Value\u0026gt; {...} #[tokio::main] async fn main() { ... tokio::spawn(async move { let app = Router::new() .route(\u0026#34;/key/get\u0026#34;, post(kv_get)) .route(\u0026#34;/key/set\u0026#34;, post(kv_set)) .route(\u0026#34;/key/set_with_expire\u0026#34;, post(kv_set_with_expire)) .route(\u0026#34;/key/delete\u0026#34;, post(kv_delete)) .route(\u0026#34;/key/clear\u0026#34;, post(kv_clear)) .route(\u0026#34;/close\u0026#34;, post(kv_close)) .layer(Extension(tx)); let addr = SocketAddr::from(([127, 0, 0, 1], port)); println!(\u0026#34;listening on {}\u0026#34;, addr); axum::Server::bind(\u0026amp;addr) .serve(app.into_make_service()) .await .unwrap(); }); ... } # 参考资料 https://riak.com/assets/bitcask-intro.pdf ","date":"2023-10-23T00:00:00Z","permalink":"https://zjregee.github.io/blog/p/mini-bitcask/","title":"基于 bitcask 存储模型的 mini kv 数据库实现"},{"content":" 本文是 mini 系列的第三篇文章，mini 系列是一些知名框架或技术的最小化实现，本系列文章仅作为学习积累的目的，代码或架构在很大程度上参考了现有的一些源码或博客。本文通过 C++ 语言模拟了 Paxos 算法中核心的二阶段提议提交。\n代码实现地址：https://github.com/zjregee/mini/mini-paxos\n# 一、分布式共识算法 分布式共识算法是一种用于在分布式系统中达成一致性的方法。在分布式系统中，多个计算机节点之间需要协作完成任务，但由于网络延迟、节点故障等问题，节点之间可能产生不一致的状态。共识算法的目标是确保所有节点就系统的状态达成一致，即使在存在故障或网络分区的情况下也能保持一致。常见的分布式共识算法包括 Paxos 算法和 Raft 算法等，其中每个算法的特点如下：\nPaxos 算法是一种经典的分布式共识算法，用于解决一致性问题。它通过两个阶段的消息传递来达成共识：提议阶段和接受阶段。Paxos 算法对于容忍节点故障具有强大的性能，但其理解和实现相对复杂。 Raft 算法是一种相对较新且更易理解的分布式共识算法，其设计目标是提供与 Paxos 相同的一致性保证，但更容易理解和实现。Raft 将共识问题划分为领导选举、日志复制和安全性这三个相对独立的子问题，并通过限制选举过程中的竞争来简化了算法。 除了 Paxos 算法和 Raft 算法，针对不同的场景还有诸多不同的分布式共识算法。在实际使用中，选择特定算法取决于系统的需求、性能要求以及容忍的故障类型，需要根据具体场景做出合适的选择。\n# 二、Paxos 算法核心 # 2.1 角色定义与提议 在 Paxos 算法中，有三个主要角色：提议者、接受者和学习者。这些角色共同协作以达成一致性，并且在具体的实现中，一个节点可能会同时充当多种角色。每个角色的定义和主要功能如下：\n提议者：提议者的主要责任是向系统中的节点提交提议。提议者希望达成一致性，它会向一组接受者发送提议。提议者的提议可以包含一个值，而接受者将根据提议的情况来接受或拒绝该提议。 接受者：接受者的主要责任是接受或拒绝提议者的提议。接受者在接受到提议后，可以根据一定的规则来判断是否接受该提议。一个提议可能会被多个接受者接受，但最终只有一个提议能够在系统中达成一致。 学习者：学习者的任务是学习已经达成的一致性，即已经被接受的提议。学习者会从接受者那里获得已接受的提议，并将这些信息传播到整个系统中，以确保所有节点都知道已经达成的一致性。 一个提议可以同时被多个接受者接受，但最终系统只会选择其中的一个提议来达成一致性。尽管多个节点可能接受相同的提议，但系统需要最终选择一个提议来作为最终的共识值。这是因为在分布式环境中，存在并发的提议。多个提议者可以同时向系统提交提议，而多个接受者可能会接受其中的一个或多个提议。然后，系统必须经过一系列的协商和决策步骤，最终只选择一个提议作为系统的共识值。这确保了系统在分布式环境中的一致性。\n在分布式系统中，提议是一种由提议者提交给接受者的操作，旨在达成分布式系统中的共识。提议通常包含一个值，提议者希望将这个值引入系统，并确保系统中的大多数节点都同意接受这个值，以达成一致性。提议通常包含两个元素，提议编号和提议值。每个提议都有一个唯一的编号，用于区分不同的提议，提议编号有助于解决并发提议的冲突，通常是一个单调递增的序列。提议值是提议者希望系统接受的实际值，这可以是任何系统状态的值，例如某个数据的更新。\n提议的提交过程通常涉及多轮协商，以确保达到一致性。接受者可能会对提议进行投票，通过投票来决定是否接受提议，并通过与其他节点协商来达成共识。对于提议者而言，如果提议被半数以上的接受者接受，提议者就认为提议提交成功；对于接受者而言，只要接受者接受了某个提议，接受者就认为提议提交成功；对于学习者而言，接受者通知学习者哪个提议提交成功，学习者就认为提议提交成功。提议的提交过程会在下一小节中具体介绍，且会通过忽略学习者简化 Paxos 算法的运行过程。\n# 2.2 提议的两阶段提交 Paxos 算法中的提议提交分为两个阶段，这两个阶段是为了确保在分布式系统中达成一致性。\n在提议阶段中，提议者向所有的接受者发送一个提议，其中包含一个提议编号。每个接受者会在接受到提议后，判断当前是否已经接受了更高编号的提议。如果接受者没有接受过更高编号的提议，它会接受当前提议，并向提议者发送一个承诺，承诺不在接受小于该提议编号的提议。如果接受者已经接受了更高编号的提议，它会拒绝当前提议。\n在接受阶段中，如果提议者收到了半数以上接受者的承诺，表示当前提议可以继续进行。提议者向所有的接受者发送一个接受请求，包含提议编号和提议值。接受者在接收到接受请求后，判断提议编号是否大于或等于它收到的所有提议阶段的提议编号，如果是，接受者接受当前提议，并通知其他节点，否则拒绝当前提议。\n通过提议的两阶段提交，Paxos 保证了以下几点：每个提议都有一个唯一的提议编号，防止冲突；较大提议编号的提案优先被接受；提议只有在大多数节点接受的情况下才被最终接受，确保了系统的一致性。在第一阶段，提议者获得了对当前提议的承诺，确保没有更高编号的提议被接受。在第二阶段，只有在足够数量的承诺下，提议者才将提议者发送给接受者，最终确保只有一个值被系统接受，从而达成一致性。如果一个值被接受，那么所有正确的节点都会接受相同的值。这种两阶段提交的方式保证了分布式系统中的一致性，即使在节点故障或网络分区的情况下也能够可靠地工作。\n提议值可以是任何想要在分布式系统中达成一致性的数据，例如状态更新、命令等。具体来说，提议者首先根据应用逻辑选择一个提议值。然而，由于分布式系统中存在网络延迟、消息丢失等问题，提议者可能需要通过与其他节点进行通信来达成一致性。在 Paxos 算法的运行过程中，提议者会根据其他节点的承诺和接受情况来确定最终的提议值。如果其他节点已经接受了一个提议，并且这个提议值比提议者最初选择的值更高（根据应用逻辑确定），那么提议者可能会选择接受这个更高的值，以保持系统的一致性。这种情况下，最终确定的提议值可能会受到其他节点的影响。\n# 三、Paxos 算法两阶段实现 # 3.1 相关数据结构 # 3.1.1 Proposal 结构体 1 2 3 4 struct Proposal { size_t serial_num; size_t value; }; Proposal 结构体代表一个提议，serial_num 成员变量表示提议的提议编号，value 成员变量表示提议的提议值。\n# 3.1.2 Acceptor 类 1 2 3 4 5 6 7 8 9 10 class Acceptor { public: Acceptor(); bool propose(size_t serial_num, Proposal \u0026amp;last_accept_value); bool accept(Proposal \u0026amp;value); private: size_t max_serial_num_; Proposal last_accept_value_; }; Acceptor 类代表 Paxos 算法模拟中的单个接受者，它包含两个成员变量 max_serial_num_ 和 last_accept_value_。max_serial_num_ 记录在提议阶段接受的最大提议号，last_accept_value_ 记录该接受者接受的提议号最大的提议。Acceptor 类包含两个关键函数，propose 函数实现接受者在提议阶段的处理逻辑，accept 函数实现接受者在接受阶段的处理逻辑。\n# 3.1.3 Proposer 类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class Proposer { public: Proposer(size_t proposer_count, size_t acceptor_count); void restart(); bool proposed(bool ok); bool accepted(bool ok); bool is_propose_finished(); bool is_accept_finished(); private: size_t proposer_count_; size_t acceptor_count_; bool is_propose_finished_; bool is_accept_finished_; size_t ok_count_; size_t refuse_count_; }; Proposer 类代表 Paxos 算法模拟中的单个提议者。proposer_count_ 和 acceptor_count_ 记录 Paxos 算法模拟中的提议者和接受者的数量，is_propose_finished_ 和 is_accept_finished_ 记录提议者当前是否结束提议和接受阶段，ok_count_ 和 refuse_count_ 记录投票情况。Proposer 类包含三个关键函数，restart 函数用于在提议失败时重制相关配置，proposed 函数用于处理提议阶段的投票情况，accepted 函数用于处理接受阶段的投票情况。\n# 3.2 Propose 阶段 1 2 3 4 5 6 7 8 9 10 11 bool Acceptor::propose(size_t serial_num, Proposal \u0026amp;last_accept_value) { if (serial_num == 0) { return false; } if (max_serial_num_ \u0026gt; serial_num) { return false; } max_serial_num_ = serial_num; last_accept_value = last_accept_value_; return true; } Acceptor 类的 propose 函数实现如上所示。接受者通过比较提议编号来决定是否投票支持支持提议，当提议编号小于接受者记录的在提议阶段接受的最大提议编号时，拒绝该提议，否则投票支持该提议。当接受者投票支持该提议时，接受者更新记录的在提议阶段接受的最大提议编号，并推荐该提议者最后一次接受的提议值。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 bool Proposer::proposed(bool ok) { if (!ok) { refuse_count_++; if (refuse_count_ \u0026gt; acceptor_count_ / 2) { return false; } return true; } ok_count_++; if (ok_count_ \u0026gt; acceptor_count_ / 2) { ok_count_ = 0; refuse_count_ = 0; is_propose_finished_ = true; } return true; } Proposer 类的 proposed 函数实现如上。提议者在处理提议阶段的投票时，如果半数以上的接受者拒绝或着没有回应，则返回提议失败，需要开启新一轮提议。如果累计收到半数以上的支持投票，则结束提议阶段，开启接受阶段。\n# 3.3 Accept 阶段 1 2 3 4 5 6 7 8 9 10 bool Acceptor::accept(Proposal \u0026amp;value) { if (value.serial_num == 0) { return false; } if (max_serial_num_ \u0026gt; value.serial_num) { return false; } last_accept_value_ = value; return true; } Acceptor 类的 accept 函数实现如上所示，如果接受者记录的在提议阶段支持的最大提议编号大于提议编号，说明接受者在提议阶段同意了其他提议编号更大的提议，则拒绝本次提议，否则同意本次提议，并更新接受者记录的最后接受的提议值。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 bool Proposer::accepted(bool ok) { if (!ok) { refuse_count_++; if (refuse_count_ \u0026gt; acceptor_count_ / 2) { return false; } return true; } ok_count_++; if (ok_count_ \u0026gt; acceptor_count_ / 2) { ok_count_ = 0; refuse_count_ = 0; is_accept_finished_ = true; } return true; } Proposer 类的 accepted 函数实现如上。Proposer 类的 accepted 函数的处理与 Proposer 类的 proposed 函数类似，如果半数以上的批准者拒绝或没有回应，则需要开启新一轮提议。如果收到半数以上的支持投票，则结束接受阶段，达成一致。\n# 3.4 Paxos 算法模拟 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 const int proposer_count = 5; const int acceptor_count = 11; std::mutex m[acceptor_count]; paxos::Acceptor a[acceptor_count]; std::mutex g_m; size_t finish_count = 0; void propose_loop(size_t index); int main() { for (size_t i = 0; i \u0026lt; proposer_count; i++) { std::thread t(propose_loop, i); t.detach(); } while (true) { if (finish_count == proposer_count) { break; } std::this_thread::sleep_for(std::chrono::milliseconds(500)); } std::cout \u0026lt;\u0026lt; \u0026#34;paxos simulation finished.\u0026#34; \u0026lt;\u0026lt; std::endl; return 0; } Paxos 算法模拟为每个提议者创建一个线程循环进行提议提交过程，并提供数个接受者全局变量。接受者全局变量通过多个互斥锁进行线程的同步，当所有提议者都通过相应的提议时结束模拟过程。提议者线程完整的线程循环实现如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 void propose_loop(size_t index) { paxos::Proposer proposer(proposer_count, acceptor_count); paxos::Proposal proposal; proposal.serial_num = index + 1; proposal.value = index + 1; while (true) { size_t id[acceptor_count]; size_t count = 0; paxos::Proposal last_proposal; for (size_t i = 0; i \u0026lt; acceptor_count; i++) { std::this_thread::sleep_for(std::chrono::milliseconds(std::rand() % 100)); std::unique_lock\u0026lt;std::mutex\u0026gt; lock(m[i]); bool ok = a[i].propose(proposal.serial_num, last_proposal); lock.unlock(); std::this_thread::sleep_for(std::chrono::milliseconds(std::rand() % 100)); if (!proposer.proposed(ok)) { break; } id[count++] = i; if (proposer.is_propose_finished()) { break; } } if (!proposer.is_propose_finished()) { proposal.serial_num += proposer_count; proposer.restart(); continue; } for (size_t i = 0; i \u0026lt; count; i++) { std::this_thread::sleep_for(std::chrono::milliseconds(std::rand() % 100)); std::unique_lock\u0026lt;std::mutex\u0026gt; lock(m[id[i]]); bool ok = a[id[i]].accept(proposal); lock.unlock(); std::this_thread::sleep_for(std::chrono::milliseconds(std::rand() % 100)); if (!proposer.accepted(ok)) { break; } if (proposer.is_accept_finished()) { break; } } if (!proposer.is_accept_finished()) { proposal.serial_num += proposer_count; proposer.restart(); continue; } std::lock_guard\u0026lt;std::mutex\u0026gt; lock(g_m); std::cout \u0026lt;\u0026lt; \u0026#34;proposer \u0026#34; \u0026lt;\u0026lt; index \u0026lt;\u0026lt; \u0026#34; accepted.\u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;serial_num: \u0026#34; \u0026lt;\u0026lt; proposal.serial_num \u0026lt;\u0026lt; \u0026#34;.\u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;value: \u0026#34; \u0026lt;\u0026lt; proposal.value \u0026lt;\u0026lt; \u0026#34;.\u0026#34; \u0026lt;\u0026lt; std::endl; finish_count++; break; } } # 3.5 一些值得一提的点 （1）提议者线程循环会创建一个初始的提议编号和提议值。当提议者在提议提交的过程中失败时，会通过加上提议者总数来更新提议号。由于不同提议者线程循环的初始提议编号不同，这种处理方式简化了提议编号的全局唯一性。\n（2）在模拟提议提交的过程中，提议者线程循环通过使线程随机睡眠一定时间来模拟与接受者信息传递过程中的时延和不稳定性。并且，提议者线程循环在处理接受阶段时，只会向在提议阶段支持提议的接受者发送提议接受请求。\n（3）在提议阶段，支持提议的接受者会返回各个接受者目前已经接受的最大提议编号的提议值，提议者线程循环可以根据这些提议值选择一个可能更合理的提议值。在 Paxos 算法模拟中，希望每个提议者的初始提议值都可以提交，而不存在直接的大小关系，因此在实现中直接忽略了接受者返回的建议提议值。\n# 四、Multi-Paxos 算法改进 Multi-Paxos 算法是对经典 Paxos 算法的扩展，用于提高在分布式系统中达成一致性的性能。Mutil-Paxos 算法相较于 Paxos 算法的主要改进在于以下几点：\nMulti-Paxos 算法允许一个节点在连续的提案中保持领导地位，而不需要在每个提案之前进行领导选举。这减少了领导选举的频率，降低了系统开销。 Multi-Paxos 算法引入了提议流水线的概念，允许领导者并行地处理多个提议，这提高了系统的吞吐量，因为领导者可以同时处理多个提议，而不是等待一个提议完成后再处理下一个。 Multi-Paxos 算法具有更高的可配置性，允许系统在不同的场景中调整参数以优化性能。这种灵活性使得 Multi-Paxos 算法能够适应不同的网络环境和负载状况。 Multi-Paxos 提高了分布式系统中一致性操作的性能和效率，使得它在需要高吞吐量和低延迟的场景中相对于传统的 Paxos 算法更具优势。\n","date":"2023-10-07T00:00:00Z","permalink":"https://zjregee.github.io/blog/p/mini-paxos/","title":"分布式共识算法之 Paxos 算法模拟"},{"content":" 本文是 mini 系列的第二篇文章，mini 系列是一些知名框架或技术的最小化实现，本系列文章仅作为学习积累的目的，代码或架构在很大程度上参考了现有的一些源码或博客。本文参考 Rust 语言的知名数据并行计算框架 Rayon 实现了一个小型的数据并行计算框架 mini-rayon，并基于 mini-rayon 进行了一系列的并行计算测试，取得了一定程度上的性能提升。\nRayon 项目地址：https://github.com/rayon-rs/rayon\nmini-rayon 代码实现地址：https://github.com/zjregee/mini/mini-rayon\n# 一、数据并行计算框架 # 1.1 并行计算框架介绍 并行计算是一种通过执行多个计算任务来提高计算效率的计算范式。与传统的串行计算方式不同，其中每个任务按顺序执行，而并行计算允许多个任务同时进行，从而在相同的时间内处理更多的数据或完成更复杂的计算任务。并行计算的核心思想是任务分解与并发执行。在并行计算中，大的计算任务被分解成许多小的子任务，这些子任务可以独立地并行执行。这种分解使得计算机系统能够更好地利用多个处理单元或多台计算机的资源，加速整体计算过程。分布在多个处理单元上的任务之间通过合理的协同工作方式实现协同完成整体任务。\n并行计算的应用范围广泛，例如在科学研究中，通过并行计算可以更快地模拟复杂的物理现象、分析遗传数据或着优化化学反应。在工程领域，有限元分析、流体力学模拟等复杂问题也常常需要并行计算来提高效率。此外，在人工智能、大数据分析等领域，通过并行计算可以更快速地训练深度学习模型、处理海量数据。尽管并行计算提供了显著的性能提升，但其开发和管理复杂性也是不可忽视的挑战。为了有效利用并行计算的优势，需要仔细设计并行算法、选择合适的并行计算架构，并进行良好的任务调度和数据管理，处理任务分解的复杂性、通信开销、数据一致性等问题。\n为了充分发挥并行计算的优势，开发人员通常需要使用专门的并行计算库和工具。这些库不仅提供了高效的并行算法实现，还简化了任务调度、数据共享和通信等方面的复杂工作。\n一些广泛使用的并行计算库包括 OpenMP 和 MPI。OpenMP 适用于共享内存并行，通过简单的指令注释即可将串行代码转换为并行代码，使得开发人员能够轻松地利用多核处理器。而 MPI 则更适用于分布式内存并行，提供了丰富的消息传递机制，使不同计算节点上的任务能够协同工作。除了这些基础性的库之外，还有一些针对特定领域的高级并行计算框架，如 TensorFlow 和 Pytorch 用于深度学习，Hadoop 和 Spark 用于大数据处理。这些框架在底层实现了复杂的并行计算模型，使开发人员能够专注于问题领域而不是底层的并行细节。\n并行计算在不同编程语言中有着不同的实现方式，同时针对各种计算场景有着各种成熟的并行计算框架实现。通过使用这些并行计算库和框架，开发人员能够在降低开发难度的同时，更有效地利用计算资源，实现复杂问题的快速解决。\nPython 的 Ray 和 Rust 的 Rayon 是两个典型的例子，Ray 是一个用于构建分布式应用和并行计算的高性能框架，它特别适用于处理大规模数据和执行复杂任务。Ray 提供了任务并行性和数据并行性的支持，允许用户轻松地并行化 Python 代码。它还具有分布式计算的能力，可以在多台计算机上执行任务。Rayon 是 Rust 的一个并行计算库，它通过简化并行性的表达方式，使得在不引入显式锁的情况下能够轻松地实现并行计算。Rayon 使用工作窃取算法，自动管理线程池，使得开发者能够更轻松地编写高性能的并行 Rust 代码。除了 Ray 和 Rayon，Java 中的 Fork/Join 框架，Go 中的 goroutines 和 channels 也是一些成熟的并行计算框架。\n# 1.2 数据并行与任务并行 数据并行和任务并行是两种广泛应用于并行计算领域的并行计算模型，它们分别关注并行处理数据和并行执行任务。在数据并行中，计算任务被划分成多个相似的子任务，并且这些子任务同时在不同的处理单元上执行。数据中心的主要思想是并行地处理相同的计算操作，但是在不同的数据集上。这样的模型特别适用于处理大规模数据集，例如矩阵运算、图像处理等。在任务并行中，计算任务被分解成多个相对独立的子任务，并且这些子任务在不同的处理单元上并行执行。任务并行通常关注于同时执行不同的计算任务，每个任务可以有不同的计算流程，但它们协同完成整个计算任务。任务并行中的各个任务之间可能需要协同工作。\n数据并行和任务并行分别强调了在处理大规模计算问题时的不同方面，数据并行关注如何同时处理相似的计算任务在不同数据上，而任务并行关注如何同时执行不同的计算任务。在实际应用中，这两种并行计算模型可以结合使用，以最大程度地发挥计算资源的潜力，提高计算效率。\n# 二、任务调度算法实现 基于工作窃取队列实现的任务调度算法在并行计算中是一种常见的调度算法，其旨在充分利用多核处理器的性能，减少线程间的竞争和等待时间。这种算法特别适用于任务并行模型，其中任务被划分成多个子任务，并且这些子任务在不同的处理单元上并行执行。\n工作窃取队列的核心是通过任务的动态调度来实现负载均衡。每个线程都维护一个本地任务队列，其中存放了该线程需要执行的任务。当一个线程完成自己的任务时，它会首先从自己的本地队列中获取新的任务执行。如果本地队列为空时，使用工作窃取算法使得空闲线程可以从其他线程的队列中窃取任务。每个线程都有一个双端队列，当一个线程需要任务执行时，它会从队列的前端取出任务执行。这种方式有效地避免了线程之间的锁竞争，提高了整体的并行性。任务在被执行的过程中可能会被分割成更小的子任务。这样，每个线程都有机会在本地队列中保持一定数量的任务，提高并行性。\n基于工作窃取队列实现的任务调度算法主要有三个优点：（1）负载均衡。工作窃取队列实现算法能够在运行时自适应地实现负载均衡，保证各个线程的工作量相对均匀，提高整体性能。（2）避免锁竞争。通过将任务放置在双端队列中，线程之间无需共享锁来保护队列的操作，减少了锁竞争的可能性，提高了并行性。（3）适应性。由于工作窃取队列算法能够根据任务的执行情况动态调整任务的分配和窃取策略，因此对于各种负载情况都能表现出较好的适应性。\n# 2.1 工作窃取队列 无锁工作窃取队列有多种算法实现，包括 Chase-Lev、Treiber、M\u0026amp;S 算法等。接下来主要介绍介常见的 Chase-Lev 算法和 Treiber 算法实现逻辑：\nChase-Lev 算法使用双端队列来组织任务，这个队列具有两个端，一个用于入队，另一个用于出队和工作窃取。队列中的每个任务节点包含了指向前一个和后一个节点的指针。 入队操作：当一个线程需要入队时，它会创建一个新的节点，将任务存放在节点中，然后通过 CAS 操作将这个新节点插入到队列的入队端。 出队操作：出队操作是指从队列的出队端移除节点。由于是双端队列，线程可以直接从自己的队列的出队端执行出队操作，无需使用 CAS 操作。 工作窃取操作：当一个线程需要执行任务时，它首先从自己的队列的出队端取得任务。如果自己的队列为空，那么它会随机选择其他线程的队列，尝试从队列的入队端窃取任务。这个过程被称为工作窃取。 Treiber 算法使用单向链表来实现队列结构。队列中的每个任务节点包含指向下一个节点的指针。 入队操作：当一个线程需要入队时，它会首先创建一个新的节点，将任务存放在节点中。然后，它将新节点的指针设置为当前队列的头部，并将队列的头部指针指向新节点。这个过程是一个原子操作，通常使用 CAS 来实现。 出队操作：当一个线程需要出队时，它会读取当前队列的头部指针，获取头部节点。然后，它将队列的头部指针更新为头部节点的下一个节点。出队操作也是一个原子操作。 工作窃取操作：当一个线程需要执行任务时，它首先尝试从自己队列的头部出队一个任务。如果自己的队列为空，那么它会随机选择其他线程的队列，尝试从队列的头部出队任务。这个过程同样可以使用 CAS 来确保线程之间的竞争安全。 Tiber 算法使用于相对简单的并发场景，任务粒度较大且相对均匀的情况。由于其实现逻辑更为简单，相比于 Chase-Lev 算法更容易实现和维护。\n在 mini-rayon 中，采用了 Rayon 早期版本中所使用的基于 Chase-Lev 算法的 dequeue crate。目前 Rayon 所使用的是 crossbeam crate 中实现的无锁工作窃取队列。\n# 2.2、工作窃取机制 在任务调度中，除了工作窃取队列，还需要通过工作窃取机制来实现完整的任务调度流程。简单来说，工作窃取机制是决定了何时以及从哪个队列中窃取任务。常见的工作窃取策略包括 Child Stealing 和 Continuation Stealing 机制。\n在 Child Stealing 机制中，每个线程都维护着自己的私有任务队列，当一个线程完成了自己队列中任务时，它会尝试从其他线程的队列中窃取任务来执行。具体来说，当一个线程空闲而其他线程仍有待执行的任务时，它会随机或按照一定策略来选择一个繁忙线程的任务队列，并尝试从队列头部或尾部窃取任务。Child Stealing 机制的优势在于促使任务在各个线程之间更均匀地分布，避免特定线程成为瓶颈。由于任务是按需发生的，这种策略具有较低的竞争程度，减少了线程之间的争夺，提高了整体并行计算的效率。\n在 Continuation Stealing 机制中，将任务划分地更细粒度，讲任务拆分成更小的执行单元，称为 continuations。在这种机制中，每个线程都维护着自己的 continuation 队列，当一个线程完成了一个 continuation 时，它会尝试从其他线程的 continuation 队列中继续窃取任务。这一机制的核心思想是将任务的执行拆解为更小的、相互独立的子任务，使得在窃取任务的过程中更加细粒度和灵活。相比 Child Stealing 机制，Continuation Stealing 机制的优势在于适应了任务的不均衡性和执行时间的不确定性。通过将任务划分为更小的 continuations，系统能够更灵活地在各个线程之间调度的任务，使得执行时间差异较大的任务不至于影响整个系统的性能。这种策略对于需要处理异步时间、任务执行时间变化较大的应用场景特别有效。\nContinuation Stealing 机制的实现通常设计复杂的调度器和任务划分逻辑，因为 continuation 的粒度相对较小，需要有效地协调线程之间的任务执行顺序。在使用 Continuation Stealing 机制时，也需要程序员精心设计任务的划分和执行逻辑，以最大程度地发挥这种机制的优势。mini-rayon 通过 Child Stealing 机制实现工作窃取，以实现高效、简单的框架 API，避免为编程引入过多的开发成本。\n# 三、mini-rayon 框架介绍 Rayon 是 Rust 中流行的数据并行计算框架，旨在简化并行编程并提高代码性能。它通过简单的 API 和 Rust 的所有权系统来实现并行计算，允许开发者轻松地将现有的迭代代码转换为并行执行的形式。 Rayon 的设计理念是提供一种易于使用的方式来利用多核处理器的性能优势，而无需处理底层的线程管理和同步问题。Rayon 的核心特性之一是并行迭代器，它们允许对集合进行并行操作，并提供了 map、filter 和 reduce 等集合操作的支持。Rayon 通过自动划分工作负载和动态调整线程池的大小来最大程度地利用可用的处理器核心，同时避免了一些常见的并发编程陷阱。\n1 2 3 4 5 6 7 let total_price = stores.iter() .map(|store| store.compute_price(\u0026amp;list)) .sum(); let total_price = stores.par_iter() .map(|store| store.compute_price(\u0026amp;list)) .sum(); mini-rayon 参考 Rayon 实现了一个轻量级的数据并行计算框架，可以轻松地将顺序计算转换为并行计算。例如上面这个常见的顺序迭代计算可以通过使用 mini-rayon 实现的并行迭代器即可将其转换为安全的并行运算。保证并行计算的安全性是使得并行计算框架变得简单易用的很重要的一部分原因。mini-rayon 所实现的并行迭代器将会负责决定如何将数据划分为任务，并通过动态调整来获得最佳性能。\n# 四、框架根基 —— join 原语 # 4.1 潜在并行性 mini-rayon 基于基本原语 join 之上构建整个框架。join 的用法非常简单，可以使用如下的两个闭包调用它。join 会当这两个闭包都完成后返回，这个过程可能是并行的。可能并行的过程被称为潜在并行性，这其实是 min-rayon，同样也就是 Rayon 的核心设计原理。潜在并行性根据空闲 CPU 核心是否可用，动态决定是否使用并行线程。通过调用 join 来注释程序指示潜在并行性，并让运行时决定何时利用它。\n1 join(|| do_something(), || do_someting_else()) 这种潜在并行性也是 mini-rayon 相较于其他并行计算框架的关键区别点之一。例如在使用一些线程池并行框架时，如果将两个任务放在不同的线程之上，它们将始终保持并发执行。mini-rayon 中的潜在并行性不仅可以使得 API 变得更简单，还可以提高执行效率。这是因为知道并行何时有利可图是很难提起预测的，并且总是需要有一定量的全局上下文，诸如计算机当前是否有空闲核心，目前正在进行哪些并行操作此类。潜在并行性相较于当前大部分并行计算框架的保证并行性存在鲜明的区别。\n# 4.2 快排实现用例 1 2 3 4 5 6 7 8 9 10 fn partition\u0026lt;T:PartialOrd+Send\u0026gt;(v: \u0026amp;mut [T]) -\u0026gt; usize { ... } fn quick_sort\u0026lt;T:PartialOrd + Send\u0026gt;(v: \u0026amp;mut [T]) { if v.len() \u0026gt; 1 { let mid = partition(v); let (lo, hi) = v.split_at_mut(mid); quick_sort(lo); quick_sort(hi)); } } 基于 join 原语，我们可以将上面顺序运行的快排伪代码，方便地修改成如下并行化运行的快排伪代码。\n1 2 3 4 5 6 7 8 fn quick_sort\u0026lt;T:PartialOrd + Send\u0026gt;(v: \u0026amp;mut [T]) { if v.len() \u0026gt; 1 { let mid = partition(v); let (lo, hi) = v.split_at_mut(mid); quick_sort(lo); quick_sort(hi)); } } # 4.3 join 原语中的任务调度 join 在具体实现上使用了基于工作窃取机制的任务调度，其基本思想是在每次调用 join(a, b) 时，可以确定两个可以安全并行的任务 a 和 b。由于无法确认是否有空闲线程，当前调用 join 的线程将 b 添加到本地待处理工作队列中，然后立即开始执行 a。同时，还有一组其他活动的线程（通常每个处理器一个线程），每当它空闲时，就会去搜索其他线程的待处理工作队列，如果存在可窃取的任务就会窃取它并自己执行。在这种情况下，当第一个线程忙于执行 a 时，另一个线程可能会出现并开始执行 b。一旦第一个线程完成 a，它就会检查是否有其他线程已经开始执行 b 了。如果没有，第一个线程就继续自己执行 b，如果 b 被其他线程窃取，就需要等待 b 完成，在等待的过程中，第一个线程可以继续从其他处理器中窃取数据，从而尝试帮助推动整个过程完成。这部分的伪代码如下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 fn join\u0026lt;A, B\u0026gt;(oper_a: A, oper_b: B) where A: FnOnce() + Send, B: FnOnce() + Send, { let job = push_onto_local_queue(oper_b); oper_a(); if pop_from_local_queue(oper_b) { oper_b(); } else { while not_yet_complete(job) { steal_from_others(); } result_b = job.result(); } } 基于工作窃取机制的任务调度能够自然地适应处理器的负载。当每个工作线程都非常忙碌时，join(a, b) 的逻辑上会退化成顺序执行每个闭包。这使得 join 原语的抽象并不会使其比顺序执行代码差，在存在可用线程的情况下，join 原语就可以获得并行性带来的性能提升。\n# 4.4 数据结构抽象 # 4.4.1 任务数据结构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 pub trait Executable { fn execute(\u0026amp;mut self); } pub struct Code\u0026lt;F, R\u0026gt; { func: Option\u0026lt;F\u0026gt;, dest: *mut Option\u0026lt;R\u0026gt;, } pub struct Job { code: Box\u0026lt;dyn Executable\u0026gt;, latch: Arc\u0026lt;Latch\u0026gt;, } unsafe impl Send for Job { } unsafe impl Sync for Job { } 在这里，我们实现了三个数据结构来代表 mini-rayon 中的任务执行单元。Job 代表具体执行的任务，code 字段通过 Box 和 dyn 关键字保存了实现 Executable trait 的类型，latch 字段提供了一种锁机制，用于探测任务的完成情况。Code 中的 func 字段保存了需要执行的函数，dest 字段用于保存函数的返回值，即执行结果。此外，我们通过 unsafe impl 为 Job 实现了 Send 和 Sync trait，这是因为 Job 需要在线程之间传递，每个 Job 都有可能会由其他线程来执行。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 impl\u0026lt;F, R\u0026gt; Executable for Code\u0026lt;F, R\u0026gt; where F: FnOnce() -\u0026gt; R, { fn execute(\u0026amp;mut self) { if let Some(func) = self.func.take() { unsafe { *self.dest = Some(func()); } } } } impl Job { pub fn execute(\u0026amp;mut self) { self.code.execute(); self.latch.set(); } } 上面是我们为 Code 和 Job 实现的同步执行函数，会通过工作线程调用来完成任务的执行。值得一提的是，我们在任务中保存的函数需要满足 FnOnce() -\u0026gt; R trait bound 。这有两个原因，首先我们在有需要的情况提供了保存任务返回结果的能力，其次 FnOnce、FnMut 和 Fn 是三种不同的表示闭包或函数的 trait，FnOnce trait 表示可以调用一次的闭包，它会获取捕获变量的所有权，FnMut trait 表示可以多次调用的闭包，它可以修改捕获的变量的值，但不会获取其所有权，Fn trait 表示不可变闭包引用，它不能修改捕获的变量的值，也不会获取其所有权，这三个 trait 是一种包含关系，如果一个闭包实现了 FnOnce trait，那么它也能实现 FnMut trait 和 Fn trait，如果一个闭包实现了 FnMut trait，那么它也能实现 Fn trait，在我们的场景下，每个任务只会执行一次，FnOnce trait 通过引入获取变量所有权的限制，不仅更适用于 mini-rayon 的框架语义，也提供了更丰富场景的支持。\n# 4.4.2 任务注册管理 1 2 3 4 5 6 7 8 9 10 11 12 13 14 struct RegistryState { threads_at_work: usize, injected_jobs: Vec\u0026lt;Job\u0026gt;, } pub struct Registry { thread_infos: Vec\u0026lt;ThreadInfo\u0026gt;, state: Mutex\u0026lt;RegistryState\u0026gt;, work_available: Condvar, terminated: AtomicBool, } unsafe impl Send for Registry { } unsafe impl Sync for Registry { } Registry 负责管理所有工作线程以及任务，因为 Registry 可能需要跨线程共享和传递，所以我们同样需要通过 unsafe impl 为其实现 Send 和 Sync trait。thread_infos 字段记录了每个工作线程的信息，state 字段记录目前活跃工作线程数以及还未分配工作线程的任务，当活跃工作线程数目大于 0 时，由于任务在执行过程中可能会产生新的待执行的任务，所以存在窃取任务的可能，work_available 是信号量，这一信号量的作用是当可能有新的任务可以执行或窃取时，会唤醒沉睡的工作线程数，注意这个地方是可能，而并不能保证一定有新的任务，terminated 字段用于停止整个线程池的运行，在初始化 Registry 时，会创建一定数量的工作线程，默认情况下工作线程数等于主机的 CPU 核心数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 impl Registry { pub fn inject(\u0026amp;self, injected_jobs: Vec\u0026lt;Job\u0026gt;) { let mut state = self.state.lock().unwrap(); state.injected_jobs.extend(injected_jobs); self.work_available.notify_all(); } fn start_working(\u0026amp;self) { let mut state = self.state.lock().unwrap(); state.threads_at_work += 1; self.work_available.notify_all(); } fn wait_for_work(\u0026amp;self, was_active: bool) -\u0026gt; Option\u0026lt;Job\u0026gt; { let mut state = self.state.lock().unwrap(); if was_active { state.threads_at_work -= 1; } loop { if let Some(job) = state.injected_jobs.pop() { return Some(job); } if state.threads_at_work \u0026gt; 0 { return None; } state = self.work_available.wait(state).unwrap(); } } } Registry 的主要函数包括 inject、start_working 和 wait_for_work。inject 函数用于提交新的任务，因为使用 mini-rayon 进行并行计算加速的线程并不是工作线程，所以提交的新任务会首先放在 Registry 中，当 inject 函数被调用时，会触发 work_available 信号量，任务后续会被工作线程给取走。start_working 和 wait_for_work 函数是内部函数，由工作线程调用。当工作线程开始执行一个新任务时，会通过 start_working 函数告知 Registry，原因在之前已经提到，本质上是告诉 Resgitry 当前有窃取任务的可能。当工作线程没有任务执行时，会调用 wait_for_work 函数，was_active 参数代表工作线程在等待工作之前是否有在执行任务，如果有的话，需要修改目前活跃工作线程数。在工作线程调用 wait_for_work 函数后，会有四种结果，第一种情况没有获取 Registry 的锁，此时会首先等待获取锁，没有锁意味着有其他工作线程在等待任务，那么即使该工作线程获取了锁，也没有任务需要执行，需要继续等待任务，所以这里对于锁的等待是合理的，与任务的等待等价，第二种情况 Registry 存在还未分发的任务，工作线程直接取走该任务并开始执行，第三种情况，当前活跃工作线程数大于 0，放弃从 Registry 中获取任务，尝试去其他工作线程的工作队列中窃取任务，第四种情况，不存在可执行以及可窃取的任务，所以需要在 Registry 中继续等待任务。\n# 4.4.3 工作线程数据结构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 struct ThreadInfo { primed: Latch, worker: Worker\u0026lt;Job\u0026gt;, stealer: Stealer\u0026lt;Job\u0026gt;, } pub struct WorkerThread { registry: Arc\u0026lt;Registry\u0026gt;, index: usize, } thread_local! { static WORKER_THREAD_STATE: RefCell\u0026lt;Option\u0026lt;Arc\u0026lt;WorkerThread\u0026gt;\u0026gt;\u0026gt; = RefCell::new(None); } WorkerThread 对应工作线程的数据结构，在 WorkerThread 中保存了指向 Registry 的指针以及 WorkerThread 在线程池中的 index。ThreadInfo 通过 deque crate 中实现的无锁双端队列提供了相应的接口。thread_local! 宏是 Rust 中用于创建线程本地存储的宏，通过 thread_local! 宏可以使得每个工作线程方便地拥有独立的 WorkerThread 实例。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 impl WorkerThread { pub fn push(\u0026amp;self, job: Job) { self.registry.thread_infos[self.index].worker.push(job); } pub fn pop(\u0026amp;self) -\u0026gt; Option\u0026lt;Job\u0026gt; { self.registry.thread_infos[self.index].worker.pop() } pub fn steal_until(\u0026amp;self, latch: Arc\u0026lt;Latch\u0026gt;) { while !latch.probe() { if let Some(mut job) = steal_work(self.registry.clone(), self.index) { job.execute(); } else { thread::yield_now(); } } } } WorkerThread 提供的主要函数包括 push、pop 和 steal_until。push 用于工作线程在执行任务的过程中，如果任务产生了新的子任务，可以通过 push 函数将任务插入到工作队列中，pop 函数用在工作队列中弹出一个任务，由于 join 原语往往会一次提交两个任务，并且需要同时返回两个任务的结果，所以 steal_until 函数用于在第二个任务被其他工作线程窃取时，等待该任务被其他工作线程执行完成的期间去其他工作线程窃取任务执行。\n# 4.5 接口设计与实现 # 4.5.1 join 在完成了上一小节中，我们对于整个 mini-rayon 框架的核心数据结构抽象后，我们就可以通过这些数据结构完成 join 语言的接口设计与实现。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 pub fn join\u0026lt;A, RA, B, RB\u0026gt;(oper_a: A, oper_b: B) -\u0026gt; (RA, RB) where A: FnOnce() -\u0026gt; RA + Send + \u0026#39;static, B: FnOnce() -\u0026gt; RB + Send + \u0026#39;static, RA: Send + \u0026#39;static, RB: Send + \u0026#39;static, { let worker_thread = WorkerThread::current(); if worker_thread.is_none() { return join_inject(oper_a, oper_b); } let worker_thread = worker_thread.unwrap(); let mut result_b = None; let code_b = Code::new(oper_b, \u0026amp;mut result_b as *mut Option\u0026lt;RB\u0026gt;); let latch_b = Arc::new(Latch::new()); let job_b = Job::new(Box::new(code_b), latch_b.clone()); worker_thread.push(job_b); let result_a = oper_a(); if let Some(mut job_b) = worker_thread.pop() { job_b.execute(); } else { worker_thread.steal_until(latch_b); } (result_a, result_b.unwrap()) } fn join_inject\u0026lt;A, RA, B, RB\u0026gt;(oper_a: A, oper_b: B) -\u0026gt; (RA, RB) where A: FnOnce() -\u0026gt; RA + Send + \u0026#39;static, B: FnOnce() -\u0026gt; RB + Send + \u0026#39;static, RA: Send + \u0026#39;static, RB: Send + \u0026#39;static, { let mut result_a = None; let code_a = Code::new(oper_a, \u0026amp;mut result_a as *mut Option\u0026lt;RA\u0026gt;); let latch_a = Arc::new(Latch::new()); let job_a = Job::new(Box::new(code_a), latch_a.clone()); let mut result_b = None; let code_b = Code::new(oper_b, \u0026amp;mut result_b as *mut Option\u0026lt;RB\u0026gt;); let latch_b = Arc::new(Latch::new()); let job_b = Job::new(Box::new(code_b), latch_b.clone()); get_registry().inject(vec![job_a, job_b]); latch_a.wait(); latch_b.wait(); (result_a.unwrap(), result_b.unwrap()) } join 函数接受两个满足 FnOnce() -\u0026gt; R + Send + \u0026lsquo;static trait bound 的闭包作为参数，需要满足 Send trait 的原因在于闭包与返回值都需要在工作线程之间传递，并由某一个工作线程执行其逻辑，\u0026lsquo;static 约束了闭包与返回值的生命周期，因为在编译的过程中，无法明确地知道闭包和返回值和会何时使用，所以出于简化的目的，避免引入声明生命周期过多的复杂性，直接声明闭包与返回值需要满足 \u0026lsquo;static 生命周期。\n事实上，\u0026lsquo;static 生命周期并不意味着一定需要程序运行过程中全局可用，\u0026lsquo;static 实际上是希望告诉编译器，开发者可以保证这个生命周期是能够满足的。在 mini-rayon 的场景中，编译器并不能自己判断出这一点，其本质原因在于 mini-rayon 是一个运行时框架，任务的执行是动态的，其生命周期是隐含的保证。\n在 join 函数中，我们会首先判断执行 join 函数的线程是否是工作线程，如果调用 join 函数是 mini-rayon 的使用线程，而非工作线程，则会通过 join_inject 函数将两个任务包装后插入到 Registry 中，get_registry 函数会获取 mini-rayon 的全局 Registry。执行 join 函数的工作线程，会首先执行第一个任务，并将第二个任务插入到工作队列中，在执行第一个任务的过程中，如果第二个任务被其他工作线程窃取，则会触发并行加速，如果其他工作线程都处于忙碌状态，无人窃取任务，那么 join 函数就会退化至顺序执行两个任务，从而实现了潜在并行性的语义。\n# 4.5.2 thread pool 在上述 join 原语接口的设计中， 由于全局 Registry 存在冷启动的情况，所以 mini-rayon 通过 ThreadPool 数据结构封装了单独的 Registry，这一设计可以实现对 Registry 细粒度的控制，通过 install 接口提交任务。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 pub struct ThreadPool { registry: Arc\u0026lt;Registry\u0026gt;, } impl ThreadPool { pub fn new() -\u0026gt; ThreadPool { let registry = Registry::new(); registry.wait_until_primed(); ThreadPool { registry, } } pub fn install\u0026lt;OP, R\u0026gt;(\u0026amp;self, op: OP) -\u0026gt; R where OP: FnOnce() -\u0026gt; R + Send + \u0026#39;static, R: Send + \u0026#39;static, { let mut result = None; let code = Code::new(op, \u0026amp;mut result as *mut Option\u0026lt;R\u0026gt;); let latch = Arc::new(Latch::new()); let job = Job::new(Box::new(code), latch.clone()); self.registry.inject(vec![job]); latch.wait(); result.unwrap() } } impl Drop for ThreadPool { fn drop(\u0026amp;mut self) { self.registry.terminate(); } } # 4.6 Rust feature 带来的优势 Rust 作为一种系统级编程语言，提供了强大的抽象能力，在编译时将这些抽象转换为高效的机器码，通过零成本抽象避免运行时开销的引入。Rust feature 为 mini-rayon 带来了一些天然的优势，下面会展开介绍如何通过 Rust feature 实现最小化任务推送开销以及避免并行编程中常见的数据竞争错误。\n# 4.6.1 最小化任务推送开销 在之前提到的任务调度过程中，为了充分发挥 join 原语带来的性能提升，避免并行抽象带来的额外成本，减少任务推送开销无疑是非常重要的。这里有两个主要原因，首先每次调用 join 都需要将其中的一个任务推送到本地队列，其次事实上处理器的数量很可能远远少于任务的数量，在这种情况下，大多数任务将不会被窃取，任务推送开销在此时变成了主要的并行抽象成本。\n为了减少任务推送开销，mini-rayon 利用了诸多 Rust feature：\njoin 原语时根据其参数的闭包类型进行通用定义的，这意味着 Rust 的单态化会在每个 join 原语的调用处生成不同的 join 原语实现副本。当 join 调用 oper_a() 和 oper_b() 时（在不被窃取的情况下），这些调用是静态分配的，它们可以进行内联，而无需分配空间创建闭包。 因为 join 原语会阻塞直至两个闭包完成，在这个过程中可以充分利用栈中的分配，完全避免堆的分配（例如，我们放入本地工作队列的闭包对象是在栈上分配的）。 通过上述方式，Rust 实现的推送任务开销实际上已经足够低，此外，还有一些方法可以进一步降低：\n许多工作窃取实现使用启发式方法来尝试决定何时跳过推送并行任务的工作。例如，一些策略尝试完全避免推送任务，除非存在可能窃取任务的空闲工作线程。 通过一些经典的方式进一步优化 join 原语所生成的汇编代码。 # 4.6.2 避免数据竞争 mini-rayon 通过 Rust feature 可以使得在向顺序代码添加并行性时，轻松地避免数据竞争，从而防止引入一些难以解释的并发错误。\n1 2 3 4 5 6 7 8 fn quick_sort\u0026lt;T:PartialOrd+Send\u0026gt;(v: \u0026amp;mut [T]) { if v.len() \u0026gt; 1 { let mid = partition(v); let (lo, hi) = v.split_at_mut(mid); mini_rayon::join(|| quick_sort(lo), || quick_sort(lo)); } } 首先，join 原语的两个闭包可能共享一些可变状态，因此其中一个闭包所做的更改可能会影响另一个闭包。例如在之前的快排实现实例中错误地调用 lo 上的 quick_sort 时，这将无法通过 Rust 的编译。Rust 使得这类错误成为编译错误，而不是难以解决的崩溃错误。\n1 2 3 4 fn share_rc\u0026lt;T:PartialOrd+Send\u0026gt;(rc: Rc\u0026lt;i32\u0026gt; { mini_rayon::join(|| something(rc.clone()), || something(rc.clone())); } 其次，另一个常见的错误是在闭包中使用非线程安全的数据类型。例如在上面的例子中使用了在线程之间共享不安全的 Rc 数据类型。这同样无法通过 Rust 的编译，这是由于 join 原语将闭包声明为 Send。Send 指示数据是否可以安全地跨线程传输。join 原语将两个闭包声明为 Send，实际上是在指示编译器在这些闭包中访问的数据必须能够安全地在线程中相互传输。\n换言之，Rust 自身的所有权、借用、多线程机制避免了数据竞争，而 mini-rayon 框架得益于这些 Rust feature，同样使得在修改顺序代码时避免引入过多的心智负担。\n# 五、构建在 join 之上的并行迭代器 上一章节详细介绍了 mini-rayon 中的 join 原语实现细节，mini-rayon 所提供的并行迭代器实际上就是构建在 join 原语之上的包装。因为 join 原语封装了所有的不安全性，并行迭代器不需要处理任何与并行性相关的 unsafe 代码。\n1 2 3 4 5 6 7 pub trait ParallelIterator { type Item; type Shared: Sync; type State: ParallelIteratorState\u0026lt;Shared=Self::Shared, Item=Self::Item\u0026gt; + Send; fn state(self) -\u0026gt; (Self::Shared, Self::State); } 上述代码是并行迭代器 trait ParallelIterator 的核心部分。state 方法将迭代器划分为一些共享状态和一些单一线程的状态。共享状态可能会被所有工作线程访问，因此它必须是 Sync 的，需要跨线程共享。单一线程的状态只需要是 Send 的，支持传输到其他线程。\n1 2 3 4 5 6 7 8 9 10 11 pub trait ParallelIteratorState: Sized { type Item; type Shared: Sync; fn len(\u0026amp;mut self) -\u0026gt; ParallelLen; fn split_at(self, index: usize) -\u0026gt; (Self, Self); fn for_each\u0026lt;OP\u0026gt;(self, shared: \u0026amp;Self::Shared, op: OP) where OP: FnMut(Self::Item); } ParallelteratorState trait 表示剩余工作的一部分，例如要处理的子数据切片。他包含了三个方法：len 方法给出了剩余工作量的概念；split_at 方法将这个状态分为分为另外两个部分；for_each 方法生成该迭代器中的所有值。因此对于一个 slice \u0026amp;[T] 所对应的并行迭代器，len 方法返回 slice 的长度，split_at 方法将 slice 分为两个子 slice，for_each 方法迭代数组并对每个元素调用 op。\n1 2 3 4 5 6 7 8 9 10 11 fn process(shared, state) { if state.len() is too big { let midpoint = state.len() / 2; let (state1, state2) = state.split_at(midpoint); rayon::join(|| process(shared, state1), || process(shared, state2)); } else { state.for_each(|item| { // process item }) } } 通过 ParallelIterator trait 和 ParallelteratorState trait，我们可以遵循相同的模版来实现一些并行操作。例如上面的这个 process 伪代码函数，首先检查有多少工作，如果太多，就分为两部分，否则，就按顺序处理。\n# 六、框架性能测试 我们在之前实现的基础上对 mini-rayon 进行性能测试，测试对象包括顺序计算的快速排序、通过 spawn 新线程实现的并行快速排序、通过 threadpool crate 使用线程池的并行快速排序和通过 mini-rayon 实现的并行快速排序，根据不同方式实现的快速排序如下面的代码所示。性能测试主机配置为 20 CPU 核心 32G 内存。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 fn partition\u0026lt;T\u0026gt;(v: \u0026amp;mut [T]) -\u0026gt; usize where T: PartialOrd + Send + \u0026#39;static { let pivot = v.len() - 1; let mut i = 0; for j in 0..pivot { if v[j] \u0026lt;= v[pivot] { v.swap(i, j); i += 1; } } v.swap(i, pivot); i } fn quick_sort\u0026lt;T\u0026gt;(v: \u0026amp;mut [T]) where T: PartialOrd + Send + \u0026#39;static { if v.len() \u0026lt;= 1 { return; } let mid = partition(v); let (lo, hi) = v.split_at_mut(mid); quick_sort(lo); quick_sort(hi); } fn quick_sort_parallel_by_spawn\u0026lt;T\u0026gt;(v: \u0026amp;\u0026#39;static mut [T]) where T: PartialOrd + Send + \u0026#39;static { if v.len() \u0026lt;= 200 { quick_sort(v); return; } let mid = partition(v); let (lo, hi) = v.split_at_mut(mid); let lo_handle = thread::spawn(|| quick_sort_parallel_by_spawn(lo)); let hi_handle = thread::spawn(|| quick_sort_parallel_by_spawn(hi)); lo_handle.join().unwrap(); hi_handle.join().unwrap(); } fn quick_sort_parallel_by_threadpool\u0026lt;T\u0026gt;(pool: \u0026amp;ThreadPool, v: \u0026amp;\u0026#39;static mut [T]) where T: PartialOrd + Send + \u0026#39;static { if v.len() \u0026lt;= 200 { quick_sort(v); return; } let mid = partition(v); let (lo, hi) = v.split_at_mut(mid); pool.execute(|| quick_sort_parallel_by_spawn(lo)); pool.execute(|| quick_sort_parallel_by_spawn(hi)); pool.join(); } fn quick_sort_parallel_by_mini_rayon\u0026lt;T\u0026gt;(v: \u0026amp;\u0026#39;static mut [T]) where T: PartialOrd + Send + \u0026#39;static { if v.len() \u0026lt;= 200 { quick_sort(v); return; } let mid = partition(v); let (lo, hi) = v.split_at_mut(mid); join(|| quick_sort_parallel_by_mini_rayon(lo), || quick_sort_parallel_by_mini_rayon(hi)); } 测试结果如下图所示，测试中我们分别使用了 10^6 和 10^8 两种数量级大小的随机数组进行排序测试。在两种数量级情况下，mini-rayon 都取得了最好的结果，且相比于顺序计算可以获得 5-7 倍的性能提升，这一性能提升无疑是非常显著的。此外，无论是在直接创建新线程或使用线程池的情况下并行化快速排序均性能表现不佳，在这里猜测主要原因在于直接创建新线程的情况下，由于任务粒度不大，频繁创建和销毁新线程严重影响了性能表现，即使是使用线程池，由于缺乏任务窃取机制，线程在使用的过程中同步成本过大，线程的利用率不高，即使完成了任务也需要在等待其他线程完成任务的过程中处于无法复用的状态，从而导致了相比于直接创建新线程仅能获得一点性能提升。\n在通过 threadpool crate 使用线程池的并行快速排序实现中，我们使用了 pool.join 函数，该函数实际上需要完成整个线程池的同步，而快速排序只需完成函数内两个闭包的同步即可返回，这一点是性能表现不佳的另一个原因。事实上，为了解决这个问题，我们无法通过 threadpool crate 提供的接口同步两个闭包，即使使用 channel 进行同步的情况下，由于引入了新的 channel 开销，根据实际测试表明在这个场景下性能表现也不会有明显的性能提升。另外，另一个常见的 crossbeam crate 提供了 scope 函数，支持创建作用域，在作用域内启动并行任务，并等待作用域内任务完成即可返回，但此函数仍会创建新的线程，难以有显著的性能提升。因此，即使是一个快速排序简单的测试场景，实际上已经可以证明 mini-rayon 和 Rayon 在数据并行计算加速中存在的价值。此外，测试中均保证了排序结果的有效性，测试代码位于 https://github.com/zjregee/mini/blob/main/mini-rayon/examples/quick_sort.rs\n# 参考资料 https://smallcultfollowing.com/babysteps/blog/2015/12/18/rayon-data-parallelism-in-rust/ https://github.com/nikomatsakis/rayon/ https://github.com/rayon-rs/rayon ","date":"2023-09-28T00:00:00Z","image":"https://zjregee.github.io/blog/p/mini-rayon/cover_hu8e48a4fdf6f1fa9f3ddf76ee9d927c43_321490_120x120_fill_q75_box_smart1.jpg","permalink":"https://zjregee.github.io/blog/p/mini-rayon/","title":"数据并行计算框架 mini-rayon 实现"},{"content":" 本文是 mini 系列的第一篇文章，mini 系列是一些知名框架或技术的最小化实现。本系列文章仅作为学习积累的目的，代码或架构在很大程度上参考了现有的一些源码或博客。本文实现了一个可作为 DNS 完整解析流程一部分的最小化 DNS 客户端，并详细介绍了 DNS 协议的原理细节。\n代码实现地址：https://github.com/zjregee/mini/mini-dns\n# 一、DNS 解析流程 # 1.1 什么是 DNS 解析 DNS 解析是将域名转换为相应的 IP 地址的过程。在互联网上，计算机和其他网络设备使用 IP 地址来定位和通信。然而，用户更容易记住和使用易于理解的域名，而不是复杂的 IP 地址。因此，DNS 解析充当了域名和 IP 地址之间的桥梁。DNS 解析的基本任务是将用户输入的域名映射到对应的 IP 地址。这个过程涉及到一系列的查询和响应步骤，包括本地域名服务器、根域名服务器、顶级域名服务器和权威域名服务器等。\n# 1.2 分层域名体系 互联网的域名体系采用层次树状结构，通过众多分布式的域名服务器系统进行解析操作，不仅提高了域名解析的效率，也保障了作为互联网基础设施的域名解析的稳定性。分层的域名体系不仅体现在由 . 隔开的层次结构的域名名称，更依赖于层次划分各司其职的多种 DNS 域名服务器：\n根域名服务器：DNS 层次结构中的最高级别，负责存储顶级域名服务器的 IP 地址。它不直接负责解析域名，而是提供指向顶级域名服务器的地址信息。 顶级域名服务器：管理顶级域的服务器，它存储了与特定的顶级域相关的权威域名服务器的 IP 地址，负责管理在该服务器注册的所有二级域名。 权威域名服务器：权威域名服务器是负责存储特定域名解析信息的服务器。当一个权威域名服务器不能给出查询结果的时候，就会告诉请求方下一步寻找哪一个权威域名服务器。 本地域名服务器：本地域名服务器本身并不属于层次树状结构的一部分，但在整个域名系统中扮演着行使请求方职责的重要任务。当一个用户计算机发出 DNS 查询请求时，会将查询请求报文交给本地域名服务器处理。 # 1.3 DNS 解析完整流程 具体来说一个完整的 DNS 域名解析流程包括以下几个步骤：\n用户输入需要 DNS 解析服务的域名； 检查浏览器缓存中是否有域名对应的解析过的 IP 地址，如果缓存中有，则结束解析过程。浏览器缓存域名是有限制的，不仅浏览器缓存大小有限制，而且缓存的时间也有限制，通常情况下为几分钟到几小时不等，域名被缓存的时间限制可以通过 TTL 属性来设置； 如果浏览器缓存中没有数据，浏览器会查找操作系统缓存中是否有这个域名对应的 DNS 解析结果。在 Linux 中还可以通过 /etc/hosts 文件来将任何域名解析到任何能够访问的 IP 地址； 当前两个过程无法解析时，就要用到网络配置中的本地域名服务器的地址了。操作系统会将这个域名发送给本地域名服务器，后续的 DNS 域名解析迭代和递归也是由本地域名服务器负责； 本地域名服务器向根域名服务器发起查询请求，询问它关于顶级域的权威域名服务器的 IP 地址； 本地域名服务器向得到的权威顶级域名服务器发送查询请求，讯问它关于二级域名的权威域名服务器的 IP 地址； 本地域名服务器向得到的权威域名服务器发送查询请求； 将查询结果返回给用户的计算机，用户可以通过获取的 IP 地址建立连接。 容易混淆的一点是本地域名服务器虽然称之为本地，但通常情况下并不是直接运行在用户的计算机中，而是由用户所连接的网络提供的。用户计算机通常通过动态主机配置协议（DHCP）或手动配置等方式从网络中获取本地域名服务器的 IP 地址。本地域名服务器通过迭代查询或递归查询等过程负责处理用户计算机发起的 DNS 解析请求，使得用户计算机无需感知其他的根域名服务器、顶级域名服务器和权威域名服务器等服务的存在。\n# 1.4 mini-dns 设计及充当的角色 在上一小节介绍 DNS 解析流程的时候已经提到了电脑中的 DNS 缓存分为两部分，它们分别是由操作系统管理的系统缓存和由浏览器管理的 DNS 缓存。这两个缓存通常都是存储在内存里，用于提高域名解析的速度，而没有保存在磁盘上的文件系统中。\n事实上，操作系统提供的系统 DNS 缓存以及 DNS 解析能力根据操作系统的不同而存在一定差异。以 Ubuntu 为例，Ubuntu使用 systemd-resolved 负责处理域名解析和 DNS 服务。systemd-resolved 是 systemd 体系结构中的一部分，它提供了一个本地的 DNS 解析器和缓存。systemd-resolved 在本地维护一个 DNS 缓存，用于存储之前解析的域名信息，这有助于避免重复向 DNS 服务器发出相同的查询请求，提高了解析的效率。systemd-resolved 还提供了 DNSSEC 支持，用于验证 DNS 响应的真实性和完整性，以提高安全性，以及 mDNS 支持，这是一种用于本地网络上的无配置服务发现的多播 DNS 协议。浏览器所需要的 DNS 解析能力也是建立在使用 systemd-resolved 提供的服务的基础上。\nmini-dns 作为一个最小化 DNS 客户端实现，并不是为了替代 systemd-resolved，也不是为了替代本地域名服务器，而是与 systemd-resolved 协同工作。在 Ubuntu 系统中，加入 mini-dns 后的 DNS 解析流程如下：\n操作系统或浏览器需要 DNS 服务时，首先将查询请求发送给 systemd-resolved； systemd-resolved 查看本地缓存，如果没有缓存命中，则先去查询 hosts 文件。如果仍没有相关信息，则将查询请求转发至 mini-dns； mini-dns 完成后续的查询请求，并将结果返回给 system-resolved。 从上述流程中可以看出，mini-rayon 旨在更灵活地控制本地域名解析，可以配置一些特殊域名或区域的处理，实现本地定制的 DNS 解析。其次，本地 DNS 客户端可以通过持久化方式缓存一些更长期的域名对应关系，但客观来说，协同工作对于性能提升还是有限的，因为，在实际的网络环境中，即使需要通过网络连接来发送 DNS 查询请求也不会跑多远就遇到诸多缓存，很难看到有明显的性能提升。此外，在上述流程的第三步，mini-dns 实际上可以实现本地域名服务器的功能，替代本地域名服务器的工作，完成迭代或递归的 DNS 解析流程。但这样做的意义有限，因此 mini-dns 只是将 DNS 解析请求直接转发给本地域名服务器。\n# 二、DNS 协议介绍 # 2.1 DNS 记录类型 DNS 记录是存储在域名系统数据库中的数据项，用于将域名与其他信息关联起来。这些记录包含了关于域名的各种信息，例如与域名相关联的 IP 地址、邮件服务器信息、文本信息等。DNS 记录有多种类型，每种类型有不同的用途，这些不同类型的记录协同工作，搭建了一个完善的层次结构。下面是一些常见的 DNS 记录类型：\nA 记录：映射域名到一个 IPv4 地址； AAAA 记录：映射域名到一个 IPv6 地址； CNAME 记录：创建域名的别名，将一个域名指向另一个域名； MX 记录：指定接收域的电子邮件的邮件服务器； PTR 记录：用于将 IP 地址映射回域名，通常用于反向 DNS 查找； NS 记录：指定域名的权威域名服务器，负责存储该域的 DNS 记录； TXT 记录：存储与域名相关的文本信息，通常用于验证域名所有权或提供其他信息； SOA 记录：包含有关域的权威信息，如域的主要域名服务器、域的管理员和域的参数； SRV 记录：用于指定特定服务的主机和端口。 # 2.2 DNS 报文格式 DNS 报文通常采用 UDP 进行传输，报文长度限制为 512 字节。这两条规则也有例外，DNS 报文可以通过 TCP 使用，并且通过称为 eDNS 的机制扩展数据包大小，但是本文不会过多涉及这些。DNS 报文使用相同的查询和响应格式，这与大多数互联网协议不同，大多数互联网协议使用不同的请求和响应结构。DNS 报文的数据包格式如下：\nHeader：12 字节，查询和响应的相关信息； Question Section：大小可变，表明查询域名和感兴趣的记录类型，在实际使用中，往往只有一个 Question； Answer Section：大小可变，所请求的相关记录； Authority Section：大小可变，NS 记录列表，用于递归地解析查询； Additional Section：大小可变，可能有用的一些记录，例如记录 NS 记录相关的 A 记录。 每个 Section 中的记录数由 Header 中的字段提供，Header 的结构如下：\nRFC Name Descriptive Name Length Description ID Packet Identifier 16 bits 为查询报文分配一个随机标识，响应报文必须使用相同的标识进行应答。这是由于 UDP 的无状态特性，区分响应所必须的。 QR Query Response 1 bit 0 代表查询报文，1 代表响应报文。 OPCODE Operation Code 4 bits 通常为 0，具体的细节要参考 RFC 1035。 AA Authoritative Answer 1 bit 如果响应服务器拥有所查询的域，设置为 1。 TC Truncated Message 1 bit 如果报文长度超过 512 字节，则设置为 1。通常用于提示使用 TCP 重新发出查询，TCP 不限制长度。 RD Recursion Desired 1 bit 由请求的发送方设置，如果服务器在没有现成的答案时需要尝试递归地解析查询。 RA Recursion Available 1 bit 由服务器设置，指示是否允许递归查询。 Z Reserved 3 bits 最初作为保留字段，现在用于 DNSSEC 查询。 RCODE Response Code 4 bits 由服务器设置，指示响应是否成功，在失败时提供有关失败原因的详细信息。 QDCOUNT Question Count 16 bits Question Section 中的记录数。 ANCOUNT Answer Count 16 bits Answer Section 中的记录数。 NSCOUNT Authority Count 16 bits Authority Section 中的记录数。 ARCOUNT Additional Count 16 bits Additional Section 中的记录数。 单个 Question Section 的记录包含如下字段：\nName：被编码成一个标签序列的域名，会在之后进一步说明； Type：2 字节的整型，代表记录的类型； Class：2 字节的整型，在实践中通常为 1。 单个 Answer Section 的记录包含如下字段：\nName：被编码成一个标签序列的域名； Type：2字节的整型，代表记录的类型； Class：2 字节的整型，在实践中通常为 1； TTL：4 字节的整形，记录可以缓存的时间； Len：2 字节的整型，记录类型特定数据的长度； Data：记录的数据，例如当记录为 A 类型时，Data 中的数据是 4 字节整型编码的 IP 地址。 # 2.3 DNS 操作示例 在这一小节我们会通过 dig 命令行工具来直观的感受 DNS 协议的实际使用。dig 是一个用于查询 DNS 信息的网络工具，可以用于诊断网络问题，验证 DNS 配置以及获取与域名相关的信息。\n可以看到 dig 明确描述了响应报文的 header、question section 和 answer section。header 中的 opcode 使用 OPCODE QUERY，对应于 0。status 也就是 RCODE，被设置为 NOERROR，对应于 0。id 为 4260，在重复查询时会随机更改。启用了 QR、RD、RA 标志位，它们的数值为 1。最后 header 还告诉了我们在 query section 和 answer section 分别有一个记录。answer section 显示了查询的结果，其中 IN 表示 class ，137 是 TTL，A 告诉我们在查询 A 记录，以及 google.com 的 IP 为 8.7.198.46。最后我们还知道了报文的总大小为 44 字节。\n# 2.4 一些更复杂的现实 由于 DNS 报文的大小限制，单个数据包最大为 512 字节，并且大部分的数据空间用于存储域名，数个域名之间往往会存在大量的重复字符串，因此在报文中会通过数据压缩的方式来节省数据空间的使用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 # dig @a.root-servers.net com - snip - ;; AUTHORITY SECTION: com. 172800 IN NS e.gtld-servers.net. com. 172800 IN NS b.gtld-servers.net. com. 172800 IN NS j.gtld-servers.net. com. 172800 IN NS m.gtld-servers.net. com. 172800 IN NS i.gtld-servers.net. com. 172800 IN NS f.gtld-servers.net. com. 172800 IN NS a.gtld-servers.net. com. 172800 IN NS g.gtld-servers.net. com. 172800 IN NS h.gtld-servers.net. com. 172800 IN NS l.gtld-servers.net. com. 172800 IN NS k.gtld-servers.net. com. 172800 IN NS c.gtld-servers.net. com. 172800 IN NS d.gtld-servers.net. ;; ADDITIONAL SECTION: e.gtld-servers.net. 172800 IN A 192.12.94.30 b.gtld-servers.net. 172800 IN A 192.33.14.30 b.gtld-servers.net. 172800 IN AAAA 2001:503:231d::2:30 j.gtld-servers.net. 172800 IN A 192.48.79.30 m.gtld-servers.net. 172800 IN A 192.55.83.30 i.gtld-servers.net. 172800 IN A 192.43.172.30 f.gtld-servers.net. 172800 IN A 192.35.51.30 a.gtld-servers.net. 172800 IN A 192.5.6.30 a.gtld-servers.net. 172800 IN AAAA 2001:503:a83e::2:30 g.gtld-servers.net. 172800 IN A 192.42.93.30 h.gtld-servers.net. 172800 IN A 192.54.112.30 l.gtld-servers.net. 172800 IN A 192.41.162.30 k.gtld-servers.net. 172800 IN A 192.52.178.30 c.gtld-servers.net. 172800 IN A 192.26.92.30 d.gtld-servers.net. 172800 IN A 192.31.80.30 - snip - 考虑上述的查询示例，我们查询互联网根服务器之一以获取处理 .com 的顶级域名服务器 IP 地址。gtld-servers.net 在查询结果中不断的重复出现，如果数据包中只需要包含这个字符串一次，并通过某种方式使得其他地方都指向这个字符串，显然可以大大压缩数据包大小。事实上，DNS 报文也是通过跳转的方式来实现数据压缩，它会告诉数据包的解析器如何跳转位置，完成名称的读取。\n之前我们提到过，记录中的 Name 字段会将每个域名编码为一系列标签，这一设计就是为了这里的数据压缩做下铺垫。在 DNS 数据报文中，每个标签前面都有一个指示其长度的字节，并且每个域名都以零长度的标签，即一个空字节结尾。例如 google 是 6 个字节，那么它的名称标签前面就是 0x06，com 是 3 个字节，前面就会是 0x03。如果这个标签前面的指示其长度的字节设置了两个最高的有效位，这代表着标签名称并不直接跟在这个字节的后面，而是需要将指示长度的字节和紧跟着的一个字节拼在一起，并除去两个最高有效位，获得标签名称的跳转地址。一旦获取标签名称后，就可以从之前中断的位置继续读取解析 DNS 数据包。\n# 三、报文序列与反序列化实现 在介绍完 DNS 协议后，我们就可以着手于具体的代码实现，得益于 DNS 多种记录格式统一的设计模式，在解析的过程中不会引入过多的复杂性。\n# 3.1 QueryType 1 2 3 4 5 6 7 8 9 #[derive(Copy, Clone, Debug, PartialEq, Eq, Hash)] pub enum QueryType { UNKNOWN(u16), A, NS, CNAME, MX, AAAA, } DNS 记录类型非常多，其中一部分在现实中几乎不会被使用，在这里我们首先定义我们需要着重实现的常用记录类型。\n# 3.2 BytePacketBuffer 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 pub struct BytePacketBuffer { pub buf: [u8; 512], pub pos: usize, } impl BytePacketBuffer { pub fn new() -\u0026gt; BytePacketBuffer { } pub fn pos(\u0026amp;self) -\u0026gt; usize { self.pos } pub fn step(\u0026amp;mut self, steps: usize) -\u0026gt; Result\u0026lt;()\u0026gt; { self.pos += steps; Ok(()) } pub fn seek(\u0026amp;mut self, pos: usize) -\u0026gt; Result\u0026lt;()\u0026gt; { self.pos = pos; Ok(()) } pub fn read(\u0026amp;mut self) -\u0026gt; Result\u0026lt;u8\u0026gt; { } pub fn get(\u0026amp;mut self, pos: usize) -\u0026gt; Result\u0026lt;u8\u0026gt; { } pub fn get_range(\u0026amp;mut self, start: usize, len: usize) -\u0026gt; Result\u0026lt;\u0026amp;[u8]\u0026gt; { } pub fn read_u16(\u0026amp;mut self) -\u0026gt; Result\u0026lt;u16\u0026gt; { } pub fn read_u32(\u0026amp;mut self) -\u0026gt; Result\u0026lt;u32\u0026gt; { } pub fn read_qname(\u0026amp;mut self, outstr: \u0026amp;mut String) -\u0026gt; Result\u0026lt;()\u0026gt; { } pub fn write(\u0026amp;mut self, val: u8) -\u0026gt; Result\u0026lt;()\u0026gt; { } pub fn write_u8(\u0026amp;mut self, val: u8) -\u0026gt; Result\u0026lt;()\u0026gt; { } pub fn write_u16(\u0026amp;mut self, val: u16) -\u0026gt; Result\u0026lt;()\u0026gt; { } pub fn write_u32(\u0026amp;mut self, val: u32) -\u0026gt; Result\u0026lt;()\u0026gt; { } pub fn write_qname(\u0026amp;mut self, qname: \u0026amp;str) -\u0026gt; Result\u0026lt;()\u0026gt; { } pub fn set(\u0026amp;mut self, pos: usize, val: u8) -\u0026gt; Result\u0026lt;()\u0026gt; { } pub fn set_u16(\u0026amp;mut self, pos: usize, val: u16) -\u0026gt; Result\u0026lt;()\u0026gt; { } } 为了更简便的操作 DNS 数据包，我们定义了一个 BytePacketBuffer 数据结构，它记录了数据和读写位置并提供了一系列操作数据包的方法。\n# 3.3 Header 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 #[derive(Clone, Debug)] pub struct Header { pub id: u16, pub recursion_desired: bool, pub truncated_message: bool, pub authoritative_answer: bool, pub opcode: u8, pub response: bool, pub rescode: ResultCode, pub checking_disabled: bool, pub authed_data: bool, pub z: bool, pub recursion_available: bool, pub questions: u16, pub answers: u16, pub authoritative_entries: u16, pub resource_entries: u16, } impl Header { pub fn read(\u0026amp;mut self, buffer: \u0026amp;mut BytePacketBuffer) -\u0026gt; Result\u0026lt;()\u0026gt; { } pub fn write(\u0026amp;self, buffer: \u0026amp;mut BytePacketBuffer) -\u0026gt; Result\u0026lt;()\u0026gt; { } } 我们用 Header 内存数据结构表示 DNS 数据报文的 Header 部分，并提供 read、write 方法处理 Header 的读取、解析与写入。\n# 3.4 Question 1 2 3 4 5 6 7 8 9 10 11 #[derive(Clone, Debug, PartialEq, Eq)] pub struct Question { pub name: String, pub qtype: QueryType, } impl Question { pub fn read(\u0026amp;mut self, buffer: \u0026amp;mut BytePacketBuffer) -\u0026gt; Result\u0026lt;()\u0026gt; { } pub fn write(\u0026amp;self, buffer: \u0026amp;mut BytePacketBuffer) -\u0026gt; Result\u0026lt;()\u0026gt; { } } Question 内存数据结构表示 DNS 数据报文的 Question Section，同样提供 read、write 方法处理读取、解析与写入。\n# 3.5 Record 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 #[derive(Clone, Debug, PartialEq, Eq, PartialOrd, Ord, Hash)] pub enum Record { UNKNOWN { domain: String, qtype: u16, data_len: u16, ttl: u32, }, // 0 A { domain: String, addr: Ipv4Addr, ttl: u32, }, // 1 NS { domain: String, host: String, ttl: u32, }, // 2 CNAME { domain: String, host: String, ttl: u32, }, // 5 MX { domain: String, priority: u16, host: String, ttl: u32, }, // 15 AAAA { domain: String, addr: Ipv6Addr, ttl: u32, }, // 28 } impl Record { pub fn read(buffer: \u0026amp;mut BytePacketBuffer) -\u0026gt; Result\u0026lt;Record\u0026gt; { } pub fn write(\u0026amp;self, buffer: \u0026amp;mut BytePacketBuffer) -\u0026gt; Result\u0026lt;usize\u0026gt; { } } Record 内存数据结构对应 DNS 数据报文中的单个记录，并且由于 DNS 数据报文中的其余部分均是由数个 Record 列表顺序排列而成的数据，所以通过 Record 即可表示出 DNS 数据报文的其他区域。Record 内存数据结构使用枚举类型，枚举类型便于表达出 Record 的类型多样性，以及每种类型特定的解析数据，并且易于拓展，可以方便地添加更多的记录类型。\n# 3.6 Packet 1 2 3 4 5 6 7 8 9 10 11 12 13 14 #[derive(Clone, Debug)] pub struct Packet { pub header: Header, pub questions: Vec\u0026lt;Question\u0026gt;, pub answers: Vec\u0026lt;Record\u0026gt;, pub authorities: Vec\u0026lt;Record\u0026gt;, pub resources: Vec\u0026lt;Record\u0026gt;, } impl Packet { pub fn from_buffer(buffer: \u0026amp;mut BytePacketBuffer) -\u0026gt; Result\u0026lt;Packet\u0026gt; { } pub fn write(\u0026amp;mut self, buffer: \u0026amp;mut BytePacketBuffer) -\u0026gt; Result\u0026lt;()\u0026gt; { } } 最后我们通过 Packe 内存数据结构将 DNS 数据报文的各个部分组织在一起。\n# 四、DNS 客户端实现与部署 # 4.1 客户端实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 fn lookup(qname: \u0026amp;str, qtype: QueryType) -\u0026gt; Result\u0026lt;Packet\u0026gt; { let server = (\u0026#34;8.8.8.8\u0026#34;, 53); let socket = UdpSocket::bind((\u0026#34;0.0.0.0\u0026#34;, 43210))?; let mut packet = Packet::new(); packet.header.id = 6666; packet.header.questions = 1; packet.header.recursion_desired = true; packet.questions.push(Question::new(qname.to_string(), qtype)); let mut req_buffer = BytePacketBuffer::new(); packet.write(\u0026amp;mut req_buffer)?; socket.send_to(\u0026amp;req_buffer.buf[0..req_buffer.pos], server)?; let mut res_buffer = BytePacketBuffer::new(); socket.recv_from(\u0026amp;mut res_buffer.buf)?; Packet::from_buffer(\u0026amp;mut res_buffer) } 在上一节我们完成了 DNS 数据报文的解析，即实现了序列与反序列化后，我们就可以通过网络连接发送我们构造的报文来验证实现。在上面我们实现了一个 lookup 函数，lookup 函数需要输入待查询的域名和查询类型，然后构造出一个数据包，并将这个数据包发送至地址为 8.8.8.8 的服务器，这是一个 Google 的公共本地域名服务器。这个服务器会帮助我们完成 DNS 解析的查询过程，并返回查询结果。我们解析返回的 DNS 数据报文，在这个数据报文中可以获取我们想要的查询结果。\n1 2 3 4 5 6 7 8 9 10 11 fn handle_query(socket: \u0026amp;UdpSocket) -\u0026gt; Result\u0026lt;()\u0026gt; { } fn main() -\u0026gt; Result\u0026lt;()\u0026gt; { let socket = UdpSocket::bind((\u0026#34;0.0.0.0\u0026#34;, 2053))?; loop { match handle_query(\u0026amp;socket) { Ok(_) =\u0026gt; {} Err(e) =\u0026gt; eprintln!(\u0026#34;An error occurred: {}\u0026#34;, e), } } } 接着我们像常见的网络编程方式一样，在程序的 main 函数中实现一个监听循环，将每一个发送至监听端口的待处理的 DNS 解析需求通过 lookup 获取结果并返回。这样我们就完成了 DNS 客户端的功能。\n# 4.2 部署与测试 测试我们所实现的 mini-dns 可以有两种方式，第一种方式我们可以协同配置 mini-dns 与 systemd-resolved，这样计算机中的任何 DNS 解析请求都会通过 mini-dns 来实现。 协同配置方法的如下：\n运行 mini-dns 在某一端口，监听 DNS 查询请求； 修改 systemd-resolved 配置文件 /etc/systemd/resolved.conf，指向 mini-dns 监听的地址和端口。 在这里，为了方便展示，我们直接使用第二种方式，即使用 dig 工具来直接测试 mini-dns。\n可以看到，我们在运行 mini-dns 后，通过 dig -p 参数指定了查询的端口。dig 获取了正确的查询结果，mini-dns 在终端中也打印出了一些中间结果，验证了 mini-dns 在 DNS 解析流程中的正确性。\n# 参考资料 https://github.com/EmilHernvall/dnsguide ","date":"2023-08-30T00:00:00Z","permalink":"https://zjregee.github.io/blog/p/mini-dns/","title":"mini-dns 一个最小化 DNS 客户端实现"},{"content":" # 一、基本介绍 fd 是一个 Rust 实现的用于在文件系统中寻找文件和目录项的命令行程序，提供了一系列简单、快速、用户友好的功能。fd 旨在替代 find 命令。find 命令是在 Unix 和类 Unix 操作系统中使用的一个强大的命令行工具，用于在文件系统中搜索文件和目录。find 命令的基本语法如下：\n1 find [起始目录] [匹配条件] [动作] 其中起始目录指定搜索的起始目录，匹配条件用于指定搜索文件的条件，可以是文件名、文件类型、文件大小等，动作用于指定在找到匹配项后执行的动作，例如打印文件名、删除文件等。作为替代的 find 的 fd，fd 有如下特征：\n更直观的语法； 基于正则表达式和 glob 的模式匹配； 并行的目录遍历，大幅度的速度优化； 使用颜色来突出显示不同类型的文件； 并行命令执行的支持； 智能大小写处理； 默认情况下忽略隐藏的目录和文件； 默认情况下，忽略 .gitignore 中的模式匹配。 1）基于 glob 的模式匹配是一种用于匹配文件路径或名称的简单模式匹配方法，通常在命令行中使用。这种模式使用通配符来表示匹配一类文件或目录的模式，相较于正则表达式更加简单，语法和功能有一定限制。在很多情况下是一种简便而有效来指定文件路径的模式。\n2）根据作者提供的测试数据，fd 相较于 find 命令可以取得一个数量级上的性能提升。fd 速度上的性能提升主要归功于并行的目录遍历以及相关正则表达式处理库。\nfd 可以实现多种方式的搜索，例如根据包含指定字符串的搜索、正则表达式搜索、指定根目录的搜索、搜索一个特定的文件扩展名、搜索一个特定的文件名、搜索隐藏和忽略的文件、匹配完整路径的搜索、执行命令的搜索、排除特定文件或目录的搜索，也可以将多种搜索条件在一次搜索中进行表达。 作为 Github 上的明星项目，fd 已有近 30k 的 star 数，同时也是基于 Rust 实现的诸多命令行工具中最具有代表性的项目之一。本文将会大致介绍 fd 的整体框架和实现逻辑，值得一提的是命令行程序会有诸多不可避免的实现上的繁琐性，对于一些细节代码，本文不会做过多展开。\n# 二、整体框架 fd 使用了 jemalloc 内存分配器替换了默认的系统内存分配器。Rust 提供了一种插件式的内存分配器接口，允许开发者使用不同的内存分配器。jemalloc 是一种高效的内存分配器，尤其适用于多线程的应用程序，同时提供了内存分析能力。\n# 三、过滤筛选 fd 作为一个强大、易用的检索工具，提供了多种过滤筛选的方式。\n# 3.1 基于类型的筛选 1 2 3 4 5 6 7 8 9 10 11 12 13 14 #[derive(Default)] pub struct FileTypes { pub files: bool, pub directories: bool, pub symlinks: bool, pub sockets: bool, pub pipes: bool, pub executables_only: bool, pub empty_only: bool, } impl FileTypes { pub fn should_ignore(\u0026amp;self, entry: \u0026amp;dir_entry::DirEntry) -\u0026gt; bool { ... } } fd 通过 FileTypes 记录了需要在命令行展示文件和目录的类型。通过 should_ignore 函数将在文件系统遍历中得到的文件和目录根据 FileTypes 设置进行基于类型的筛选。\n# 3.2 基于权限的筛选 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #[derive(Clone, Copy, Debug, PartialEq, Eq)] pub struct OwnerFilter { uid: Check\u0026lt;u32\u0026gt;, gid: Check\u0026lt;u32\u0026gt;, } #[derive(Clone, Copy, Debug, PartialEq, Eq)] enum Check\u0026lt;T\u0026gt; { Equal(T), NotEq(T), Ignore, } impl OwnerFilter { pub fn matches(\u0026amp;self, md: \u0026amp;fs::Metadata) -\u0026gt; bool { ... } } fd 通过 OwnerFilter 记录需要在命令行展示文件和目录的权限范围，matches 函数根据具体的元数据来实现基于权限的筛选。\n# 3.3 基于大小的筛选 1 2 3 4 5 6 7 8 9 10 #[derive(Clone, Copy, Debug, PartialEq, Eq)] pub enum SizeFilter { Max(u64), Min(u64), Equals(u64), } impl SizeFilter { pub fn is_within(\u0026amp;self, size: u64) -\u0026gt; bool { ... } } fd 通过 SizeFilter 记录基于大小的筛选条件，并提供了 is_within 函数。\n# 3.4 基于时间的筛选 1 2 3 4 5 6 7 8 9 #[derive(Debug, PartialEq, Eq)] pub enum TimeFilter { Before(SystemTime), After(SystemTime), } impl TimeFilter { pub fn applies_to(\u0026amp;self, t: \u0026amp;SystemTime) -\u0026gt; bool { ... } } fd 通过 TimeFilter 记录基于时间的筛选条件，并提供了 applies_to 函数。\n# 四、文件系统遍历 文件系统遍历是 fd 所需要考虑的第一个核心功能，fd 需要获取指定目录下的所有目录和文件，才能做进一步的处理、筛选和展示。事实上，fd 通过 ignore 第三方 crate 来实现这一功能，ignore crate 提供了一个快速递归目录迭代器。\n# 4.1 数据结构抽象 1 2 3 4 5 6 7 8 9 10 enum DirEntryInner { Normal(ignore::DirEntry), BrokenSymlink(PathBuf), } pub struct DirEntry { inner: DirEntryInner, metadata: OnceCell\u0026lt;Option\u0026lt;Metadata\u0026gt;\u0026gt;, style: OnceCell\u0026lt;Option\u0026lt;Style\u0026gt;\u0026gt;, } fd 通过 DirEntry 保存在文件系统遍历过程中获取的文件和目录项，并提供了一系列获取路径和元数据以及命令行显示风格的方法。\n# 4.2 并行遍历模式 # 4.2.1 数据接收缓存 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 #[derive(PartialEq)] enum ReceiverMode { Buffering, Streaming, } #[allow(clippy::large_enum_variant)] pub enum WorkerResult { Entry(DirEntry), Error(ignore::Error), } struct ReceiverBuffer\u0026lt;W\u0026gt; { config: Arc\u0026lt;Config\u0026gt;, quit_flag: Arc\u0026lt;AtomicBool\u0026gt;, interrupt_flag: Arc\u0026lt;AtomicBool\u0026gt;, rx: Receiver\u0026lt;WorkerResult\u0026gt;, stdout: W, mode: ReceiverMode, deadline: Instant, buffer: Vec\u0026lt;DirEntry\u0026gt;, num_results: usize, } impl\u0026lt;W: Write\u0026gt; ReceiverBuffer\u0026lt;W\u0026gt; { fn process(\u0026amp;mut self) -\u0026gt; ExitCode { ... } fn recv(\u0026amp;self) -\u0026gt; Result\u0026lt;WorkerResult, RecvTimeoutError\u0026gt; { ... } fn poll(\u0026amp;mut self) -\u0026gt; Result\u0026lt;(), ExitCode\u0026gt; { ... } fn print(\u0026amp;mut self, entry: \u0026amp;DirEntry) -\u0026gt; Result\u0026lt;(), ExitCode\u0026gt; { ... } fn stream(\u0026amp;mut self) -\u0026gt; Result\u0026lt;(), ExitCode\u0026gt; { ... } fn stop(\u0026amp;mut self) -\u0026gt; Result\u0026lt;(), ExitCode\u0026gt; { ... } } fd 通过 channel 实现单消费者多生产者模型并构建数据流水线。当开始路径遍历过程时，fd 会 spawn 一个新的线程创建 ReceiverBuffer 数据结构，并调用其 process 函数进行循环处理。\nprocess 函数采用了状态机模型，其中的每一次循环都会调用 poll 函数。poll 函数代表着一次数据处理或是状态转换，函数处理逻辑如下：\n调用 recv 函数从 channel 中接收一个数据。ReceiverBuffer 有两种接收模式，Buffering 和 Streaming 模式。在 Buffering 模式下，recv 函数会等待 channel 中的数据直到达到 ReceiverBuffer 的 deadline。而 Streaming 模式会一直等待 channel 返回数据。在默认情况下 ReceiverBuffer 初始化为 Buffering 模式。 根据 recv 函数的返回情况实现不同的行为。 当 recv 函数成功返回一个文件或目录项时，如果当前的接收模式仍为 Buffering 模式时，将数据插入 buffer，并在 buffer 的数据量大于设置的阈值时调用 stream 函数。stream 函数会将当前的接收模式修改为 Streaming 模式，并使用 print 函数打印 buffer 中的所有文件或目录项。如果当前的接收模式为 Streaming 模式时，调用 print 函数直接打印该文件或目录项。 当 recv 函数返回超时错误时，说明在 Buffering 模式下，recv 函数在达到 deadline 时仍未接收到新数据，调用 stream 函数，打印现有 buffer 中的数据，并将接收模式修改为 Streaming 模式。 当 recv 函数返回 channel 关闭消息时，则调用 stop 方法。如果当前 ReceiverBuffer 仍为 Buffering 接收模式，则排序 buffer 中的数据并打印。 为什么需要有 Buffering 和 Streaming 两种接收模式？\n在文件系统遍历初期，可能有大量结果需要输出，通过缓存的方式批量输出结果降低输出压力。在达到一定的时间或数据量后，如果仍需要有数据输出，则可以切换至 FIFO 模式输出结果。\n# 4.2.2 并行数据发送 fd 在遍历文件系统时，会通过 ignore crate 构建一个并行的目录迭代器。并行的目录迭代器会根据设置 spawn 多个线程，每个线程会通过相同的方式处理目录迭代器产生的遍历结果。当目录迭代器返回一个遍历结果时，首先判断是否返回了错误，如果在遍历过程中发生了错误，则直接将错误通过 channel 发送至 ReceiverBuffer，ReceiverBuffer 会直接打印错误信息。然后会先根据文件或目录项的名字进行筛选，因为根据名字进行筛选不需要获取元数据，再根据第二章中提到的各种筛选方式进行筛选。当满足所有条件后，将数据发送至 ReceiverBuffer。\n# 五、命令执行模型 fd 不仅仅可以显示搜索的结果，也支持对搜索结果执行一系列的外部命令。fd 为搜索结果提供了两种执行外部命令的方式：\n-x/\u0026ndash;exec 选项为每个搜索结果并行地运行一个外部命令； -X/\u0026ndash;exec-batch 选项启动外部命令一次，并将所有搜索结果作为参数。 fd 还支持使用占位符语法将命令作为一种模版而不是单个字符串时用，具体来收，fd 提供了对如下占位符的支持：\n{}：一个占位符标记，将被搜索结果的路径所替换； {.}：与 {} 类似，但会去除搜索结果的文件扩展名； {/}：将被搜索结果的文件名所替换； {//}：将被搜索结果的父目录路径所替换； {/.}：去除搜索结果文件扩展名的文件名。 当没有使用占位符时，实际上 fd 会自动在末尾加上 {}。\n# 5.1 命令相关数据结构抽象 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 #[derive(Clone, Debug, PartialEq, Eq)] pub enum Token { Placeholder, Basename, Parent, NoExt, BasenameNoExt, Text(String), } #[derive(Clone, Debug, PartialEq)] enum ArgumentTemplate { Tokens(Vec\u0026lt;Token\u0026gt;), Text(String), } #[derive(Debug, Clone, PartialEq)] struct CommandTemplate { args: Vec\u0026lt;ArgumentTemplate\u0026gt;, } Token 代表着占位符的类型，ArgumentTemplate 是命令的参数单元，多个 ArgumentTemplate 组成了一个完整的命令。\n# 5.2 CommandSet 数据结构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 #[derive(Debug, Clone, Copy, PartialEq, Eq)] pub enum ExecutionMode { OneByOne, Batch, } #[derive(Debug, Clone, PartialEq)] pub struct CommandSet { mode: ExecutionMode, commands: Vec\u0026lt;CommandTemplate\u0026gt;, } impl CommandSet { pub fn new\u0026lt;I, T, S\u0026gt;(input: I) -\u0026gt; Result\u0026lt;CommandSet\u0026gt; where I: IntoIterator\u0026lt;Item = T\u0026gt;, T: IntoIterator\u0026lt;Item = S\u0026gt;, S: AsRef\u0026lt;str\u0026gt;, { ... } pub fn new_batch\u0026lt;I, T, S\u0026gt;(input: I) -\u0026gt; Result\u0026lt;CommandSet\u0026gt; where I: IntoIterator\u0026lt;Item = T\u0026gt;, T: IntoIterator\u0026lt;Item = S\u0026gt;, S: AsRef\u0026lt;str\u0026gt;, { ... } pub fn execute( \u0026amp;self, input: \u0026amp;Path, path_separator: Option\u0026lt;\u0026amp;str\u0026gt;, out_perm: Arc\u0026lt;Mutex\u0026lt;()\u0026gt;\u0026gt;, buffer_output: bool ) -\u0026gt; ExitCode { ... }, pub fn execute_batch\u0026lt;I\u0026gt;(\u0026amp;self, paths: I, limit: usize, path_separator: Option\u0026lt;\u0026amp;str\u0026gt;) -\u0026gt; ExitCode where I: Iterator\u0026lt;Item = PathBuf\u0026gt;, { ... } } CommandSet 代表 fd 需要执行的命令集合。CommandSet 有两种执行模式，OneByOne 和 Batch 模式。 在 OneByOne 模式下，调用 execute 函数会将 fd 在文件系统遍历过程中得到的单个结果依据 CommandTemplate 生成完整的命令表示，并打印输出命令执行结果。值的一提的是，OneByOne 模式并不意味着 fd 一次只会处理一个文件系统得到的遍历结果，fd 会根据设置并发多个线程对多个遍历结果执行各自的命令集合。在多个线程前提下，fd 会使用输出缓存，等待单个遍历结果全部执行完毕命令集合后一起输出最后的执行结果。如果只使用一个线程接收文件系统遍历的结果并执行命令时，fd 不使用输出缓存，而是启动一个新的进程并等待它完成。这样做的好处是允许查看中间命令输出并与之交互。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 #[derive(Debug)] struct CommandBuilder { pre_args: Vec\u0026lt;OsString\u0026gt;, path_arg: ArgumentTemplate, post_args: Vec\u0026lt;OsString\u0026gt;, cmd: Command, count: usize, limit: usize, exit_code: ExitCode, } impl CommandBuilder { fn push(\u0026amp;mut self, path: \u0026amp;Path, separator: Option\u0026lt;\u0026amp;str\u0026gt;) -\u0026gt; io::Result\u0026lt;()\u0026gt; { ... } fn finish(\u0026amp;mut self) -\u0026gt; io::Result\u0026lt;()\u0026gt; { ... } } 在 Batch 模式下，调用 execute_batch 函数使用 fd 遍历文件系统得到的所有结果构造 CommandBuilder，用于在命令执行过程中添加多个结果参数。\n本文基于 v8.7.0 版本的 fd 实现。\nGithub 地址：https://github.com/sharkdp/fd\n","date":"2023-08-17T00:00:00Z","image":"https://zjregee.github.io/blog/p/fd/cover_hu5d8acb1e814c36457f6782e122fe0ff3_366641_120x120_fill_q75_box_smart1.jpg","permalink":"https://zjregee.github.io/blog/p/fd/","title":"新一代文件系统检索命令行工具 fd 源码阅读"}]